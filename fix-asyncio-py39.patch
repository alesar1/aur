Only in orig/catkin_tools-0.5.0/: build
diff -ur orig/catkin_tools-0.5.0/catkin_tools/execution/executor.py catkin_tools-0.5.0/catkin_tools/execution/executor.py
--- orig/catkin_tools-0.5.0/catkin_tools/execution/executor.py	2020-12-04 14:39:41.194846733 -0800
+++ catkin_tools-0.5.0/catkin_tools/execution/executor.py	2020-12-04 14:40:59.722491646 -0800
@@ -43,8 +43,7 @@
     return [v for c, v in head if c], [v for c, v in tail if not c]
 
 
-@asyncio.coroutine
-def async_job(verb, job, threadpool, locks, event_queue, log_path):
+async def async_job(verb, job, threadpool, locks, event_queue, log_path):
     """Run a sequence of Stages from a Job and collect their output.
 
     :param job: A Job instance
@@ -70,7 +69,7 @@
         # Check for stage synchronization lock
         if stage.locked_resource is not None:
             lock = locks.setdefault(stage.locked_resource, asyncio.Lock())
-            yield from lock
+            await lock.acquire()
         else:
             lock = FakeLock()
 
@@ -79,7 +78,7 @@
             if stage.occupy_job:
                 if not occupying_job:
                     while job_server.try_acquire() is None:
-                        yield from asyncio.sleep(0.05)
+                        await asyncio.sleep(0.05)
                     occupying_job = True
             else:
                 if occupying_job:
@@ -103,16 +102,15 @@
                             # Get the logger
                             protocol_type = stage.logger_factory(verb, job.jid, stage.label, event_queue, log_path)
                             # Start asynchroonous execution
-                            transport, logger = yield from (
-                                async_execute_process(
-                                    protocol_type,
-                                    **stage.async_execute_process_kwargs))
+                            transport, logger = await async_execute_process(
+                                protocol_type,
+                                **stage.async_execute_process_kwargs)
                             break
                         except OSError as exc:
                             if 'Text file busy' in str(exc):
                                 # This is a transient error, try again shortly
                                 # TODO: report the file causing the problem (exc.filename)
-                                yield from asyncio.sleep(0.01)
+                                await asyncio.sleep(0.01)
                                 continue
                             raise
 
@@ -125,7 +123,7 @@
                         **stage.async_execute_process_kwargs))
 
                     # Asynchronously yield until this command is completed
-                    retcode = yield from logger.complete
+                    retcode = await logger.complete
                 except:  # noqa: E722
                     # Bare except is permissable here because the set of errors which the CommandState might raise
                     # is unbounded. We capture the traceback here and save it to the build's log files.
@@ -137,7 +135,7 @@
                 logger = IOBufferLogger(verb, job.jid, stage.label, event_queue, log_path)
                 try:
                     # Asynchronously yield until this function is completed
-                    retcode = yield from get_loop().run_in_executor(
+                    retcode = await get_loop().run_in_executor(
                         threadpool,
                         stage.function,
                         logger,
@@ -182,8 +180,7 @@
     return (job.jid, all_stages_succeeded)
 
 
-@asyncio.coroutine
-def execute_jobs(
+async def execute_jobs(
         verb,
         jobs,
         locks,
@@ -272,14 +269,14 @@
         ))
 
         # Process jobs as they complete asynchronously
-        done_job_fs, active_job_fs = yield from asyncio.wait(
+        done_job_fs, active_job_fs = await asyncio.wait(
             active_job_fs,
             timeout=0.10,
             return_when=FIRST_COMPLETED)
 
         for done_job_f in done_job_fs:
             # Capture a result once the job has finished
-            job_id, succeeded = yield from done_job_f
+            job_id, succeeded = await done_job_f
 
             # Release a jobserver token now that this job has succeeded
             job_server.release(job_id)
