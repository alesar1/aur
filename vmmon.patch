--- a/vmmon/Makefile
+++ b/vmmon/Makefile
@@ -43,7 +43,11 @@ INCLUDE      += -I$(SRCROOT)/shared
 endif
 
 
+ifdef KVERSION
+VM_UNAME = $(KVERSION)
+else
 VM_UNAME = $(shell uname -r)
+endif
 
 # Header directory for the running kernel
 ifdef LINUXINCLUDE
@@ -100,6 +104,13 @@ auto-build: $(DRIVER_KO)
 $(DRIVER): $(DRIVER_KO)
 	if [ $< -nt $@ ] || [ ! -e $@ ] ; then cp -f $< $@; fi
 
+# Use SUBDIRS on 2.x, 3.x, 4.x.  Use M on newer kernels.
+ifeq ($(filter-out 2 3 4,$(firstword $(subst ., ,$(VM_UNAME)))),)
+DIRVAR := SUBDIRS
+else
+DIRVAR := M
+endif
+
 # Pass gcc version down the chain, so we can detect if kernel attempts to use unapproved compiler
 VM_CCVER := $(VMCCVER)
 export VM_CCVER
@@ -117,7 +128,7 @@ prebuild:: ;
 postbuild:: ;
 
 $(DRIVER_KO): prebuild
-	$(MAKE) -C $(BUILD_DIR) SUBDIRS=$$PWD SRCROOT=$$PWD/$(SRCROOT) \
+	$(MAKE) -C $(BUILD_DIR) $(DIRVAR)=$$PWD SRCROOT=$$PWD/$(SRCROOT) \
 	  MODULEBUILDDIR=$(MODULEBUILDDIR) modules
 	$(MAKE) -C $$PWD SRCROOT=$$PWD/$(SRCROOT) \
 	  MODULEBUILDDIR=$(MODULEBUILDDIR) postbuild
--- a/vmmon/linux/driver.c
+++ b/vmmon/linux/driver.c
@@ -104,7 +114,9 @@ long LinuxDriver_Ioctl(struct file *filp, u_int iocmd,
 
 static int LinuxDriver_Close(struct inode *inode, struct file *filp);
 static unsigned int LinuxDriverPoll(struct file *file, poll_table *wait);
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 11, 0)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 17, 0)
+static vm_fault_t LinuxDriverFault(struct vm_fault *fault);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4, 11, 0)
 static int LinuxDriverFault(struct vm_fault *fault);
 #elif defined(VMW_NOPAGE_2624)
 static int LinuxDriverFault(struct vm_area_struct *vma, struct vm_fault *fault);
@@ -115,7 +115,7 @@
 #endif
 static int LinuxDriverMmap(struct file *filp, struct vm_area_struct *vma);
 
-static void LinuxDriverPollTimeout(unsigned long clientData);
+static void LinuxDriverPollTimeout(struct timer_list *clientData);
 static unsigned int LinuxDriverEstimateTSCkHz(void);
 
 static struct vm_operations_struct vmuser_mops = {
@@ -227,7 +228,7 @@ LinuxDriverEstimateTSCkHz(void)
  *----------------------------------------------------------------------
  */
 static void
-LinuxDriverEstimateTSCkHzDeferred(unsigned long data)
+LinuxDriverEstimateTSCkHzDeferred(struct timer_list *data)
 {
    LinuxDriverEstimateTSCkHz();
 }
@@ -265,9 +266,7 @@ LinuxDriverInitTSCkHz(void)
    }
 
    Vmx86_ReadTSCAndUptime(&tsckHzStartTime);
-   tscTimer.function = LinuxDriverEstimateTSCkHzDeferred;
    tscTimer.expires  = jiffies + 4 * HZ;
-   tscTimer.data     = 0;
    add_timer(&tscTimer);
 }
 
@@ -309,9 +308,13 @@ init_module(void)
     */
 
    init_waitqueue_head(&linuxState.pollQueue);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 15, 0) && !defined(timer_setup)
    init_timer(&linuxState.pollTimer);
    linuxState.pollTimer.data = 0;
-   linuxState.pollTimer.function = LinuxDriverPollTimeout;
+   linuxState.pollTimer.function = (void *)LinuxDriverPollTimeout;
+#else
+   timer_setup(&linuxState.pollTimer, LinuxDriverPollTimeout, 0);
+#endif
 
    linuxState.fastClockThread = NULL;
    linuxState.fastClockFile = NULL;
@@ -360,7 +357,13 @@ init_module(void)
        linuxState.deviceName, linuxState.major, linuxState.minor);
 
    HostIF_InitUptime();
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 15, 0) && !defined(timer_setup)
    init_timer(&tscTimer);
+   tscTimer.function = (void *)LinuxDriverEstimateTSCkHzDeferred;
+   tscTimer.data = (unsigned long)&tscTimer;
+#else
+   timer_setup(&tscTimer, LinuxDriverEstimateTSCkHzDeferred, 0);
+#endif
    LinuxDriverInitTSCkHz();
    Vmx86_InitIDList();
 
@@ -741,14 +751,12 @@ void
 LinuxDriverWakeUp(Bool selective)  // IN:
 {
    if (selective && linuxState.pollList != NULL) {
-      struct timeval tv;
       VmTimeType now;
       VMLinux *p;
       VMLinux *next;
 
       HostIF_PollListLock(1);
-      do_gettimeofday(&tv);
-      now = tv.tv_sec * 1000000ULL + tv.tv_usec;
+      now = ktime_get_ns() / NSEC_PER_USEC;
 
       for (p = linuxState.pollList; p != NULL; p = next) {
          next = p->pollForw;
@@ -815,12 +823,10 @@ LinuxDriverPoll(struct file *filp,  // IN:
       }
    } else {
       if (linuxState.fastClockThread && vmLinux->pollTimeoutPtr != NULL) {
-         struct timeval tv;
+         u64 now = ktime_get_ns() / NSEC_PER_USEC;
 
-         do_gettimeofday(&tv);
          poll_wait(filp, &vmLinux->pollQueue, wait);
-         vmLinux->pollTime = *vmLinux->pollTimeoutPtr +
-                                       tv.tv_sec * 1000000ULL + tv.tv_usec;
+         vmLinux->pollTime = *vmLinux->pollTimeoutPtr + now;
          if (vmLinux->pollBack == NULL) {
             HostIF_PollListLock(2);
             if (vmLinux->pollBack == NULL) {
@@ -858,7 +858,7 @@
  */
 
 static void
-LinuxDriverPollTimeout(unsigned long clientData)  // IN:
+LinuxDriverPollTimeout(struct timer_list *clientData)  // IN:
 {
    LinuxDriverWakeUp(FALSE);
 }
@@ -884,7 +904,12 @@ LinuxDriver_Close(struct inode *inode, // IN
  */
 
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 11, 0)
-static int
+static
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 17, 0)
+vm_fault_t
+#else
+int
+#endif
 LinuxDriverFault(struct vm_fault *fault)     //IN/OUT
 #elif defined(VMW_NOPAGE_2624)
 static int LinuxDriverFault(struct vm_area_struct *vma, //IN
--- a/vmmon/linux/hostif.c
+++ b/vmmon/linux/hostif.c
@@ -1164,16 +1172,7 @@
 {
    int retval;
 
-   down_read(&current->mm->mmap_sem);
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 9, 0)
-   retval = get_user_pages((unsigned long)uvAddr, numPages, 0, ppages, NULL);
-#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4, 6, 0)
-   retval = get_user_pages((unsigned long)uvAddr, numPages, 0, 0, ppages, NULL);
-#else
-   retval = get_user_pages(current, current->mm, (unsigned long)uvAddr,
-                           numPages, 0, 0, ppages, NULL);
-#endif
-   up_read(&current->mm->mmap_sem);
+   retval = get_user_pages_fast((unsigned long)uvAddr, numPages, 0, ppages);
 
    return retval != numPages;
 }
@@ -1574,9 +1565,13 @@
     * since at least 2.6.0.
     */
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 0, 0)
    extern unsigned long totalram_pages;
 
    unsigned int totalPhysicalPages = totalram_pages;
+#else
+   unsigned int totalPhysicalPages = totalram_pages();
+#endif
 
 #if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 28)
    return MemDefaults_CalcMaxLockedPages(totalPhysicalPages);
@@ -1594,17 +1593,34 @@ HostIF_EstimateLockedPageLimit(const VMDriver* vm,                // IN
    unsigned int reservedPages = MEMDEFAULTS_MIN_HOST_PAGES;
    unsigned int hugePages = (vm == NULL) ? 0 :
       BYTES_2_PAGES(vm->memInfo.hugePageBytes);
-   unsigned int lockedPages = global_page_state(NR_PAGETABLE) +
-                              global_page_state(NR_SLAB_UNRECLAIMABLE) +
-                              global_page_state(NR_UNEVICTABLE) +
-                              hugePages + reservedPages;
-   unsigned int anonPages =
+   unsigned int lockedPages = hugePages + reservedPages;
+   unsigned int anonPages;
+   unsigned int swapPages = BYTES_2_PAGES(linuxState.swapSize);
+
+   /* global_page_state is global_zone_page_state in 4.14. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 14, 0)
+   lockedPages += global_zone_page_state(NR_PAGETABLE);
+#else
+   lockedPages += global_page_state(NR_PAGETABLE);
+#endif
+   /* NR_SLAB_* moved from zone to node in 4.13. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 13, 0)
+   lockedPages += global_node_page_state(NR_SLAB_UNRECLAIMABLE);
+#else
+   lockedPages += global_page_state(NR_SLAB_UNRECLAIMABLE);
+#endif
+   /* NR_UNEVICTABLE moved from global to node in 4.8. */
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 8, 0)
-      global_page_state(NR_ANON_MAPPED);
+   lockedPages += global_node_page_state(NR_UNEVICTABLE);
 #else
-      global_page_state(NR_ANON_PAGES);
+   lockedPages += global_page_state(NR_UNEVICTABLE);
+#endif
+   /* NR_ANON_MAPPED moved & changed name in 4.8. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 8, 0)
+   anonPages = global_node_page_state(NR_ANON_MAPPED);
+#else
+   anonPages = global_page_state(NR_ANON_PAGES);
 #endif
-   unsigned int swapPages = BYTES_2_PAGES(linuxState.swapSize);
 
    if (anonPages > swapPages) {
       lockedPages += anonPages - swapPages; 
@@ -1664,6 +1676,49 @@
 /*
  *----------------------------------------------------------------------
  *
+ * HostIFGetTime --
+ *
+ *      Reads the current time in UPTIME_FREQ units.
+ *
+ * Results:
+ *      The uptime, in units of UPTIME_FREQ.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static uint64
+HostIFGetTime(void)
+{
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 0, 0)
+   struct timeval tv;
+
+   do_gettimeofday(&tv);
+   return tv.tv_usec * (UPTIME_FREQ / 1000000) + tv.tv_sec * UPTIME_FREQ;
+#else
+   struct timespec64 now;
+
+   /*
+    * Use raw time used by Posix timers.  This time is not affected by
+    * NTP adjustments, so it may drift from real time and monotonic time,
+    * but it will stay in sync with other timers.
+    */
+   ktime_get_raw_ts64(&now);
+   /*
+    * UPTIME_FREQ resolution is lower than tv_nsec,
+    * so we have to do division...
+    */
+   ASSERT_ON_COMPILE(1000000000 % UPTIME_FREQ == 0);
+   return now.tv_nsec / (1000000000 / UPTIME_FREQ) + now.tv_sec * UPTIME_FREQ;
+#endif
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
  * HostIFReadUptimeWork --
  *
  *      Reads the current uptime.  The uptime is based on getimeofday,
@@ -1692,16 +1747,12 @@
 static uint64
 HostIFReadUptimeWork(unsigned long *j)  // OUT: current jiffies 
 {
-   struct timeval tv;
    uint64 monotime, uptime, upBase, monoBase;
    int64 diff;
    uint32 version;
    unsigned long jifs, jifBase;
    unsigned int attempts = 0;
 
-   /* Assert that HostIF_InitUptime has been called. */
-   ASSERT(uptimeState.timer.function);
-
  retry:
    do {
       version  = VersionedAtomic_BeginTryRead(&uptimeState.version);
@@ -1710,13 +1761,12 @@
       monoBase = uptimeState.monotimeBase;
    } while (!VersionedAtomic_EndTryRead(&uptimeState.version, version));
 
-   do_gettimeofday(&tv);
+   uptime = HostIFGetTime();
    upBase = Atomic_Read64(&uptimeState.uptimeBase);
    
    monotime = (uint64)(jifs - jifBase) * (UPTIME_FREQ / HZ);
    monotime += monoBase;
 
-   uptime = tv.tv_usec * (UPTIME_FREQ / 1000000) + tv.tv_sec * UPTIME_FREQ;
    uptime += upBase;
    
    /* 
@@ -1767,7 +1804,7 @@ HostIFReadUptimeWork(unsigned long *j)  // OUT: current jiffies
  */
 
 static void
-HostIFUptimeResyncMono(unsigned long data)  // IN: ignored
+HostIFUptimeResyncMono(struct timer_list *timer)  // IN: ignored
 {
    unsigned long jifs;
    uintptr_t flags;
@@ -1821,16 +1871,19 @@
 void
 HostIF_InitUptime(void)
 {
-   struct timeval tv;
+   uint64 tm;
 
    uptimeState.jiffiesBase = jiffies;
-   do_gettimeofday(&tv);
-   Atomic_Write64(&uptimeState.uptimeBase, 
-                  -(tv.tv_usec * (UPTIME_FREQ / 1000000) + 
-                    tv.tv_sec * UPTIME_FREQ));
+   tm = HostIFGetTime();
+   Atomic_Write64(&uptimeState.uptimeBase, -tm);
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 15, 0) && !defined(timer_setup)
    init_timer(&uptimeState.timer);
-   uptimeState.timer.function = HostIFUptimeResyncMono;
+   uptimeState.timer.function = (void *)HostIFUptimeResyncMono;
+   uptimeState.timer.data = (unsigned long)&uptimeState.timer;
+#else
+   timer_setup(&uptimeState.timer, HostIFUptimeResyncMono, 0);
+#endif
    mod_timer(&uptimeState.timer, jiffies + HZ);
 }
 
@@ -2251,7 +2304,7 @@ isVAReadable(VA r)  // IN:
    int ret;
    
    old_fs = get_fs();
-   set_fs(get_ds());
+   set_fs(KERNEL_DS);
    r = APICR_TO_ADDR(r, APICR_VERSION);
    ret = HostIF_CopyFromUser(&dummy, (void*)r, sizeof(dummy));
    set_fs(old_fs);
@@ -2284,7 +2337,7 @@
    volatile void *hostapic;
 
    ASSERT_ON_COMPILE(APICR_SIZE <= PAGE_SIZE);
-   hostapic = (volatile void *) ioremap_nocache(ma, PAGE_SIZE);
+   hostapic = (volatile void *) ioremap(ma, PAGE_SIZE);
    if (hostapic) {
       if ((APIC_VERSIONREG(hostapic) & 0xF0) == 0x10) {
 	 vm->hostAPIC.base = (volatile uint32 (*)[4]) hostapic;
@@ -2452,7 +2505,7 @@ HostIF_SemaphoreWait(VMDriver *vm,   // IN:
    }
 
    old_fs = get_fs();
-   set_fs(get_ds());
+   set_fs(KERNEL_DS);
 
    {
       struct poll_wqueues table;
@@ -2581,7 +2634,7 @@ HostIF_SemaphoreSignal(uint64 *args)  // IN:
    }
 
    old_fs = get_fs();
-   set_fs(get_ds());
+   set_fs(KERNEL_DS);
 
    /*
     * Always write sizeof(uint64) bytes. This works fine for eventfd and
@@ -3524,7 +3577,6 @@ HostIF_SetFastClockRate(unsigned int rate) // IN: Frequency in Hz.
       }
    } else {
       if (linuxState.fastClockThread) {
-         force_sig(SIGKILL, linuxState.fastClockThread);
          kthread_stop(linuxState.fastClockThread);
 	 close_rtc(linuxState.fastClockFile, current->files);
 
@@ -3572,7 +3625,12 @@
 
    ASSERT(handle);
 
-   if (!access_ok(VERIFY_WRITE, p, size)) {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 0, 0)
+   if (!access_ok(VERIFY_WRITE, p, size))
+#else
+   if (!access_ok(p, size))
+#endif
+   {
       printk(KERN_ERR "%s: Couldn't verify write to uva 0x%p with size %"
              FMTSZ"u\n", __func__, p, size);
 
From 2da85cbe6d9c0bc5c7c2008748bd12e70ce0f310 Mon Sep 17 00:00:00 2001
From: Jan Andres <jandres@gmx.net>
Date: Fri, 4 Sep 2020 10:53:10 +0200
Subject: [PATCH] Fix NX bit handling for Linux 5.8+

Do not use vmap() to map the cross page, it needs to be executable and
vmap() unconditionally sets the NX bit starting with 5.8.x.

Emulate previous behavior of vmap() by using alloc_vm_area() and
explicitly setting the PTE.
---
 vmmon-only/linux/hostif.c | 18 ++++++++++++++++++
 1 file changed, 18 insertions(+)

diff --git a/vmmon-only/linux/hostif.c b/vmmon-only/linux/hostif.c
index 3a48505..ec6856a 100644
--- a/vmmon-only/linux/hostif.c
+++ b/vmmon-only/linux/hostif.c
@@ -68,6 +68,7 @@
 #endif
 
 #include <asm/io.h>
+#include <asm/tlbflush.h>
 #include <asm/uaccess.h>
 #include <linux/mc146818rtc.h>
 #include <linux/capability.h>
@@ -695,7 +696,24 @@ HostIF_FastClockUnlock(int callerID) // IN
 static void *
 MapCrossPage(struct page *p)  // IN:
 {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
    return vmap(&p, 1, VM_MAP, VM_PAGE_KERNEL_EXEC);
+#else
+   /* Starting with 5.8, vmap() always sets the NX bit, but the cross
+    * page needs to be executable. */
+   pte_t *ptes[1];
+   struct vm_struct *area = alloc_vm_area(1UL << PAGE_SHIFT, ptes);
+   if (area == NULL)
+      return NULL;
+
+   set_pte(ptes[0], mk_pte(p, VM_PAGE_KERNEL_EXEC));
+
+   preempt_disable();
+   __flush_tlb_all();
+   preempt_enable();
+
+   return area->addr;
+#endif
 }
 
 
From c71e377757f20dc78a99d42a127124bb2c49e865 Mon Sep 17 00:00:00 2001
From: Jan Andres <jandres@gmx.net>
Date: Fri, 4 Sep 2020 10:59:19 +0200
Subject: [PATCH] Fix NULL pointer dereference in eventfd read call

Starting with 5.8, the "read" function pointer in eventfd's
file_operations is NULL, "read_iter" is available instead.

Use kernel_read() and kernel_write() instead of directly calling the
function pointers to handle this correctly.
---
 vmmon-only/linux/hostif.c | 8 ++++++++
 1 file changed, 8 insertions(+)

diff --git a/vmmon-only/linux/hostif.c b/vmmon-only/linux/hostif.c
index ec6856a..4a7afb1 100644
--- a/vmmon-only/linux/hostif.c
+++ b/vmmon-only/linux/hostif.c
@@ -2547,7 +2547,11 @@ HostIF_SemaphoreWait(VMDriver *vm,   // IN:
     * reading no bytes (EAGAIN - non blocking fd) or sizeof(uint64).
     */
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 8, 0)
+   res = kernel_read(file, (char *) &value, sizeof value, &file->f_pos);
+#else
    res = file->f_op->read(file, (char *) &value, sizeof value, &file->f_pos);
+#endif
 
    if (res == sizeof value) {
       res = MX_WAITNORMAL;
@@ -2660,7 +2664,11 @@ HostIF_SemaphoreSignal(uint64 *args)  // IN:
     * it be present.
     */
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 8, 0)
+   res = kernel_write(file, (char *) &value, sizeof value, &file->f_pos);
+#else
    res = file->f_op->write(file, (char *) &value, sizeof value, &file->f_pos);
+#endif
 
    if (res == sizeof value) {
       res = MX_WAITNORMAL;
