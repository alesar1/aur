diff --git a/.circleci/build.sh b/.circleci/build.sh
index 3b1bbaa..67a0e7b 100755
--- a/.circleci/build.sh
+++ b/.circleci/build.sh
@@ -8,7 +8,10 @@ VERSION=$(head -10 "${ROOT}/__init__.py" | grep -o 'version.: *(.*)' | tr ',' '.
 
 DEV_VER=''
 if [ "x$(head -10 "${ROOT}/__init__.py" | grep -o 'warning.: *.dev')" != 'x' ]; then
-    DEV_VER="-$(git -C "${ROOT}" rev-parse --short HEAD)"
+    # Mark development version with hash to not confuse with the logs
+    GIT_HASH=$(git -C "${ROOT}" rev-parse --short HEAD)
+    sed -i "0,/'development version'/{s/'development version'/'dev-${GIT_HASH}'/}" "${ROOT}/__init__.py"
+    DEV_VER="-${GIT_HASH}"
 fi
 
 echo "INFO: BlendNet version: $VERSION$DEV_VER"
diff --git a/.circleci/config.yml b/.circleci/config.yml
index eaae11c..518fdfb 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -1,15 +1,27 @@
 version: 2.1
 
+orbs:
+  win: circleci/windows@2.4.0
+
 workflows:
   build_and_test:
     jobs:
       - build
       - blendnet_test:
           blender_version: "2.80" # The first one supported
+          requires:
+            - build
       - blendnet_test:
           blender_version: lts
+          requires:
+            - build
       - blendnet_test:
           blender_version: latest # Latest release available
+          requires:
+            - build
+      - blendnet_test_win:
+          requires:
+            - build
 
   nightly_test:
     triggers:
@@ -83,7 +95,6 @@ jobs:
           name: Run blendnet-agent-1
           background: true
           command: |
-            # Run Agent for max 10 minutes
             docker run --name blendnet-agent-1 -m 2G --rm -it \
                 --volumes-from blendnet-srv ubuntu:20.04 \
                 /srv/workspace/test_run_service.sh agent 2>&1 | tee results/agent-1.log || true
@@ -98,7 +109,6 @@ jobs:
           name: Run blendnet-agent-2
           background: true
           command: |
-            # Run Agent for max 10 minutes
             docker run --name blendnet-agent-2 -m 2G --rm -it \
                 --volumes-from blendnet-srv ubuntu:20.04 \
                 /srv/workspace/test_run_service.sh agent 2>&1 | tee results/agent-2.log || true
@@ -118,7 +128,6 @@ jobs:
             # Wait for blendnet-agent-2 container
             while ! docker ps | grep blendnet-agent-2; do echo "waiting agent-2"; docker ps; sleep 1; done
 
-            # Run Manager for max 10 minutes
             docker run --name blendnet-manager -m 2G --rm -it \
                 --link blendnet-agent-1:blendnet-agent-1-host \
                 --link blendnet-agent-2:blendnet-agent-2-host \
@@ -168,3 +177,137 @@ jobs:
       - store_artifacts:
           path: results
           destination: results
+
+
+  blendnet_test_win:
+    executor:
+      name: win/default
+
+    steps:
+      - checkout:
+          path: blendnet
+
+      - run:
+          name: Preparing to the test execution
+          command: |
+            blendnet\.circleci\test_prepare.ps1
+
+            # Put addon to the proper place
+            mkdir -p scripts/addons
+            cp -r blendnet scripts/addons/
+            # Create the results dir
+            mkdir results
+          no_output_timeout: 5m
+
+      - run:
+          name: Run blendnet-agent-1
+          background: true
+          command: |
+            cp -r workspace agent-1
+            cd agent-1
+            echo '{"listen_host": "127.0.1.1"}' | Out-File -Encoding ASCII agent.json
+
+            ..\blender\blender.exe -b -noaudio -P ..\scripts\addons\blendnet\agent.py 2>&1 | tee -filepath ..\results\agent-1.log
+
+            cd ..
+            echo "Check exceptions in the log"
+            $result = cat results\agent-1.log | Select-String -Pattern '^Traceback'
+            if ($result -ne $null) {
+                echo "Found exceptions in the agent-1 log: $result"
+                exit 1
+            }
+            echo "Check errors in the log"
+            $result = cat results\agent-1.log | Select-String -Pattern '^ERROR: '
+            if ($result -ne $null) {
+                echo "Found errors in the agent-1 log: $result"
+                exit 2
+            }
+            $result = cat results\agent-1.log | Select-String -Pattern '^Fatal Python error: '
+            if ($result -ne $null) {
+                echo "Found errors in the agent-1 log: $result"
+                exit 3
+            }
+
+      - run:
+          name: Run blendnet-agent-2
+          background: true
+          command: |
+            cp -r workspace agent-2
+            cd agent-2
+            echo '{"listen_host": "127.0.1.2"}' | Out-File -Encoding ASCII agent.json
+
+            ..\blender\blender.exe -b -noaudio -P ..\scripts\addons\blendnet\agent.py 2>&1 | tee -filepath ..\results\agent-2.log
+
+            cd ..
+            echo "Check exceptions in the log"
+            $result = cat results\agent-2.log | Select-String -Pattern '^Traceback'
+            if ($result -ne $null) {
+                echo "Found exceptions in the agent-2 log: $result"
+                exit 1
+            }
+            echo "Check errors in the log"
+            $result = cat results\agent-2.log | Select-String -Pattern '^ERROR: '
+            if ($result -ne $null) {
+                echo "Found errors in the agent-2 log: $result"
+                exit 2
+            }
+            $result = cat results\agent-2.log | Select-String -Pattern '^Fatal Python error: '
+            if ($result -ne $null) {
+                echo "Found errors in the agent-2 log: $result"
+                exit 3
+            }
+
+      - run:
+          name: Run blendnet-manager
+          background: true
+          command: |
+            # Adding resolve paths for the agents
+            Add-Content -Path "$env:windir\System32\drivers\etc\hosts" -Value "127.0.1.1`tblendnet-agent-1-host" -Force
+            Add-Content -Path "$env:windir\System32\drivers\etc\hosts" -Value "127.0.1.2`tblendnet-agent-2-host" -Force
+
+            cp -r workspace manager
+            cd manager
+            ..\blender\blender.exe -b -noaudio -P ..\scripts\addons\blendnet\manager.py 2>&1 | tee -filepath ..\results\manager.log
+
+            cd ..
+            echo "Check exceptions in the log"
+            $result = cat results\manager.log | Select-String -Pattern '^Traceback'
+            if ($result -ne $null) {
+                echo "Found exceptions in the manager log: $result"
+                exit 1
+            }
+            echo "Check errors in the log"
+            $result = cat results\manager.log | Select-String -Pattern '^ERROR: '
+            if ($result -ne $null) {
+                echo "Found errors in the manager log: $result"
+                exit 2
+            }
+            $result = cat results\manager.log | Select-String -Pattern '^Fatal Python error: '
+            if ($result -ne $null) {
+                echo "Found errors in the manager log: $result"
+                exit 3
+            }
+
+      - run:
+          name: Run Addon test
+          command: |
+            Add-Content -Path "$env:windir\System32\drivers\etc\hosts" -Value "127.0.0.1`tblendnet-manager-host" -Force
+            blendnet\.circleci\test_execute_addon.ps1
+
+      - run:
+          name: Stop the running blender processes
+          when: always
+          command: |
+            # TODO: when BN-64 is completed - stop Manager and Agents properly
+            Stop-Process -Name "blender"
+            sleep 1
+            Stop-Process -Name "blender" -Force
+            sleep 10
+
+      # TODO: Add test results
+      #- store_test_results:
+      #    path: results/reports
+
+      - store_artifacts:
+          path: results
+          destination: results
diff --git a/.circleci/test_execute_addon.ps1 b/.circleci/test_execute_addon.ps1
new file mode 100644
index 0000000..e7e3ab7
--- /dev/null
+++ b/.circleci/test_execute_addon.ps1
@@ -0,0 +1,53 @@
+# Runs the actual test on win platform
+
+# Wait till the Manager service will be started
+$counter = 0
+do {
+    if ( $counter -gt 30 ) {
+        echo "Reached maximum retries ($i)"
+        exit 1
+    }
+    $counter = $counter+1
+    Write-Host "waiting ($counter)..."
+    sleep 2
+} until(Test-NetConnection "blendnet-manager-host" -Port 8443 | ? { $_.TcpTestSucceeded } )
+
+$results_dir = 'results\addon'
+mkdir -p $results_dir
+
+$env:BLENDER_USER_SCRIPTS = "$pwd\scripts"
+blender\blender.exe -b -noaudio test-project\proj\test-project.blend -P blendnet\.circleci\test_script_addon.py 2>&1 | tee -filepath "$results_dir\addon.log"
+
+$remote_file = cat "$results_dir\addon.log" | Select-String -Pattern '^DATA: CI: ' | ForEach-Object { $_.ToString().split(' ', 3)[-1] }
+if ($remote_file -eq $null) {
+    echo "Not found the compose filepath in the test script output"
+    exit 1
+}
+
+cp "$remote_file" "$results_dir"
+
+echo "Check compose file size"
+if ( (Get-Item $remote_file).length -lt 540*1024 ) {
+    echo "File size is less then 540KB"
+    exit 2
+}
+
+echo "Check exceptions in the log"
+$result = cat "$results_dir\addon.log" | Select-String -Pattern '^Traceback'
+if ($result -ne $null) {
+    echo "Found exceptions in the addon log: $result"
+    exit 3
+}
+echo "Check errors in the log"
+$result = cat "$results_dir\addon.log" | Select-String -Pattern '^ERROR: '
+if ($result -ne $null) {
+    echo "Found errors in the addon log: $result"
+    exit 4
+}
+$result = cat "$results_dir\addon.log" | Select-String -Pattern '^Fatal Python error: '
+if ($result -ne $null) {
+    echo "Found errors in the addon log: $result"
+    exit 5
+}
+
+echo "Addon Compose image is received"
diff --git a/.circleci/test_execute_api.sh b/.circleci/test_execute_api.sh
index 9bbb501..a1a09af 100755
--- a/.circleci/test_execute_api.sh
+++ b/.circleci/test_execute_api.sh
@@ -39,8 +39,8 @@ docker exec blendnet-executor curl --user 'None:None' --insecure --silent -X PUT
 
 # Uploading the required task dependencies
 docker exec blendnet-executor /bin/sh -c '
-cd /workspace/test-project
-for f in $(find . -type f -name "*0032*") tex/* test-project.blend; do
+cd /workspace
+for f in $(find /workspace/test-project/proj test-project/ext -type f -name "*0032*") test-project/ext/tex/* test-project/proj/test-project.blend; do
     curl --user "None:None" --insecure \
         --header "X-Checksum-Sha1:$(sha1sum "${f}" | cut -d " " -f 1)" \
         --upload-file "${f}" "https://blendnet-manager-host:8443/api/v1/task/test-task-1/file/${f}"
@@ -49,7 +49,7 @@ done
 
 # Configure the task (render-ci and compose-ci uses 23 samples)
 docker exec blendnet-executor curl --user 'None:None' --insecure --silent -X PUT \
-    -d '{"samples": 23, "project": "test-project.blend", "frame": 32}' \
+    -d '{"samples": 23, "compose_filepath": "newout-32.png", "project": "test-project.blend", "frame": 32, "project_path": "/workspace/test-project/proj", "cwd_path": "/workspace"}' \
     "https://blendnet-manager-host:8443/api/v1/task/test-task-1/config"
 
 # Run the task execution
@@ -80,7 +80,7 @@ file "${render_file}" | grep -q 'compression: zip' # Compression is lossless
 if [ "${BLENDER_VERSION}" = '2.80' ]; then
     [ $(stat --format '%s' "${render_file}") -gt $((2*1024*1024)) ] # Render EXR size > 2MB
 else
-    [ $(stat --format '%s' "${render_file}") -gt $((14*1024*1024)) ] # Render EXR size > 14MB
+    [ $(stat --format '%s' "${render_file}") -gt $((5*1024*1024)) ] # Render EXR size > 5MB
 fi
 
 # Watch the task execution and save compose
diff --git a/.circleci/test_prepare.ps1 b/.circleci/test_prepare.ps1
new file mode 100644
index 0000000..52f81c7
--- /dev/null
+++ b/.circleci/test_prepare.ps1
@@ -0,0 +1,41 @@
+# PowerShell script to prepare the windows env
+
+echo "Prepare the environment to execute tests"
+$global:ProgressPreference = "SilentlyContinue" # For Expand-Archive
+$wc = [System.Net.WebClient]::new()
+
+echo "Download the blender dist"
+$disturl = 'https://download.blender.org/release/Blender2.90/blender-2.90.0-windows64.zip'
+$disthash = 'f51e1c33f6c61bdef86008280173e4c5cf9c52e4f5c490e9a7e4db3a355639bc'
+$wc.DownloadFile($disturl, "blender-dist.zip")
+$FileHash = Get-FileHash blender-dist.zip -Algorithm SHA256
+$FileHash.Hash -eq $disthash
+echo "Unpack dist..."
+Expand-Archive blender-dist.zip
+mv blender-dist\* blender
+
+echo "Download the openssl dist"
+$disturl = 'https://curl.se/windows/dl-7.80.0_2/openssl-3.0.1_2-win64-mingw.zip'
+$disthash = 'd19096170fc47ac0284077b9a925b83cd6f4ed0268fbb54cd6de171cd0735c1d'
+$wc.DownloadFile($disturl, "openssl-dist.zip")
+$FileHash = Get-FileHash openssl-dist.zip -Algorithm SHA256
+$FileHash.Hash -eq $disthash
+echo "Unpack dist..."
+Expand-Archive openssl-dist.zip
+mv openssl-dist\* openssl
+
+echo "Create the template workspace & prepare certificates"
+mkdir workspace
+openssl\bin\openssl.exe req -x509 -nodes -newkey rsa:4096 `
+    -keyout workspace\server.key -out workspace\server.crt `
+    -days 365 -subj "/C=US/ST=N/L=N/O=N/OU=N/CN=blendnet-service" `
+    -config .\openssl\ssl\openssl.cnf
+# Required ca.crt for Manager
+cp workspace\server.crt workspace\ca.crt
+
+echo "Download the test project"
+$disturl = 'https://github.com/state-of-the-art/BlendNet-test-project/archive/v2.82-v0.4.zip'
+$wc.DownloadFile($disturl, "test-project-dist.zip")
+echo "Unpack dist..."
+Expand-Archive test-project-dist.zip
+mv test-project-dist\* test-project
diff --git a/.circleci/test_prepare.sh b/.circleci/test_prepare.sh
index 3b684f0..4448aae 100755
--- a/.circleci/test_prepare.sh
+++ b/.circleci/test_prepare.sh
@@ -7,7 +7,7 @@ BLENDER_VERSION=$1
 ROOT=$(dirname "$0")/..
 
 # Find the required blender version
-python3 "${ROOT}/BlendNet/list_blender_versions.py" "${BLENDER_VERSION}" | tee /tmp/blender_versions.txt
+python3 "${ROOT}/BlendNet/list_blender_versions.py" 'lin' "${BLENDER_VERSION}" | tee /tmp/blender_versions.txt
 ver_line=$(grep '^DATA:' /tmp/blender_versions.txt | head -1)
 rm -f /tmp/blender_versions.txt
 version=$(echo "${ver_line}" | cut -d" " -f2)
@@ -38,15 +38,15 @@ cp -a "${ROOT}/.circleci/test_run_service.sh" workspace
 cp -a "${ROOT}/.circleci/test_script_addon.py" workspace
 
 # Download the test project
-testproject_url='https://github.com/state-of-the-art/BlendNet/wiki/files/blendnet-test-project'
+testproject_url='https://github.com/state-of-the-art/BlendNet-test-project/archive/'
 # (not perfect but simple & working for current CI)
 if [ "${BLENDER_VERSION}" = '2.80' ]; then
-    testproject_url="${testproject_url}-2.80"
+    testproject_url="${testproject_url}v2.80"
 else
-    testproject_url="${testproject_url}-2.82"
+    testproject_url="${testproject_url}v2.82"
 fi
-testproject_url="${testproject_url}-v0.3.zip"
+testproject_url="${testproject_url}-v0.4.zip"
 
 curl -fLo test-project.zip "${testproject_url}"
 unzip -d workspace test-project.zip
-mv workspace/blendnet-test-project* workspace/test-project
+mv workspace/BlendNet-test-project* workspace/test-project
diff --git a/.circleci/test_run_service.sh b/.circleci/test_run_service.sh
index e4fb51b..adbe624 100755
--- a/.circleci/test_run_service.sh
+++ b/.circleci/test_run_service.sh
@@ -16,7 +16,7 @@ apt install --no-install-recommends -y libxrender1 libxi6 libgl1
 
 if [ "${SVC}" = "addon" ]; then
     export BLENDER_USER_SCRIPTS=/srv/scripts
-    /srv/blender/blender -b -noaudio test-project/test-project.blend -P /srv/workspace/test_script_addon.py
+    /srv/blender/blender -b -noaudio test-project/proj/test-project.blend -P /srv/workspace/test_script_addon.py
 else
     /srv/blender/blender -b -noaudio -P /srv/scripts/addons/blendnet/${SVC}.py
 fi
diff --git a/.circleci/test_script_addon.py b/.circleci/test_script_addon.py
index 1363bdf..6ebb207 100644
--- a/.circleci/test_script_addon.py
+++ b/.circleci/test_script_addon.py
@@ -17,7 +17,7 @@ prefs.resource_provider = 'local'
 print('INFO: CI: Using provider:', prefs.resource_provider)
 
 prefs.manager_address = 'blendnet-manager-host' # Using presetup docker container DN
-prefs.manager_ca_path = '/srv/workspace/ca.crt'
+prefs.manager_ca_path = os.path.abspath('workspace/ca.crt')
 prefs.manager_user = 'None'
 prefs.manager_password = 'None'
 
@@ -28,6 +28,16 @@ print('INFO: CI: Setup scene')
 scene = bpy.context.scene
 scene.render.engine = 'CYCLES'
 
+# Override the absolute path of the used images
+for img in bpy.data.images:
+    img.filepath = img.filepath.replace(
+            '/home/user/Work/state-of-the-art/BlendNet-test-project',
+            os.path.abspath(bpy.path.abspath('//..')), 1)
+    # In windows it looks different
+    img.filepath = img.filepath.replace(
+            '/home\\user\\Work\\state-of-the-art\\BlendNet-test-project',
+            os.path.abspath(bpy.path.abspath('//..')), 1)
+
 # Set the number of samples to CI level
 scene.cycles.samples = 23
 scene.cycles.aa_samples = 23
diff --git a/.github/ISSUE_TEMPLATE/bug_report.md b/.github/ISSUE_TEMPLATE/bug_report.md
index a30db61..1d7f8b1 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.md
+++ b/.github/ISSUE_TEMPLATE/bug_report.md
@@ -8,6 +8,8 @@ assignees: ''
 ---
 
 ### Issue description:
+If it's a question - it's better to ask here: https://gitter.im/state-of-the-art/BlendNet
+
 A clear and concise description of what the bug is.
 
 ### Environment:
@@ -31,4 +33,5 @@ A clear and concise description of what you expected to happen.
 If applicable, add screenshots to help explain your problem.
 
 ### Additional context
-Add any other context about the problem here.
+Please check https://github.com/state-of-the-art/BlendNet/wiki/If-you-stuck-with-an-issue to attach
+some useful logs here.
diff --git a/.github/ISSUE_TEMPLATE/feature_request.md b/.github/ISSUE_TEMPLATE/feature_request.md
index 52ceb39..b45f480 100644
--- a/.github/ISSUE_TEMPLATE/feature_request.md
+++ b/.github/ISSUE_TEMPLATE/feature_request.md
@@ -8,6 +8,8 @@ assignees: ''
 ---
 
 ### Is your feature request related to a problem? Please describe.
+If it's a question - it's better to ask here: https://gitter.im/state-of-the-art/BlendNet
+
 A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]
 
 ### Describe the solution you'd like
diff --git a/.github/actions/blendnet-test-linux/action.yml b/.github/actions/blendnet-test-linux/action.yml
new file mode 100644
index 0000000..6abe1a3
--- /dev/null
+++ b/.github/actions/blendnet-test-linux/action.yml
@@ -0,0 +1,38 @@
+name: BlendNet Test Linux
+description: Runs test on linux with the specified blender version
+inputs:
+  blender_version:
+    required: true
+    description: |
+      Blender version to use
+      * <version> - exact version you need
+      * lts    - latest available LTS version
+      * latest - latest available version
+runs:
+  using: composite
+  steps:
+    - name: Preparing to the test execution
+      shell: bash
+      run: |
+        $GITHUB_ACTION_PATH/test_prepare.sh "${{ inputs.blender_version }}"
+        # Creating the docker container to store the data
+        docker create -v /srv --name blendnet-srv alpine /bin/true
+        mkdir -p scripts/addons
+        cp -a blendnet scripts/addons
+        docker cp scripts blendnet-srv:/srv
+        docker cp blender blendnet-srv:/srv
+        docker cp workspace blendnet-srv:/srv
+        mkdir -p results
+
+    - name: Run Addon test
+      shell: bash
+      run: $GITHUB_ACTION_PATH/test_execute_addon.sh "${{ inputs.blender_version }}" || exit 1
+
+    - name: Run API test
+      shell: bash
+      run: $GITHUB_ACTION_PATH/test_execute_api.sh "${{ inputs.blender_version }}" || exit 1
+
+    - name: Clean
+      shell: bash
+      run: |
+        docker rm -f blendnet-srv || true
diff --git a/.github/actions/blendnet-test-linux/test_execute_addon.sh b/.github/actions/blendnet-test-linux/test_execute_addon.sh
new file mode 100755
index 0000000..0c120e8
--- /dev/null
+++ b/.github/actions/blendnet-test-linux/test_execute_addon.sh
@@ -0,0 +1,56 @@
+#!/bin/sh -xe
+# Runs the actual test
+
+BLENDER_VERSION=$1
+[ "${BLENDER_VERSION}" != '' ] || exit 1
+
+ROOT=$(dirname "$0")/../../..
+
+# Run Agents & Manager containers
+"${ROOT}/.github/actions/blendnet-test-linux/test_run_agent.sh" addon 1 &
+"${ROOT}/.github/actions/blendnet-test-linux/test_run_agent.sh" addon 2 &
+"${ROOT}/.github/actions/blendnet-test-linux/test_run_manager.sh" addon &
+
+# Wait for blendnet-manager container
+while ! docker ps | grep blendnet-manager; do echo "waiting manager"; docker ps; sleep 1; done
+
+echo "Docker containers are running"
+docker ps
+
+results_dir=results/addon
+mkdir -p "${results_dir}"
+
+# Run the execution of BlendNet Addon test script
+docker run --name blendnet-executor -m 1G -i \
+    --link blendnet-manager:blendnet-manager-host \
+    --volumes-from blendnet-srv \
+    ubuntu:20.04 /srv/workspace/test_run_service.sh addon 2>&1 | tee "${results_dir}/addon.log" || true
+
+# Stop the Agents & Manager
+# TODO: when BN-64 is completed - stop Manager and Agents properly
+docker rm -f blendnet-manager || true
+docker rm -f blendnet-agent-1 || true
+docker rm -f blendnet-agent-2 || true
+
+# Check existing of the path in the log
+grep --text 'DATA: CI:' "${results_dir}/addon.log"
+
+# Copy the compose file to results
+remote_file="$(grep --text 'DATA: CI:' "${results_dir}/addon.log" | cut -d' ' -f3-)"
+docker cp "blendnet-executor:${remote_file}" "${results_dir}"
+docker rm -f blendnet-executor || true
+
+compose_file="${results_dir}/$(basename ${remote_file})"
+[ -f "${compose_file}" ] # Compose file exists
+ls -lh "${compose_file}"
+file "${compose_file}"
+file "${compose_file}" | grep -q 'PNG image data' # It's PNG format
+file "${compose_file}" | grep -q '1280 x 720' # Resolution is ok
+file "${compose_file}" | grep -q '8-bit/color RGB' # Color is encoded properly
+[ $(stat --format '%s' "${compose_file}") -gt $((540*1024)) ] # Compose PNG size > 540KB
+
+grep '^Traceback' "${results_dir}/addon.log" && exit 1 || echo "ok - no exceptions in ${results_dir}/addon.log"
+grep '^ERROR: ' "${results_dir}/addon.log" && exit 2 || echo "ok - no errors in ${results_dir}/addon.log"
+grep '^Fatal Python error: ' "${results_dir}/addon.log" && exit 3 || echo "ok - no python errors in ${results_dir}/addon.log"
+
+echo "Addon Compose images are received"
diff --git a/.github/actions/blendnet-test-linux/test_execute_api.sh b/.github/actions/blendnet-test-linux/test_execute_api.sh
new file mode 100755
index 0000000..9d86ae5
--- /dev/null
+++ b/.github/actions/blendnet-test-linux/test_execute_api.sh
@@ -0,0 +1,124 @@
+#!/bin/sh -xe
+# Runs the actual test
+
+BLENDER_VERSION=$1
+[ "${BLENDER_VERSION}" != '' ] || exit 1
+
+ROOT=$(dirname "$0")/../../..
+
+# Run Agents & Manager containers
+"${ROOT}/.github/actions/blendnet-test-linux/test_run_agent.sh" api 1 &
+"${ROOT}/.github/actions/blendnet-test-linux/test_run_agent.sh" api 2 &
+"${ROOT}/.github/actions/blendnet-test-linux/test_run_manager.sh" api &
+
+# Wait for blendnet-manager container
+while ! docker ps | grep blendnet-manager; do echo "waiting manager"; docker ps; sleep 1; done
+
+docker run --name blendnet-executor -m 1G -i -d \
+    --link blendnet-manager:blendnet-manager-host \
+    --volumes-from blendnet-srv ubuntu:20.04 /bin/sleep 3600 || true
+
+# Wait for blendnet-executor container
+while ! docker ps | grep blendnet-executor; do echo "waiting executor"; docker ps; sleep 1; done
+
+# There is no direct access to the Manager port, so using it to run required commands
+# Install curl and unzip to the Manager
+docker exec blendnet-executor /bin/sh -c 'apt update; apt install -y curl unzip'
+echo "Docker containers are running"
+
+docker ps
+
+for retry in $(seq 1 10); do
+    sleep 5
+    echo "Check ${retry}"
+    docker exec blendnet-executor curl --user 'None:None' --insecure --max-time 5 --silent \
+        "https://blendnet-manager-host:8443/api/v1/status" || continue
+    echo "Looks like connected to blendnet-manager"
+    break
+done
+
+# Add the Agents to the Manager
+docker exec blendnet-executor curl --user 'None:None' --insecure --silent -X PUT \
+    "https://blendnet-manager-host:8443/api/v1/agent/agent-1/config" \
+    --data '{"address": "blendnet-agent-1-host", "port": 9443, "auth_user": "None", "auth_password": "None"}'
+docker exec blendnet-executor curl --user 'None:None' --insecure --silent -X PUT \
+    "https://blendnet-manager-host:8443/api/v1/agent/agent-2/config" \
+    --data '{"address": "blendnet-agent-2-host", "port": 9443, "auth_user": "None", "auth_password": "None"}'
+
+# Uploading the required task dependencies
+docker exec blendnet-executor /bin/sh -c '
+cd /srv/workspace
+for f in $(find /srv/workspace/test-project/proj test-project/ext -type f -name "*0032*") test-project/ext/tex/* test-project/proj/test-project.blend; do
+    curl --user "None:None" --insecure \
+        --header "X-Checksum-Sha1:$(sha1sum "${f}" | cut -d " " -f 1)" \
+        --upload-file "${f}" "https://blendnet-manager-host:8443/api/v1/task/test-task-1/file/${f}"
+done
+'
+
+# Configure the task (render-ci and compose-ci uses 23 samples)
+docker exec blendnet-executor curl --user 'None:None' --insecure --silent -X PUT \
+    -d '{"samples": 23, "compose_filepath": "newout-32.png", "project": "test-project.blend", "frame": 32, "project_path": "/srv/workspace/test-project/proj", "cwd_path": "/srv/workspace"}' \
+    "https://blendnet-manager-host:8443/api/v1/task/test-task-1/config"
+
+# Run the task execution
+docker exec blendnet-executor curl --user 'None:None' --insecure --silent \
+    "https://blendnet-manager-host:8443/api/v1/task/test-task-1/run"
+
+results_dir=results/api
+mkdir -p "${results_dir}"
+
+# Watch the task execution and save render
+for retry in $(seq 1 50); do
+    sleep 5
+    echo "Check task render ${retry}"
+    r=$(docker exec blendnet-executor curl --user 'None:None' --insecure --silent \
+        "https://blendnet-manager-host:8443/api/v1/task/test-task-1/status")
+    [ "$(echo "${r}" | jq -r '.data.result.render')" != "null" ] || continue
+    docker exec blendnet-executor curl --user 'None:None' --insecure --output - --silent \
+        "https://blendnet-manager-host:8443/api/v1/task/test-task-1/status/result/render" > "${results_dir}/render.exr"
+    break
+done
+
+render_file="${results_dir}/render.exr"
+[ -f "${render_file}" ] # Render file exists
+ls -lh "${render_file}"
+file "${render_file}"
+file "${render_file}" | grep -q 'OpenEXR image data' # It's EXR format
+file "${render_file}" | grep -q 'compression: zip' # Compression is lossless
+if [ "${BLENDER_VERSION}" = '2.80' ]; then
+    [ $(stat --format '%s' "${render_file}") -gt $((2*1024*1024)) ] # Render EXR size > 2MB
+else
+    [ $(stat --format '%s' "${render_file}") -gt $((5*1024*1024)) ] # Render EXR size > 5MB
+fi
+
+# Watch the task execution and save compose
+fn='notexist'
+for retry in $(seq 1 10); do
+    sleep 5
+    echo "Check task compose ${retry}"
+    r=$(docker exec blendnet-executor curl --user 'None:None' --insecure --silent \
+        "https://blendnet-manager-host:8443/api/v1/task/test-task-1/status")
+    [ "$(echo "${r}" | jq -r '.data.result.compose')" != "null" ] || continue
+    fn=$(echo "${r}" | jq -r '.data.compose_filepath')
+    docker exec blendnet-executor curl --user 'None:None' --insecure --output - --silent \
+        "https://blendnet-manager-host:8443/api/v1/task/test-task-1/status/result/compose" > "${results_dir}/$(basename "${fn}")"
+    break
+done
+
+# Stop the Agents & Manager
+# TODO: when BN-64 is completed - stop Manager and Agents properly
+docker rm -f blendnet-executor || true
+docker rm -f blendnet-manager || true
+docker rm -f blendnet-agent-1 || true
+docker rm -f blendnet-agent-2 || true
+
+compose_file="${results_dir}/$(basename ${fn})"
+[ -f "${compose_file}" ] # Compose file exists
+ls -lh "${compose_file}"
+file "${compose_file}"
+file "${compose_file}" | grep -q 'PNG image data' # It's PNG format
+file "${compose_file}" | grep -q '1280 x 720' # Resolution is ok
+file "${compose_file}" | grep -q '8-bit/color RGB' # Color is encoded properly
+[ $(stat --format '%s' "${compose_file}") -gt $((540*1024)) ] # Compose PNG size > 540KB
+
+echo "Render & Compose images are received"
diff --git a/.github/actions/blendnet-test-linux/test_prepare.sh b/.github/actions/blendnet-test-linux/test_prepare.sh
new file mode 100755
index 0000000..52a5187
--- /dev/null
+++ b/.github/actions/blendnet-test-linux/test_prepare.sh
@@ -0,0 +1,52 @@
+#!/bin/sh -xe
+# Prepares the necessary resources to run the tests
+
+BLENDER_VERSION=$1
+[ "${BLENDER_VERSION}" != '' ] || exit 1
+
+ROOT=$(dirname "$0")/../../..
+
+# Find the required blender version
+python3 "${ROOT}/BlendNet/list_blender_versions.py" 'lin' "${BLENDER_VERSION}" | tee /tmp/blender_versions.txt
+ver_line=$(grep '^DATA:' /tmp/blender_versions.txt | head -1)
+rm -f /tmp/blender_versions.txt
+version=$(echo "${ver_line}" | cut -d" " -f2)
+checksum=$(echo "${ver_line}" | cut -d" " -f3)
+url=$(echo "${ver_line}" | cut -d" " -f4-)
+
+[ "${version}" != '' ] || exit 2
+[ "${checksum}" != '' ] || exit 3
+[ "${url}" != '' ] || exit 4
+
+# Download the blender archive and unpack it
+out_archive=/tmp/$(basename "${url}")
+echo "${checksum} -" > sum.txt
+curl -fLs "${url}" | tee "${out_archive}" | sha256sum -c sum.txt
+rm -f sum.txt
+mkdir -p blender
+tar -C blender --strip-components=1 --checkpoint=10000 --checkpoint-action=echo='Unpacked %{r}T' -xf "${out_archive}"
+rm -f "${out_archive}"
+
+# Create the initial workspace
+mkdir -p workspace
+openssl req -x509 -nodes -newkey rsa:4096 \
+    -keyout workspace/server.key -out workspace/server.crt \
+    -days 365 -subj "/C=US/ST=N/L=N/O=N/OU=N/CN=blendnet-service"
+# Required ca.crt for Manager
+cp workspace/server.crt workspace/ca.crt
+cp -a "${ROOT}/.github/actions/blendnet-test-linux/test_run_service.sh" workspace
+cp -a "${ROOT}/.github/scripts/test_script_addon.py" workspace
+
+# Download the test project
+testproject_url='https://github.com/state-of-the-art/BlendNet-test-project/archive/'
+# (not perfect but simple & working for current CI)
+if [ "${BLENDER_VERSION}" = '2.80' ]; then
+    testproject_url="${testproject_url}v2.80"
+else
+    testproject_url="${testproject_url}v2.82"
+fi
+testproject_url="${testproject_url}-v0.4.zip"
+
+curl -fLo test-project.zip "${testproject_url}"
+unzip -d workspace test-project.zip
+mv workspace/BlendNet-test-project* workspace/test-project
diff --git a/.github/actions/blendnet-test-linux/test_run_agent.sh b/.github/actions/blendnet-test-linux/test_run_agent.sh
new file mode 100755
index 0000000..c05f1f3
--- /dev/null
+++ b/.github/actions/blendnet-test-linux/test_run_agent.sh
@@ -0,0 +1,16 @@
+#!/bin/sh -xe
+# Runs the agent in docker container
+
+TEST_NAME=$1
+AGENT_NUM=$2
+
+logfile="results/${TEST_NAME}/agent-${AGENT_NUM}.log"
+mkdir -p "$(dirname "${logfile}")"
+
+docker run --name blendnet-agent-${AGENT_NUM} -m 2G --rm -i \
+    --volumes-from blendnet-srv ubuntu:20.04 \
+    /srv/workspace/test_run_service.sh agent > "${logfile}" 2>&1 || true
+
+grep '^Traceback' "${logfile}" && exit 1 || echo "ok - no exceptions in ${logfile}"
+grep '^ERROR: ' "${logfile}" && exit 2 || echo "ok - no errors in ${logfile}"
+grep '^Fatal Python error: ' "${logfile}" && exit 3 || echo "ok - no python errors in ${logfile}"
diff --git a/.github/actions/blendnet-test-linux/test_run_manager.sh b/.github/actions/blendnet-test-linux/test_run_manager.sh
new file mode 100755
index 0000000..8a2437b
--- /dev/null
+++ b/.github/actions/blendnet-test-linux/test_run_manager.sh
@@ -0,0 +1,22 @@
+#!/bin/sh -xe
+# Runs the manager in docker container
+
+TEST_NAME=$1
+
+logfile="results/${TEST_NAME}/manager.log"
+mkdir -p "$(dirname "${logfile}")"
+
+# Wait for blendnet-agent-1 container
+while ! docker ps | grep blendnet-agent-1; do echo "waiting agent-1"; docker ps; sleep 1; done
+# Wait for blendnet-agent-2 container
+while ! docker ps | grep blendnet-agent-2; do echo "waiting agent-2"; docker ps; sleep 1; done
+
+docker run --name blendnet-manager -m 2G --rm -i \
+    --link blendnet-agent-1:blendnet-agent-1-host \
+    --link blendnet-agent-2:blendnet-agent-2-host \
+    --volumes-from blendnet-srv ubuntu:20.04 \
+    /srv/workspace/test_run_service.sh manager > "${logfile}" 2>&1 || true
+
+grep '^Traceback' "${logfile}" && exit 1 || echo "ok - no exceptions in ${logfile}"
+grep '^ERROR: ' "${logfile}" && exit 2 || echo "ok - no errors in ${logfile}"
+grep '^Fatal Python error: ' "${logfile}" && exit 3 || echo "ok - no python errors in ${logfile}"
diff --git a/.github/actions/blendnet-test-linux/test_run_service.sh b/.github/actions/blendnet-test-linux/test_run_service.sh
new file mode 100755
index 0000000..adbe624
--- /dev/null
+++ b/.github/actions/blendnet-test-linux/test_run_service.sh
@@ -0,0 +1,22 @@
+#!/bin/sh -xe
+# Runs the required service (manager/agent/addon) in test env
+
+SVC=$1
+
+[ "${SVC}" = 'agent' -o "${SVC}" = 'manager' -o "${SVC}" = 'addon' ] || exit 1
+[ -d /srv/scripts/addons/blendnet ] || exit 2
+[ -d /srv/blender ] || exit 3
+[ -d /srv/workspace ] || exit 4
+
+cp -a /srv/workspace /workspace
+cd /workspace
+
+apt update
+apt install --no-install-recommends -y libxrender1 libxi6 libgl1
+
+if [ "${SVC}" = "addon" ]; then
+    export BLENDER_USER_SCRIPTS=/srv/scripts
+    /srv/blender/blender -b -noaudio test-project/proj/test-project.blend -P /srv/workspace/test_script_addon.py
+else
+    /srv/blender/blender -b -noaudio -P /srv/scripts/addons/blendnet/${SVC}.py
+fi
diff --git a/.github/scripts/build.sh b/.github/scripts/build.sh
new file mode 100755
index 0000000..b553166
--- /dev/null
+++ b/.github/scripts/build.sh
@@ -0,0 +1,26 @@
+#!/bin/sh -xe
+# Show the version and pack the BlendNet distributive archive
+
+ROOT=$(dirname "$0")/../..
+
+# Get version from the addon init file
+VERSION=$(head -10 "${ROOT}/__init__.py" | grep -o 'version.: *(.*)' | tr ',' '.' | grep -o '[0-9]\|\.' | tr -d '\n')
+
+DEV_VER=''
+if [ "x$(head -10 "${ROOT}/__init__.py" | grep -o 'warning.: *.dev')" != 'x' ]; then
+    # Mark development version with hash to not confuse with the logs
+    GIT_HASH=$(git -C "${ROOT}" rev-parse --short HEAD)
+    sed -i "0,/'development version'/{s/'development version'/'dev-${GIT_HASH}'/}" "${ROOT}/__init__.py"
+    DEV_VER="-${GIT_HASH}"
+fi
+
+echo "INFO: BlendNet version: $VERSION$DEV_VER"
+if [ -d blendnet ]; then
+    mkdir -p results/dist
+
+    tar -cvzf results/dist/blendnet-${VERSION}${DEV_VER}.tar.gz --exclude='.*' --exclude='__pycache__' blendnet
+    zip -9 -r results/dist/blendnet-${VERSION}${DEV_VER}.zip blendnet --exclude '**/.*' '**/__pycache__/*'
+    echo "INFO: Created dist archives: $(ls results/dist | tr '\n' ', ')"
+else
+    echo 'WARN: Skip creating dist archives, no blendnet dir is here'
+fi
diff --git a/.github/scripts/test_script_addon.py b/.github/scripts/test_script_addon.py
new file mode 100644
index 0000000..6ebb207
--- /dev/null
+++ b/.github/scripts/test_script_addon.py
@@ -0,0 +1,92 @@
+#!blender -b -noaudio -P
+# CI script to test the BlendNet Addon send task to Manager
+
+import os
+import sys
+import time
+
+import bpy
+
+print('INFO: CI: Enabling BlendNet addon')
+bpy.ops.preferences.addon_enable(module='blendnet')
+
+print('INFO: CI: Configuring BlendNet addon')
+prefs = bpy.context.preferences.addons['blendnet'].preferences
+
+prefs.resource_provider = 'local'
+print('INFO: CI: Using provider:', prefs.resource_provider)
+
+prefs.manager_address = 'blendnet-manager-host' # Using presetup docker container DN
+prefs.manager_ca_path = os.path.abspath('workspace/ca.crt')
+prefs.manager_user = 'None'
+prefs.manager_password = 'None'
+
+prefs.agent_user = 'None'
+prefs.agent_password = 'None'
+
+print('INFO: CI: Setup scene')
+scene = bpy.context.scene
+scene.render.engine = 'CYCLES'
+
+# Override the absolute path of the used images
+for img in bpy.data.images:
+    img.filepath = img.filepath.replace(
+            '/home/user/Work/state-of-the-art/BlendNet-test-project',
+            os.path.abspath(bpy.path.abspath('//..')), 1)
+    # In windows it looks different
+    img.filepath = img.filepath.replace(
+            '/home\\user\\Work\\state-of-the-art\\BlendNet-test-project',
+            os.path.abspath(bpy.path.abspath('//..')), 1)
+
+# Set the number of samples to CI level
+scene.cycles.samples = 23
+scene.cycles.aa_samples = 23
+
+# Wait manager connected
+for retry in range(1, 10):
+    print('INFO: CI: Wait for the Manager active, retry:', retry)
+    if bpy.ops.blendnet.agentcreate.poll():
+        break
+    time.sleep(5)
+if not bpy.ops.blendnet.agentcreate.poll():
+    print('ERROR: CI: BlendNet Manager was not connected to setup Agents')
+    sys.exit(1)
+
+print('INFO: CI: Attaching the Agents to clean the environment')
+for i in {1,2}:
+    print('INFO: CI: Connecting Agent', i)
+    bpy.ops.blendnet.agentcreate(
+        'EXEC_DEFAULT',
+        agent_name='agent-{}'.format(i),
+        agent_address='blendnet-agent-{}-host'.format(i), # Using presetup docker container DN
+        agent_port=prefs.agent_port, # Defaults is set in invoke, so reproducing
+        agent_user=prefs.agent_user,
+        agent_password=prefs.agent_password_hidden,
+    )
+
+print('INFO: CI: Run the BlendNet Image Task')
+bpy.ops.blendnet.runtask()
+
+print('INFO: CI: Waiting for the compose result file')
+for retry in range(1, 50):
+    if os.path.isfile(scene.render.frame_path()):
+        break
+    time.sleep(5)
+    print('INFO: CI: Retry to check the compose file "{}" downloaded ({})'.format(scene.render.frame_path(), retry))
+    sys.stdout.flush()
+
+print('INFO: CI: Remove the Agents to clean the environment')
+for i in {1,2}:
+    print('INFO: CI: Disconnecting Agent', i)
+    bpy.ops.blendnet.agentremove(
+        'EXEC_DEFAULT',
+        agent_name='agent-{}'.format(i),
+    )
+
+# Check the result
+if not os.path.isfile(scene.render.frame_path()):
+    print('ERROR: CI: BlendNet did not downloaded the compose file')
+    sys.exit(2)
+
+print('DATA: CI:', scene.render.frame_path())
+sys.stdout.flush()
diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml
new file mode 100644
index 0000000..11774bf
--- /dev/null
+++ b/.github/workflows/ci.yml
@@ -0,0 +1,125 @@
+name: CI
+
+on:
+  push:
+    branches:
+      - '!BN-*'
+  pull_request:
+    paths:
+      - '*.py'
+      - 'BlendNet/**.py'
+      - '.github/**'
+
+defaults:
+  run:
+    shell: bash
+
+jobs:
+  build:
+    runs-on: ubuntu-latest
+    timeout-minutes: 10
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v2
+        with:
+          path: blendnet
+
+      - name: Packing dist archive
+        run: blendnet/.github/scripts/build.sh
+
+      # TODO: run static tests
+      #- store_test_results:
+      #    path: results/reports
+
+      - name: Save artifacts
+        if: ${{ always() }}
+        uses: actions/upload-artifact@v2
+        with:
+          name: dist
+          path: results/dist/blendnet-*
+
+  blendnet_test_lin_280:
+    runs-on: ubuntu-latest
+    needs: build
+    timeout-minutes: 15
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v2
+        with:
+          path: blendnet
+
+      - uses: ./blendnet/.github/actions/blendnet-test-linux
+        with:
+          blender_version: '2.80' # Support starts with this version
+
+      - name: Save artifacts
+        if: ${{ always() }}
+        uses: actions/upload-artifact@v2
+        with:
+          name: results-test-280
+          path: results/**
+
+  blendnet_test_lin_lts:
+    runs-on: ubuntu-latest
+    needs: build
+    timeout-minutes: 15
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v2
+        with:
+          path: blendnet
+
+      - uses: ./blendnet/.github/actions/blendnet-test-linux
+        with:
+          blender_version: 'lts' # Long term support release
+
+      - name: Save artifacts
+        if: ${{ always() }}
+        uses: actions/upload-artifact@v2
+        with:
+          name: results-test-lts
+          path: results/**
+
+  blendnet_test_lin_latest:
+    runs-on: ubuntu-latest
+    needs: build
+    timeout-minutes: 15
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v2
+        with:
+          path: blendnet
+
+      - uses: ./blendnet/.github/actions/blendnet-test-linux
+        with:
+          blender_version: 'latest' # Latest release available
+
+      - name: Save artifacts
+        if: ${{ always() }}
+        uses: actions/upload-artifact@v2
+        with:
+          name: results-test-latest
+          path: results/**
+
+#  blendnet_test_win:
+#    runs-on: windows-latest
+#    needs: build
+#    timeout-minutes: 15
+#    defaults:
+#      run:
+#        shell: powershell
+#    steps:
+#      - name: Checkout
+#        uses: actions/checkout@v2
+#        with:
+#          path: blendnet
+#
+#      - uses: ./blendnet/.github/actions/blendnet-test-windows
+#        with:
+#          blender_version: '2.80' # Support starts with this version
+#
+#      - name: Save artifacts
+#        if: ${{ always() }}
+#        uses: actions/upload-artifact@v2
+#        with:
+#          path: results/**
diff --git a/.github/workflows/nightly.yml b/.github/workflows/nightly.yml
new file mode 100644
index 0000000..c1e5b0d
--- /dev/null
+++ b/.github/workflows/nightly.yml
@@ -0,0 +1,67 @@
+name: Nightly
+
+on:
+  schedule:
+    - cron: '0 6 * * *'
+
+defaults:
+  run:
+    shell: bash
+
+jobs:
+  blendnet_test_lin_280:
+    runs-on: ubuntu-latest
+    timeout-minutes: 15
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v2
+        with:
+          path: blendnet
+
+      - uses: ./blendnet/.github/actions/blendnet-test-linux
+        with:
+          blender_version: '2.80' # Support starts with this version
+
+      - name: Save artifacts
+        if: ${{ always() }}
+        uses: actions/upload-artifact@v2
+        with:
+          path: results/**
+
+  blendnet_test_lin_lts:
+    runs-on: ubuntu-latest
+    timeout-minutes: 15
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v2
+        with:
+          path: blendnet
+
+      - uses: ./blendnet/.github/actions/blendnet-test-linux
+        with:
+          blender_version: 'lts' # Long term support release
+
+      - name: Save artifacts
+        if: ${{ always() }}
+        uses: actions/upload-artifact@v2
+        with:
+          path: results/**
+
+  blendnet_test_lin_latest:
+    runs-on: ubuntu-latest
+    timeout-minutes: 15
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v2
+        with:
+          path: blendnet
+
+      - uses: ./blendnet/.github/actions/blendnet-test-linux
+        with:
+          blender_version: 'latest' # Latest release available
+
+      - name: Save artifacts
+        if: ${{ always() }}
+        uses: actions/upload-artifact@v2
+        with:
+          path: results/**
diff --git a/BlendNet/AgentTask.py b/BlendNet/AgentTask.py
index f00fb33..459b93f 100644
--- a/BlendNet/AgentTask.py
+++ b/BlendNet/AgentTask.py
@@ -63,7 +63,7 @@ class AgentTask(TaskBase):
         finally:
             self._parent._fc.workspaceClean(self.name())
 
-        print('INFO: Execution of the task "%s" is ended' % self.name())
+        print('INFO: Execution of the task "%s" is ended' % (self.name(),))
         self.stateStop()
 
         with self._execution_lock:
@@ -112,6 +112,8 @@ class AgentTask(TaskBase):
         sample_preview_save_time = 0
         # Used to contain the current rendering sample
         curr_sample = 0
+        # The blender crashed, so the path contains trace
+        crash_path = None
         for line in iter(process.stdout.readline, b''):
             l = ''
             try:
@@ -157,12 +159,15 @@ class AgentTask(TaskBase):
                         mem_render_peak = float(d[1].split(':')[1][:-1])
                         rest_status = i+1
                         break
-                if rest_status: # Scene, RenderLayer | Synchronizing object | Ship_Floor
-                                # Scene, RenderLayer | Path Tracing Sample 1/10
+                if rest_status: # Blender v2.80:
+                                #   Scene, RenderLayer | Synchronizing object | Ship_Floor
+                                #   Scene, RenderLayer | Path Tracing Sample 1/10
+                                # Blender v3.0.0:
+                                #   Scene, View Layer | Sample 97/105
                     scene_info = status[rest_status]
                     operation = ' | '.join(status[rest_status+1:])
-                    if 'Path Tracing Sample' in operation:
-                        operation, curr_sample = operation.split(' Sample ')
+                    if 'Sample ' in operation:
+                        operation, curr_sample = operation.split('Sample ')
                         curr_sample = int(curr_sample.split('/')[0])
                         self.statusSamplesDoneSet(curr_sample-1)
                 self.executionDetailsAdd({
@@ -184,7 +189,7 @@ class AgentTask(TaskBase):
                     prepare_time = time_sec
                     self.statusPrepareTimeSet(prepare_time)
 
-                # Update preview every 5 second
+                # Update preview every 5 seconds
                 if curr_sample > 1 and curr_sample < self._cfg.samples and time.time() > sample_preview_save_time:
                     try:
                         sample_preview_save_time = time.time() + 5
@@ -193,7 +198,7 @@ class AgentTask(TaskBase):
                     except Exception as e:
                         print('ERROR: Unable to send "savePreview" command due to exception: %s' % e)
 
-                if operation in ('Finished', 'Cancel | Cancelled'):
+                if operation in ('Finished', 'Cancel | Cancelled', 'Cancelled'):
                     finished = operation == 'Finished'
                     process.stdin.write(b'end\n')
                     process.stdin.flush()
@@ -201,8 +206,13 @@ class AgentTask(TaskBase):
                         self.statusRenderTimeSet(time_sec - prepare_time)
                         self.statusSamplesDoneSet(curr_sample if finished else curr_sample-1)
 
+            # In case the crash happened
+            elif l.startswith('Writing:') and l.endswith('.crash.txt'):
+                print('WARN: Found crash report')
+                crash_path = l.replace('Writing: ', '', 1)
+
             # Collecting the render statistics
-            if l.startswith('Render statistics:'):
+            elif l.startswith('Render statistics:'):
                 statistics = {}
                 header = None
                 for line in iter(process.stdout.readline, b''): # Redefined line intentionally
@@ -237,7 +247,7 @@ class AgentTask(TaskBase):
                 process.send_signal(signal.SIGINT) # Signal will cause Cancel event
                 continue
 
-            # Do something on terminating
+            # Do action on terminating
             if self._parent.isTerminating():
                 print('WARN: Detected terminating in %s' % self._parent.timeToTerminating())
                 self.executionMessagesAdd('WARN: Instance is going to be terminated in %d sec' % self._parent.timeToTerminating())
@@ -275,11 +285,18 @@ class AgentTask(TaskBase):
 
         print('DEBUG: Return code: %s' % process.poll())
 
+        if crash_path:
+            print('WARN: Crash report content:')
+            with open(crash_path, 'r') as f:
+                print(f.read())
+
         if process.poll() == -9: # OOM kill
             self.stateError({self.name(): 'The worker was killed by Out Of Memory - try to use bigger VM for the Agent'})
 
         if finished:
             self.stateComplete()
+        else:
+            self.stateStop()
 
     def _stop(self):
         self._stop_task = True
diff --git a/BlendNet/Client.py b/BlendNet/Client.py
index 98eff36..7ab7df3 100644
--- a/BlendNet/Client.py
+++ b/BlendNet/Client.py
@@ -94,8 +94,7 @@ class ClientEngine:
         if self._ca:
             return True
 
-        print('DEBUG: Trying to get CA certificate from the bucket')
-        self._ca = providers.downloadDataFromBucket(self._cfg.get('bucket', ''), 'ca.crt')
+        self._ca = providers.downloadDataFromStorage(self._cfg.get('storage_url'), 'ca.crt')
         if not self._ca:
             return False
 
@@ -132,7 +131,7 @@ class ClientEngine:
                 print('WARN: Communication issue with request to "%s": HTTP %d %s: %s' % (req.full_url, e.getcode(), e.reason, e.read(1024)))
             except urllib.error.URLError as e:
                 if 'CERTIFICATE_VERIFY_FAILED' in str(e.reason) or 'handshake' in str(e.reason):
-                    print('WARN: Seems like wrong (or old) CA is loaded, reinit SSL context and repeat.')
+                    print('WARN: SSL verify failed. It could be wrong (or old) CA is loaded, will reinit SSL context and repeat.')
                     self._initSSL()
                 else:
                     if req.data and (isinstance(e.reason, BrokenPipeError) # Linux
diff --git a/BlendNet/Config.py b/BlendNet/Config.py
index fda16e9..8bc8fa2 100644
--- a/BlendNet/Config.py
+++ b/BlendNet/Config.py
@@ -64,11 +64,13 @@ class Config:
 
     def configsSet(self, configs):
         '''Walk through the defined configs and set configs values'''
+        results = []
         for name, conf in self._defs.items():
             if name in configs:
-                self._setattr(name, configs[name])
+                results.append(self._setattr(name, configs[name]))
             elif conf.get('value') is not None:
-                self._setattr(name, conf['value'](self) if callable(conf['value']) else conf['value'])
+                results.append(self._setattr(name, conf['value'](self) if callable(conf['value']) else conf['value']))
+        return all(results)
 
     def configsGet(self):
         '''Returns set configs or defaults if defined'''
diff --git a/BlendNet/Manager.py b/BlendNet/Manager.py
index 14e6afe..4a9e492 100644
--- a/BlendNet/Manager.py
+++ b/BlendNet/Manager.py
@@ -111,6 +111,8 @@ class Manager(TaskExecutorBase, providers.Manager):
         # Let's delete the agents
         with self._agents_pool_lock:
             for agent in self._agents_pool:
+                if not agent._id:
+                    continue
                 print('WARN: Deleting the agent %s due to Manager termination' % agent.name())
                 # We don't need to wait until delete will be completed
                 thread = threading.Thread(target=providers.deleteInstance, args=(agent._id,))
@@ -130,7 +132,8 @@ class Manager(TaskExecutorBase, providers.Manager):
             'session_id': self._cfg.session_id,
             'dist_url': self._cfg.dist_url,
             'dist_checksum': self._cfg.dist_checksum,
-            'bucket': self._cfg.bucket,
+            'provider': providers.getSelectedProvider(),
+            'storage_url': self._cfg.storage_url,
             'instance_type': self._cfg.agent_instance_type,
             'use_cheap_instance': self._cfg.agent_use_cheap_instance,
             'instance_max_price': self._cfg.agent_instance_max_price,
diff --git a/BlendNet/ManagerAgentWorker.py b/BlendNet/ManagerAgentWorker.py
index ca5c404..146c121 100644
--- a/BlendNet/ManagerAgentWorker.py
+++ b/BlendNet/ManagerAgentWorker.py
@@ -31,7 +31,7 @@ class ManagerAgentWorker(object):
         self._cfg = cfg.copy()
 
         # Generate agent certificates
-        if 'bucket' in self._cfg:
+        if 'storage_url' in self._cfg:
             SimpleREST.generateCert(self._name, self._name)
 
         self._enabled = False
@@ -264,9 +264,9 @@ class ManagerAgentWorker(object):
 
         if self.state() in (ManagerAgentState.STOPPED, ManagerAgentState.DESTROYED):
             # Agent will need config files right after the start
-            providers.uploadFileToBucket('%s.key' % self._name, self._cfg.get('bucket'), 'work_%s/server.key' % self._name)
-            providers.uploadFileToBucket('%s.crt' % self._name, self._cfg.get('bucket'), 'work_%s/server.crt' % self._name)
-            providers.uploadDataToBucket(json.dumps(self._cfg).encode('utf-8'), self._cfg.get('bucket'), 'work_%s/agent.json' % self._name)
+            providers.uploadFileToStorage('%s.key' % self._name, self._cfg.get('storage_url'), 'work_%s/server.key' % self._name)
+            providers.uploadFileToStorage('%s.crt' % self._name, self._cfg.get('storage_url'), 'work_%s/server.crt' % self._name)
+            providers.uploadDataToStorage(json.dumps(self._cfg).encode('utf-8'), self._cfg.get('storage_url'), 'work_%s/agent.json' % self._name)
 
         if self.state() == ManagerAgentState.STOPPED:
             print('DEBUG: Starting the existing agent instance "%s"' % self._name)
diff --git a/BlendNet/ManagerTask.py b/BlendNet/ManagerTask.py
index a2b04b1..a7d7107 100644
--- a/BlendNet/ManagerTask.py
+++ b/BlendNet/ManagerTask.py
@@ -150,7 +150,7 @@ class ManagerTask(TaskBase):
             else:
                 files = dict([ (blob + '.exr', blob) for blob in to_merge[1] ])
                 cfg = {
-                    'images': list(files.keys()),
+                    'images': [ 'project/' + f for f in files.keys() ],
                     'result': 'result.exr',
                 }
                 with self.prepareWorkspace(files) as ws_path:
@@ -197,8 +197,10 @@ class ManagerTask(TaskBase):
             cfg = {
                 'use_compositing_nodes': self._cfg.use_compositing_nodes,
                 'frame': self._cfg.frame,
-                'render_file_path': render_name + '.exr',
+                'render_file_path': 'project/' + render_name + '.exr',
                 'result_dir': render_name + '-result',
+                'project_path': self._cfg.project_path,
+                'cwd_path': self._cfg.cwd_path,
             }
             print('DEBUG: Files to use in workspace:')
             for path in sorted(files_map):
@@ -211,7 +213,7 @@ class ManagerTask(TaskBase):
                 for filename in os.listdir(os.path.join(ws_path, cfg['result_dir'])):
                     blob = self._parent._fc.blobStoreFile(os.path.join(ws_path, cfg['result_dir'], filename), True)
                     if not blob:
-                        print('ERROR: Unable to store blob for compose result of "%s"' % self.name())
+                        print('ERROR: Unable to store blob for compose result of', self.name())
                         return
                     self.statusComposeSet(blob['id'])
                     break
@@ -222,7 +224,7 @@ class ManagerTask(TaskBase):
             print('ERROR: Exception occurred during composing the result for task "%s": %s: %s' % (self.name(), type(e), e))
             self.stateError({self.name(): 'Exception occurred during composing the result: %s' % (e,)})
 
-        print('DEBUG: Compositing completed for task "%s"' % (self.name(),))
+        print('DEBUG: Compositing completed for task', self.name())
 
     def _processOutputs(self, process, show_out = False):
         '''Shows info from the process'''
diff --git a/BlendNet/Server.py b/BlendNet/Server.py
index 146f8b3..171db73 100644
--- a/BlendNet/Server.py
+++ b/BlendNet/Server.py
@@ -5,33 +5,15 @@
 Description: Basic REST service for BlendNet task servers
 '''
 
-import os, sys, time
+import os
+import sys
 import threading
 import json # Used in the tasks configuration
 
 from . import providers
+from . import utils
 from . import SimpleREST
 
-class CopyStringIO:
-    '''Class to store the logs to get them from client'''
-    def __init__(self, orig_out, copy_out, copy_out_lock):
-        self._orig_out = orig_out
-        self._copy_out = copy_out
-        self._copy_out_lock = copy_out_lock
-    def write(self, buf):
-        self._orig_out.write(buf)
-        with self._copy_out_lock:
-            key = str(time.time())
-            while key in self._copy_out:
-                key = str(float(key)+0.00001)
-            self._copy_out[key] = buf
-            if len(self._copy_out) > 100000:
-                to_remove_keys = sorted(self._copy_out.keys())[0:10000]
-                for key in to_remove_keys:
-                    del self._copy_out[key]
-    def flush(self):
-        self._orig_out.flush()
-
 class Processor(providers.Processor, SimpleREST.ProcessorBase):
     def __init__(self, engine, prefix = 'api/v1'):
         print('DEBUG: Creating Processor')
@@ -42,8 +24,8 @@ class Processor(providers.Processor, SimpleREST.ProcessorBase):
         self._log = dict()
         self._log_lock = threading.Lock()
 
-        sys.stdout = CopyStringIO(sys.__stdout__, self._log, self._log_lock)
-        sys.stderr = CopyStringIO(sys.__stderr__, self._log, self._log_lock)
+        sys.stdout = utils.CopyStringIO(sys.__stdout__, self._log, self._log_lock)
+        sys.stderr = utils.CopyStringIO(sys.__stderr__, self._log, self._log_lock)
 
     @SimpleREST.get()
     def info(self, req = None):
@@ -148,6 +130,11 @@ class Processor(providers.Processor, SimpleREST.ProcessorBase):
     @SimpleREST.put('task/*/file/**')
     def put_task_file(self, req, parts):
         '''Upload file required to execute task'''
+        # The cross-system paths are a pain. In blender we have 3 types (including '//'), so the rules are:
+        # * Path delimiter is always '/'. Backslash '\' will be converted to '/'
+        # * The path should be straight and can't contain '/../' (parent dir usage)
+        # * Relative paths (dir/file.txt) will be transformed with 'cwd' to absolute path during config
+        # * Project paths (//something) will be transformed with 'path' to absolute path during config
         length = req.headers['content-length']
         if not length:
             return { 'success': False, 'message': 'Unable to find "Content-Length" header' }
@@ -164,9 +151,14 @@ class Processor(providers.Processor, SimpleREST.ProcessorBase):
         if not result:
             return { 'success': False, 'message': 'Error during receiving the file' }
 
-        if not task.fileAdd(parts[1], result['id']):
+        path = parts[1].replace('\\', '/')
+
+        if not task.fileAdd(path, result['id']):
             return { 'success': False, 'message': 'Error during add file to the task' }
 
+        if self._e.taskGet(parts[0]).filesPathsFix(path) == False:
+            return { 'success': False, 'message': 'Error during task file fixing' }
+
         return { 'success': True, 'message': 'Uploaded task file',
             'data': result,
         }
@@ -190,6 +182,9 @@ class Processor(providers.Processor, SimpleREST.ProcessorBase):
         if not self._e.taskGet(parts[0]).configsSet(conf):
             return { 'success': False, 'message': 'Error during task configuration' }
 
+        if self._e.taskGet(parts[0]).filesPathsFix() != True:
+            return { 'success': False, 'message': 'Error during task files fixing' }
+
         return { 'success': True, 'message': 'Task configured' }
 
     @SimpleREST.get('task/*/run')
diff --git a/BlendNet/TaskBase.py b/BlendNet/TaskBase.py
index ba5f192..ea6a2bc 100644
--- a/BlendNet/TaskBase.py
+++ b/BlendNet/TaskBase.py
@@ -16,13 +16,23 @@ from random import randrange
 from abc import ABC, abstractmethod
 
 from .Config import Config
+from . import utils
 
 class TaskConfig(Config):
     _defs = {
         'project': {
             'description': '''Set the project file will be used to render''',
             'type': str,
-            'validation': lambda cfg, val: cfg._parent.fileGet(val),
+        },
+        'project_path': {
+            'description': '''Absolute path to the project dir, required to resolve `//../dir/file`''',
+            'type': str,
+            'validation': lambda cfg, val: utils.isPathAbsolute(val) and utils.isPathStraight(val),
+        },
+        'cwd_path': {
+            'description': '''Absolute path to the current working dir, required to resolve `dir/file`''',
+            'type': str,
+            'validation': lambda cfg, val: utils.isPathAbsolute(val) and utils.isPathStraight(val),
         },
         'samples': {
             'description': '''How much samples to process for the task''',
@@ -235,7 +245,7 @@ class TaskBase(ABC):
 
     def fileAdd(self, path, file_id):
         '''Add file to the files map'''
-        if path.startswith('/') or '../' in path:
+        if '../' in path:
             return print('WARN: Unable to use path with absolute path or contains parent dir symlink')
 
         if not self.canBeChanged():
@@ -256,6 +266,33 @@ class TaskBase(ABC):
         with self._files_lock:
             return self._files.copy()
 
+    def filesPathsFix(self, path = None):
+        '''Fixes the files mapping to be absolute paths'''
+        result = True
+        tocheck = [path] if path else list(self._files.keys())
+        for p in tocheck:
+            if not utils.isPathStraight(p):
+                print('ERROR: Path is not straight:', p)
+                return False
+            if not self._cfg.project_path or not self._cfg.cwd_path:
+                # The required configs are not set - skipping fix
+                result = None
+                continue
+
+            if not utils.isPathAbsolute(p):
+                new_p = p
+                if p.startswith('//'):
+                    # Project-based file
+                    new_p = self._cfg.project_path + p[2:].lstrip('/')
+                else:
+                    # Relative path to CWD
+                    new_p = self._cfg.cwd_path + p.lstrip('/')
+                with self._files_lock:
+                    self._files[new_p] = self._files.pop(p)
+                print('DEBUG: Fixed path:', p, new_p)
+
+        return result
+
     def run(self):
         '''Trigger the task to execute'''
         with self._state_lock:
@@ -263,7 +300,11 @@ class TaskBase(ABC):
                 print('WARN: Unable to run already started task')
                 return True
 
-            print('DEBUG: Running task %s' % self.name())
+            print('DEBUG: Running task', self.name())
+
+        if not self.check():
+            print('ERROR: Task check fail:', self.name())
+            return False
 
         return self._parent.taskAddToPending(self)
 
@@ -340,8 +381,13 @@ class TaskBase(ABC):
         if not self.canBeChanged():
             return print('WARN: Unable to change the task once started')
 
-        self._cfg.configsSet(configs)
-        return True
+        # Make sure the paths will be properly set
+        if configs.get('project_path'):
+            configs['project_path'] = configs['project_path'].replace('\\', '/').rstrip('/') + '/'
+        if configs.get('cwd_path'):
+            configs['cwd_path'] = configs['cwd_path'].replace('\\', '/').rstrip('/') + '/'
+
+        return self._cfg.configsSet(configs)
 
     def configsGet(self):
         '''Get all the set configs'''
@@ -352,6 +398,10 @@ class TaskBase(ABC):
         errors = []
         with self._files_lock:
             for path, sha1 in self._files.items():
+                if not utils.isPathAbsolute(path):
+                    errors.append({self.name(): 'The file path "%s" is not absolute' % (path,)})
+                if not utils.isPathStraight(path):
+                    errors.append({self.name(): 'The file path "%s" is contains parent dir usage' % (path,)})
                 if not self._parent._fc.blobGet(sha1):
                     errors.append({self.name(): 'Unable to find required file "%s" with id "%s" in file cache' % (path, sha1)})
         for err in errors:
@@ -360,7 +410,22 @@ class TaskBase(ABC):
 
     def prepareWorkspace(self, files_map):
         '''Preparing workspace to process files'''
-        ws_dir = self._parent._fc.workspaceCreate(self.name(), files_map)
+        # Change the absolute paths to the required relative ones
+        # and placing files to the proper folders
+        new_files_map = {}
+        for path in files_map:
+            p = ''
+            if path.startswith(self._cfg.project_path):
+                p = path.replace(self._cfg.project_path, 'project/', 1)
+            elif utils.isPathAbsolute(path):
+                # Windows don't like colon and other spec symbols in the path
+                p = 'ext_deps' + '/' + path.replace(':', '_')
+            else:
+                # Just a regular relative files are going to the project dir
+                # they could be here because inner logic is using them to create files
+                p = 'project/' + path
+            new_files_map[p] = files_map[path]
+        ws_dir = self._parent._fc.workspaceCreate(self.name(), new_files_map)
         if not ws_dir:
             raise Exception('ERROR: Unable to prepare workspace to execute task')
 
@@ -369,20 +434,22 @@ class TaskBase(ABC):
     def runBlenderScriptProcessor(self, workspace_path, script_suffix, cfg, blendfile = None):
         '''Running blender in workspace with providing a script path'''
 
-        config_name = 'config-%s.json' % script_suffix
+        config_name = 'config-%s.json' % (script_suffix,)
         with open(os.path.join(workspace_path, config_name), 'w') as f:
             json.dump(cfg, f)
 
         script_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'script-%s.py' % script_suffix)
         command = [bpy.app.binary_path, '-b', '-noaudio', '-y']
         if blendfile:
-            command.append(os.path.join(workspace_path, blendfile))
+            command.append(os.path.join(workspace_path, 'project', blendfile))
         # Position of script is important - if it's after blend file,
         # than it will be started after blend loading
         command.append('-P')
         command.append(script_path)
         command.append('--')
         command.append(config_name)
+
+        print('DEBUG: Run subprocess "%s" in "%s"' % (command, workspace_path))
         return subprocess.Popen(
             command,
             cwd = workspace_path,
diff --git a/BlendNet/TaskExecutorBase.py b/BlendNet/TaskExecutorBase.py
index 1d6e2d2..d56cfbd 100644
--- a/BlendNet/TaskExecutorBase.py
+++ b/BlendNet/TaskExecutorBase.py
@@ -35,10 +35,10 @@ class TaskExecutorConfig(Config):
             'type': str,
             'default': '',
         },
-        'bucket': {
-            'description': '''Bucket name used to store things''',
+        'storage_url': {
+            'description': '''Storage URL used to store things''',
             'type': str,
-            'default': lambda cfg: providers.getBucketName(cfg.session_id),
+            'default': lambda cfg: providers.getStorageUrl(cfg.session_id),
         },
         'listen_host': {
             'description': '''Server listen host - ip address or name''',
diff --git a/BlendNet/Workers.py b/BlendNet/Workers.py
index dc844df..369f1f4 100644
--- a/BlendNet/Workers.py
+++ b/BlendNet/Workers.py
@@ -49,7 +49,7 @@ class Workers(object):
                 with self._tasks_lock:
                     self._tasks_ended += 1
             except queue.Empty:
-                print('DEBUG: Workers "%s" worker thread completed' % self._name)
+                #print('DEBUG: Workers "%s" worker thread completed' % (self._name,))
                 break # Thread will stop if there is no tasks
 
     def start(self):
diff --git a/BlendNet/__init__.py b/BlendNet/__init__.py
index c3e2988..2113ef1 100644
--- a/BlendNet/__init__.py
+++ b/BlendNet/__init__.py
@@ -1,6 +1,30 @@
-from .Agent import Agent
 from .AgentClient import AgentClient
-from .Manager import Manager
 from .ManagerClient import ManagerClient
 
 from . import addon
+
+import os
+
+def getBlInfo():
+    '''Gets part of addon init and returns the version'''
+    out = {}
+    with open(os.path.join(os.path.dirname(__file__), '..', '__init__.py'), 'r') as f:
+        info = []
+        for line in f:
+            if not (info or line.startswith('bl_info = {')):
+                continue
+
+            info.append(line.rstrip())
+
+            if line.startswith('}'):
+                break
+        exec(''.join(info), out)
+    return out['bl_info']
+
+def getVersion():
+    '''Returns the version of BlendNet'''
+    bl_info = getBlInfo()
+    out = '%d.%d.%d' % bl_info['version']
+    if bl_info.get('warning'):
+        out += '-{}'.format(bl_info.get('warning').split()[0])
+    return out
diff --git a/BlendNet/addon.py b/BlendNet/addon.py
index b005061..a549e4f 100644
--- a/BlendNet/addon.py
+++ b/BlendNet/addon.py
@@ -4,6 +4,7 @@
 '''
 
 import os
+import sys
 import bpy
 import time
 import threading
@@ -16,19 +17,75 @@ import tempfile
 from datetime import datetime
 
 from . import providers
+from . import utils
 from . import ManagerClient
 from .Workers import Workers
 from .list_blender_versions import getBlenderVersions
 
+addon_log = dict()
+addon_log_lock = threading.Lock()
+def initAddonLog():
+    '''Intercept the stdout/err to capture the log out and exceptions'''
+    global addon_log, addon_log_lock
+    sys.stdout = utils.CopyStringIO(sys.__stdout__, addon_log, addon_log_lock)
+    sys.stderr = utils.CopyStringIO(sys.__stderr__, addon_log, addon_log_lock)
+
+def getAddonLog():
+    return addon_log
+
 def selectProvider(provider):
     '''Sets the current provider identifier'''
-    print('DEBUG: selected provider: %s' % provider)
-    providers.selectProvider(provider)
+    print('DEBUG: selecting provider:', provider)
+    providers.selectProvider(provider, getAddonProviderSettings(provider))
+    return
 
 def getProvider():
     '''Returns the current provider identifier'''
     return providers.selected_provider
 
+def getAddonProviderSettings(provider):
+    '''Collects the provider settings from Addon'''
+    prefs = bpy.context.preferences.addons[__package__.split('.', 1)[0]].preferences
+    out = {}
+
+    provider_settings = providers.getProvidersSettings(provider)
+    for key, data in provider_settings.items():
+        path = 'provider_' + provider + '_' + key
+        if path in prefs and prefs[path]:
+            if data['type'] == 'choice':
+                path += '_value'
+                # Use actual value instead of enum index or when items are not filled
+                if path in prefs and prefs[path]:
+                    out[key] = prefs[path]
+            else:
+                out[key] = prefs[path]
+    return out
+
+def updateProviderSettings(self, context):
+    '''Change the current provider settings and reinit the provider'''
+    prefs = bpy.context.preferences.addons[__package__.split('.', 1)[0]].preferences
+    provider = getProvider()
+    if provider != prefs.resource_provider:
+        # In case the provider got issues during select previously
+        selectProvider(prefs.resource_provider)
+        return
+
+    curr_settings = providers.getProvidersSettings(provider)
+    # Update enums actual values stored in separated property
+    for key, data in curr_settings.items():
+        if data['type'] == 'choice':
+            path = 'provider_' + provider + '_' + key
+            if prefs.get(path+'_value') != getattr(prefs, path):
+                prefs[path+'_value'] = getattr(prefs, path)
+
+    addon_settings = getAddonProviderSettings(provider)
+
+    for key, val in addon_settings.items():
+        # Only update if something was changed
+        if curr_settings[key]['value'] != val:
+            print('DEBUG: reinit provider:', providers.initProvider(addon_settings))
+            return
+
 def hidePassword(obj, prop):
     '''Will set the hidden value and replace the property with stars'''
     if getattr(obj, prop) != '**********':
@@ -71,8 +128,9 @@ def getConfig():
     cfg['session_id'] = prefs.session_id
     cfg['dist_url'] = prefs.blender_dist_url
     cfg['dist_checksum'] = prefs.blender_dist_checksum
+    cfg['provider'] = prefs.resource_provider
     if prefs.resource_provider != 'local':
-        cfg['bucket'] = providers.getBucketName(cfg['session_id'])
+        cfg['storage_url'] = providers.getStorageUrl(cfg['session_id'])
 
     cfg['listen_port'] = prefs.manager_port
     cfg['auth_user'] = prefs.manager_user
@@ -108,23 +166,37 @@ def _runBackgroundWork(function, *args, **kwargs):
     thread.daemon = True
     thread.start()
 
-def getProvidersEnumItems():
+def getProvidersEnumItems(scene = None, context = None):
     '''Return the available providers list of tuples with ident, name and description for enumproperty items'''
     docs = providers.getProvidersDoc()
     return [(i, d[0], d[1]) for i, d in docs.items()]
 
 def getProviderDocs(provider):
-    '''Return the available providers list of tuples with ident, name and description for enumproperty items'''
+    '''Gets docs for specified provider'''
     docs = providers.getProvidersDoc()
     return docs.get(provider, (provider, 'No documentation provided'))[1]
 
+def getProviderMessages(provider):
+    '''Returns the list of messages for provider'''
+    return providers.getProviderMessages(provider)
+
+def getProvidersSettings():
+    '''Returns the dict of provider settings'''
+    return providers.getProvidersSettings()
+
+def getProviderSettings():
+    '''Returns the dict of provider settings'''
+    prefs = bpy.context.preferences.addons[__package__.split('.', 1)[0]].preferences
+    return providers.getProvidersSettings(prefs.resource_provider)
+
 def getAddonDefaultProvider():
-    '''Will find the first available provider for addon and return its name'''
-    return providers.getGoodProvidersList()[0]
+    '''Will return the default provider'''
+    return 'local'
 
-def checkProviderIsGood(provider):
+def checkProviderIsSelected():
     '''Make sure current choosen provider is good enough'''
-    return provider in providers.getGoodProvidersList()
+    prefs = bpy.context.preferences.addons[__package__.split('.', 1)[0]].preferences
+    return providers.getSelectedProvider() == prefs.resource_provider
 
 
 provider_info_cache = [{}, '', 0]
@@ -349,6 +421,7 @@ manager_info_cache = [{}, 0]
 def getManagerInfo():
     '''Update cache and return the current manager info'''
     # TODO: Not multithread for now - need to add locks
+    prefs = bpy.context.preferences.addons[__package__.split('.', 1)[0]].preferences
     global manager_info_cache, manager_info_timer
 
     if manager_info_timer:
@@ -363,8 +436,12 @@ def getManagerInfo():
         # Update tasks if info is here
         updateManagerTasks()
 
-    manager_info_timer = threading.Timer(5.0, getManagerInfo)
-    manager_info_timer.start()
+    if prefs.blendnet_show_panel:
+        # Do not need to loop through update if the panel is hidden
+        manager_info_timer = threading.Timer(5.0, getManagerInfo)
+        manager_info_timer.start()
+    else:
+        manager_info_timer = None
 
     return manager_info_cache[0]
 
@@ -397,8 +474,8 @@ def startManager(cfg = None):
             return
 
     if not isManagerStarted():
-        print('DEBUG: Running uploading to bucket')
-        providers.setupBucket(cfg['bucket'], cfg)
+        print('DEBUG: Running uploading to storage')
+        providers.setupStorage(cfg['storage_url'], cfg)
 
     if not isManagerCreated():
         print('DEBUG: Creating the required firewall rules')
@@ -725,7 +802,7 @@ def getAgentPriceBG(inst_type, context = None):
     global instance_type_price_agent_cache
     info = instance_type_price_agent_cache
     prefs = bpy.context.preferences.addons[__package__.split('.', 1)[0]].preferences
-    if info[1] != inst_type or info[2] != prefs.agent_use_cheap_instance and info[3] != prefs.agent_cheap_multiplier:
+    if info[1] != inst_type or info[2] != prefs.agent_use_cheap_instance or info[3] != prefs.agent_cheap_multiplier:
         instance_type_price_agent_cache[1] = inst_type
         instance_type_price_agent_cache[2] = prefs.agent_use_cheap_instance
         instance_type_price_agent_cache[3] = prefs.agent_cheap_multiplier
diff --git a/BlendNet/blend_file.py b/BlendNet/blend_file.py
index ad68d94..05830e3 100644
--- a/BlendNet/blend_file.py
+++ b/BlendNet/blend_file.py
@@ -5,54 +5,106 @@
 Description: Useful functions to get info about the loaded blend file
 '''
 
+import os
 import bpy
-from pathlib import Path
+import glob
 
-def getDependencies():
+try:
+    from . import utils
+except ImportError:
+    # In case loaded as a regular script
+    import utils
+
+def getDependencies(project_path, cwd_path, change = False):
     '''Will return good and bad set of file dependencies'''
-    good, bad = getImages()
+    # * project_path - absolute path to the project on the client system
+    # * cwd_path - absolute path to the current working directory on the client system
+    # * change - replace the path in blend project with the changed one
+
+    good, bad = checkLibraries(project_path, cwd_path, change)
+
+    data = checkImages(project_path, cwd_path, change)
+    good = good.union(data[0])
+    bad = bad.union(data[1])
 
-    data = getCaches()
+    data = checkCaches(project_path, cwd_path, change)
     good = good.union(data[0])
     bad = bad.union(data[1])
 
     return good, bad
 
-def getImages():
+def fixPath(path, project_path, cwd_path, change):
+    '''Will make sure the path is properly formatted'''
+    newpath = path.replace('\\', '/')
+    # Make sure the blend file path is absolute for further processing
+    if newpath.startswith('//') and project_path:
+        # Convert the project (starts with '//') paths - they could
+        # contain parent dir usage, so need to ensure it's ok
+        newpath = utils.resolvePath(os.path.join(project_path, newpath[2:]))
+    elif not utils.isPathAbsolute(newpath) and cwd_path:
+        # Looks like relative path to the cwd - so making it
+        newpath = utils.resolvePath(os.path.join(cwd_path, newpath))
+
+    # Now the path is absolute and we can modify it to the actual path
+    if newpath.startswith(project_path):
+        newpath = '//' + newpath.replace(project_path, '', 1).lstrip('/')
+    elif change:
+        newpath = '//../ext_deps/' + newpath.replace(':', '_').lstrip('/')
+
+    return newpath
+
+def checkLibraries(project_path, cwd_path, change):
+    '''Will go through linked libraries, check they are existing and return good and bad set of files'''
+    good = set()
+    bad = set()
+
+    for l in bpy.data.libraries:
+        path = fixPath(l.filepath, project_path, cwd_path, change)
+        if not os.path.isfile(bpy.path.abspath(path)):
+            print('ERROR: Unable to locate the library file:', path)
+            bad.add(path)
+            continue
+        if change:
+            # Do not change the linked resources
+            if not l.is_library_indirect:
+                l.filepath = path
+
+        good.add(path)
+
+    return good, bad
+
+def checkImages(project_path, cwd_path, change):
     '''Will go through images, check they are existing and return good and bad set of files'''
     good = set()
     bad = set()
 
-    localdir = Path(bpy.path.abspath('//'))
     for i in bpy.data.images:
         if i.packed_file or i.source != 'FILE':
             continue
 
-        try:
-            path = Path(bpy.path.abspath(i.filepath)).relative_to(localdir)
-        except:
-            print('ERROR: The image is not relative to the project dir: "%s"' % i.filepath)
-            bad.add(i.filepath)
+        path = fixPath(i.filepath_from_user(), project_path, cwd_path, change)
+        if not os.path.isfile(bpy.path.abspath(path)):
+            print('ERROR: Unable to locate the image file:', path)
+            bad.add(path)
             continue
+        if change:
+            # Do not change the linked resources
+            if not i.is_library_indirect:
+                i.filepath = path
 
-        if not (localdir / path).is_file():
-            print('ERROR: The image is not relative to the project dir: "%s"' % i.filepath)
-            bad.add(i.filepath)
-        else:
-            good.add(path.as_posix())
-            i.filepath = '//' + path.as_posix()
+        good.add(path)
 
     return good, bad
 
-def getCaches():
+def checkCaches(project_path, cwd_path, change):
     '''Will go through caches, check they are existing and return good and bad set of files'''
     scene = bpy.context.scene
 
     good = set()
     bad = set()
 
-    localdir = Path(bpy.path.abspath('//'))
-    pointcache_dir = 'blendcache_' + Path(bpy.data.filepath).name.rsplit('.', 1)[0]
+    localdir = bpy.path.abspath('//')
+    pointcache_dir = 'blendcache_' + os.path.basename(bpy.data.filepath).rsplit('.', 1)[0]
     for o in bpy.data.objects:
         if not o.visible_get():
             continue
@@ -62,19 +114,15 @@ def getCaches():
 
             if mod.type == 'FLUID' and mod.fluid_type == 'DOMAIN':
                 # New mantaflow added in 2.82
-                try:
-                    cachedir = Path(bpy.path.abspath(mod.domain_settings.cache_directory)).relative_to(localdir)
-                except:
-                    print('ERROR: Cache dir is not relative to the project dir: "%s"' % mod.domain_settings.cache_directory)
-                    bad.add(mod.domain_settings.cache_directory)
-                    continue
-                if not (localdir / cachedir).is_dir():
-                    print('ERROR: Not a relative/not existing path of the cachedir '
-                          '"%s" for object modifier %s --> %s' % (mod.domain_settings.cache_directory, o.name, mod.name))
+                cachedir = fixPath(mod.domain_settings.cache_directory, project_path, cwd_path, change)
+                if not os.path.isdir(bpy.path.abspath(cachedir)):
+                    print('ERROR: Unable to locate the cachedir "%s" for object modifier %s --> %s' %
+                            (mod.domain_settings.cache_directory, o.name, mod.name))
                     bad.add(cachedir)
                     continue
 
-                mod.domain_settings.cache_directory = '//' + cachedir.as_posix()
+                if change:
+                    mod.domain_settings.cache_directory = cachedir
 
                 def _fmt(ext_type):
                     return {
@@ -132,41 +180,38 @@ def getCaches():
                     #if fire:
                     #   files.append('noise/flame_noise_%04d.%s' % (scene.frame_current, _fmt(ds.cache_noise_format)))
 
+                print('DEBUG: Expecting files:', files)
                 for f in files:
-                    cpath = cachedir / f
-                    if not (localdir / cpath).is_file():
+                    cpath = os.path.join(cachedir, f)
+                    if not os.path.isfile(bpy.path.abspath(cpath)):
                         print('ERROR: Unable to locate fluid cache file '
                               '"%s" for object modifier %s --> %s' % (cpath, o.name, mod.name))
-                        bad.add(cpath.as_posix())
-                    else:
-                        good.add(cpath.as_posix())
+                        bad.add(cpath)
+                        continue
+                    good.add(cpath)
 
                 # Some settings are attached to other objects (like flow for fire/smoke)
                 # so it's hard to determine right now, let's use just glob to find related
-                files_additional = (localdir / cachedir).glob('**/*_%04d.*' % scene.frame_current)
-                for f in files_additional:
-                    cpath = f.relative_to(localdir)
-                    if cpath.as_posix() not in files:
-                        print('INFO: Found an additional fluid cache file: %s' % (cpath.as_posix(),))
-                        good.add(cpath.as_posix())
+                files_additional = glob.glob(os.path.join(cachedir, '**/*_%04d.*' % (scene.frame_current,)))
+                for cpath in files_additional:
+                    cpath = fixPath(cpath, project_path, cwd_path, change)
+                    if cpath not in good:
+                        print('INFO: Found an additional fluid cache file:', cpath)
+                        good.add(cpath)
 
                 continue
 
             elif mod.type == 'FLUID_SIMULATION' and mod.settings.type in ('DOMAIN', 'PARTICLE'):
-                # Deprecated: < 2.82
-                try:
-                    cachedir = Path(bpy.path.abspath(mod.settings.filepath)).relative_to(localdir)
-                except:
-                    print('ERROR: Cache dir is not relative to the project dir: "%s"' % mod.settings.filepath)
-                    bad.add(mod.settings.filepath)
-                    continue
-                if not (localdir / cachedir).is_dir():
-                    print('ERROR: Not a relative/not existing path of the cachedir '
-                          '"%s" for object modifier %s --> %s' % (mod.settings.filepath, o.name, mod.name))
+                # Deprecated in blender >= 2.82
+                cachedir = fixPath(mod.settings.filepath, project_path, cwd_path, change)
+                if not os.path.isdir(bpy.path.abspath(cachedir)):
+                    print('ERROR: Unable to find the cachedir "%s" for object modifier %s --> %s' %
+                            (mod.settings.filepath, o.name, mod.name))
                     bad.add(mod.settings.filepath)
                     continue
 
-                mod.settings.filepath = '//' + cachedir.as_posix()
+                if change:
+                    mod.settings.filepath = cachedir
 
                 files = None
                 if mod.settings.type == 'DOMAIN':
@@ -181,16 +226,16 @@ def getCaches():
                 else:
                     continue
                 for f in files:
-                    cpath = cachedir / f
-                    if not (localdir / cpath).is_file():
+                    cpath = os.path.join(cachedir, f)
+                    if not os.path.isfile(bpy.path.abspath(cpath)):
                         print('ERROR: Unable to locate fluid sim cache file '
-                              '"%s" for object modifier %s --> %s' % (cpath.as_posix(), o.name, mod.name))
-                        bad.add(cpath.as_posix())
+                              '"%s" for object modifier %s --> %s' % (cpath, o.name, mod.name))
+                        bad.add(cpath)
                     else:
-                        good.add(cpath.as_posix())
+                        good.add(cpath)
                 continue
             elif mod.type == 'SMOKE':
-                # Deprecated in >= 2.82
+                # Deprecated in blender >= 2.82
                 if mod.smoke_type != 'DOMAIN':
                     continue
                 ext = '.vdb' if mod.domain_settings.cache_file_format == 'OPENVDB' else '.bphys'
@@ -221,12 +266,12 @@ def getCaches():
                 else:
                     fname = '%s_%06d%s' % (fname, scene.frame_current, ext)
 
-                cpath = Path(pointcache_dir) / fname
-                if not (localdir / cpath).is_file():
+                cpath = fixPath(os.path.join('//', pointcache_dir, fname), project_path, cwd_path, change)
+                if not os.path.isfile(bpy.path.abspath(cpath)):
                     print('ERROR: Unable to locate pointcache file '
-                          '"%s" for object modifier %s --> %s' % (cpath.as_posix(), o.name, mod.name))
-                    bad.add(cpath.as_posix())
+                          '"%s" for object modifier %s --> %s' % (cpath, o.name, mod.name))
+                    bad.add(cpath)
                 else:
-                    good.add(cpath.as_posix())
+                    good.add(cpath)
 
     return good, bad
diff --git a/BlendNet/list_blender_versions.py b/BlendNet/list_blender_versions.py
index ad807f2..92c3bd8 100644
--- a/BlendNet/list_blender_versions.py
+++ b/BlendNet/list_blender_versions.py
@@ -3,12 +3,89 @@
 '''BlendNet module to check the available blender versions
 
 Used in Addon and build automation
-Usage: python4 list_blender_versions.py [<version>/lts/latest]
+Usage: python3 list_blender_versions.py [platform [<version>/lts/latest]]
 '''
 
 import os
 from urllib.request import urlopen
 from html.parser import HTMLParser
+import threading # Sync between threads needed
+try:
+    from .Workers import Workers
+except ImportError:
+    # In case loaded as a regular script
+    from Workers import Workers
+
+workers_out = {}
+workers_out_lock = threading.Lock()
+
+def _downloadWorker(url, ctx, req_version, req_platform):
+    if not url.endswith('.sha256'):
+        # Process directory list
+        parser = LinkHTMLParser()
+        with urlopen(url, timeout=5, context=ctx) as f:
+            data = f.read()
+            try:
+                parser.feed(data.decode('utf-8'))
+            except (LookupError, UnicodeDecodeError):
+                # UTF-8 not worked, so probably it's latin1
+                parser.feed(data.decode('iso-8859-1'))
+
+        # Processing links of the dirs
+        links = parser.links()
+        global workers
+        for link in links:
+            if link.endswith('.sha256'):
+                workers.add(url+link, ctx, req_version, req_platform)
+        workers.start()
+        return
+
+    # Process sha256 file data
+    # Getting the file and search for linux dist there
+    with urlopen(url, timeout=5, context=ctx) as f:
+        for line in f:
+            try:
+                line = line.decode('utf-8')
+            except (LookupError, UnicodeDecodeError):
+                # UTF-8 not worked, so probably it's latin1
+                line = line.decode('iso-8859-1')
+            sha256, name = line.strip().split()
+            # In case name in the sha256 file absolute
+            name = os.path.basename(name)
+
+            # Check the required platform
+            if req_platform == 'lin' and ('-linux' not in name or '64.tar' not in name):
+                # blender-2.80-linux-glibc217-x86_64.tar.bz2
+                # blender-2.83.7-linux64.tar.xz
+                continue
+            elif req_platform == 'win' and '-windows64.zip' not in name:
+                # blender-2.80-windows64.zip
+                # blender-2.83.7-windows64.zip
+                continue
+            elif req_platform == 'mac' and '-macOS.dmg' not in name:
+                # blender-2.80-macOS.dmg
+                # blender-2.83.7-macOS.dmg
+                continue
+
+            # Check the full version equality
+            ver = name.split('-')[1]
+            if req_version not in {'lts', 'latest', None}:
+                if not ver == req_version:
+                    continue
+
+            global workers_out, workers_out_lock
+            with workers_out_lock:
+                workers_out[ver] = {
+                    'url': os.path.dirname(url)+'/'+name,
+                    'checksum': sha256,
+                }
+            print('INFO: found blender version: %s (%s %s)' % (ver, workers_out[ver]['url'], sha256))
+
+workers = Workers(
+    'Get the list of available Blender versions',
+    8,
+    _downloadWorker,
+)
 
 class LinkHTMLParser(HTMLParser):
     def __init__(self):
@@ -27,16 +104,18 @@ class LinkHTMLParser(HTMLParser):
         self._links = []
         return out
 
-def getBlenderVersions(ctx = None, req_version = None):
-    '''Returns a dict with {'<version>': {'url': '<dist_url>', 'checksum': '<sha256>'}}'''
-    out = {}
+def getBlenderVersions(ctx = None, req_platform = 'lin', req_version = None):
+    '''
+    * ctx - SSL context to override the CA list
+    * req_version - what kind of version to use: strict version, 'lts' or 'latest'
+    * req_platform - platform to find the right dist: 'lin', 'win' or 'mac'
+    Returns a dict with {'<version>': {'url': '<dist_url>', 'checksum': '<sha256>'}}'''
     mirrors = [
         'https://download.blender.org/release/',
         'https://mirror.clarkson.edu/blender/release/',
         'https://ftp.nluug.nl/pub/graphics/blender/release/',
     ]
     for url in mirrors:
-        out = {}
         try:
             # Getting the entry point of the mirror
             parser = LinkHTMLParser()
@@ -71,46 +150,17 @@ def getBlenderVersions(ctx = None, req_version = None):
                         continue # Skip if it's not the required version major.minor
                 dirs.append(l)
 
-            # Process the versions from latest to oldest
-            dirs.reverse()
-
             # Getting lists of the specific dirs
             for d in dirs:
-                with urlopen(url+d, timeout=5, context=ctx) as f:
-                    data = f.read()
-                    try:
-                        parser.feed(data.decode('utf-8'))
-                    except (LookupError, UnicodeDecodeError):
-                        # UTF-8 not worked, so probably it's latin1
-                        parser.feed(data.decode('iso-8859-1'))
-
-                # Processing links of the dirs
-                links = parser.links()
-                # Process the versions from latest to oldest
-                links.reverse()
-                for l in links:
-                    if not l.endswith('.sha256'):
-                        continue
-                    # Getting the file and search for linux dist there
-                    with urlopen(url+d+l, timeout=5, context=ctx) as f:
-                        for line in f:
-                            sha256, name = line.decode('utf-8').strip().split()
-                            # In case name is actually an absolute path
-                            name = os.path.basename(name)
-
-                            if '-linux' not in name or '64.tar' not in name:
-                                continue
-                            ver = name.split('-')[1]
-                            if req_version not in {'lts', 'latest', None}:
-                                if not ver == req_version:
-                                    continue # Check the full version equality
-                            out[ver] = {
-                                'url': url+d+name,
-                                'checksum': sha256,
-                            }
-                            print('INFO: found blender version: %s (%s %s)' % (ver, url, sha256))
-                            if req_version:
-                                return out # Return just one found required version
+                workers.add(url+d, ctx, req_version, req_platform)
+            workers.start()
+            workers.wait()
+
+            if req_version in {'latest', 'lts'}:
+                # Getting the latest version - lts was already filtered
+                global workers_out
+                key = sorted(workers_out.keys())[-1]
+                workers_out = {key: workers_out[key]}
 
             # Don't need to check the other mirrors
             break
@@ -118,13 +168,14 @@ def getBlenderVersions(ctx = None, req_version = None):
         except Exception as e:
             print('WARN: unable to get mirror list for: %s %s' % (url, e))
 
-    return out
+    return workers_out
 
 
 if __name__ == '__main__':
     import sys
-    req_version = sys.argv[-1] if len(sys.argv) > 1 else None
-    print('INFO: Getting Blender versions with required one: "%s"' % (req_version,))
-    versions = getBlenderVersions(None, req_version)
+    req_platform = sys.argv[1] if len(sys.argv) > 1 else 'lin'
+    req_version = sys.argv[2] if len(sys.argv) > 2 else None
+    print('INFO: Getting Blender versions with required one: "%s" for platform %s' % (req_version, req_platform))
+    versions = getBlenderVersions(None, req_platform, req_version)
     for ver in versions:
         print('DATA:', ver, versions[ver]['checksum'], versions[ver]['url'])
diff --git a/BlendNet/providers/__init__.py b/BlendNet/providers/__init__.py
index abf50bd..17bb0fd 100644
--- a/BlendNet/providers/__init__.py
+++ b/BlendNet/providers/__init__.py
@@ -1,23 +1,9 @@
 from .InstanceProvider import InstanceProvider
-from ..Workers import Workers
 
 import os
 import traceback
 import importlib
-
-modules = {}
-
-with os.scandir(os.path.dirname(__file__)) as it:
-    for entry in it:
-        if not entry.is_dir() or entry.name.startswith('__'):
-            continue
-        print('INFO: Found provider "%s"' % entry.name)
-        try:
-            modules[entry.name] = importlib.import_module('.'+entry.name, __package__)
-        except Exception as e:
-            print('WARN: Unable to load "%s" provider due to init error: %s' % (entry.name, e))
-            #traceback.print_exc()
-            modules[entry.name] = 'ERROR: Unable to load provider: %s' % (e,)
+import platform
 
 __all__ = [
     'Processor',
@@ -25,28 +11,59 @@ __all__ = [
     'Agent',
 ]
 
+modules = {}
+modules_messages = {}
 selected_provider = 'local'
 
-def selectProvider(provider):
+def loadProviders():
+    '''Go through the folders in the module dir and loads the providers'''
+    with os.scandir(os.path.dirname(__file__)) as it:
+        for entry in it:
+            if not entry.is_dir() or entry.name.startswith('__') or entry.name in modules:
+                continue
+            print('INFO: Found provider "%s"' % entry.name)
+
+            try:
+                modules[entry.name] = importlib.import_module('.'+entry.name, __package__)
+            except Exception as e:
+                print('WARN: Unable to load "%s" provider due to init error: %s' % (entry.name, e))
+                #traceback.print_exc()
+                modules[entry.name] = 'ERROR: Unable to load provider: %s' % (e,)
+
+def selectProvider(provider, settings = dict()):
     '''Sets the current provider identifier'''
     if provider not in modules:
         raise Exception('Unable to set unknown provider "%s"' % provider)
+
+    if isinstance(modules[provider], str):
+        print('WARN: Unable to select "%s" provider due to loading error: %s' % (provider, modules[provider]))
+        return
+
+    check = modules[provider].checkDependencies(settings)
+    if isinstance(check, str):
+        print('WARN: Unable to select "%s" provider due to dependency error: %s' % (provider, check))
+        modules_messages[provider] = [check]
+        return
+    modules_messages[provider] = []
+
+    print('INFO: Importing base from "%s" provider' % (provider,))
+    global Processor, Manager, Agent
+    Processor = importlib.import_module('.Processor', '%s.%s' % (__package__, provider)).Processor
+    Manager = importlib.import_module('.Manager', '%s.%s' % (__package__, provider)).Manager
+    Agent = importlib.import_module('.Agent', '%s.%s' % (__package__, provider)).Agent
+
     global selected_provider
     selected_provider = provider
 
-for name, module in modules.items():
-    if name != 'local' and not isinstance(module, str) and module.checkLocation():
-        print('INFO: Importing base from "%s" provider' % name)
-        global Processor, Manager, Agent
-        Processor = importlib.import_module('.Processor', '%s.%s' % (__package__, name)).Processor
-        Manager = importlib.import_module('.Manager', '%s.%s' % (__package__, name)).Manager
-        Agent = importlib.import_module('.Agent', '%s.%s' % (__package__, name)).Agent
-        selectProvider(name)
-        break
-else:
-    print('INFO: Importing base from "local" provider')
-    from .local import Processor, Manager, Agent
+    return True
 
+def initProvider(settings):
+    '''Init provider with settings'''
+    return _execProviderFunc('initProvider', None, settings)
+
+def getProviderMessages(provider):
+    '''Returns messages happening in the provider module'''
+    return modules_messages.get(provider, [])
 
 def getProvidersDoc():
     '''Return map with {ident: (name, desc), ...} of the providers'''
@@ -60,13 +77,27 @@ def getProvidersDoc():
 
     return out
 
-def getGoodProvidersList():
+def getProvidersSettings(provider = None):
+    '''Get the available providers settings'''
+    out = dict()
+    for ident, module in modules.items():
+        if isinstance(module, str):
+            continue
+        if provider and ident == provider:
+            return module.getSettings()
+        out[ident] = module.getSettings()
+    return out
+
+def getProviderSettings():
+    '''Get the current provider settings'''
+    return _execProviderFunc('getSettings')
+
+def getSelectedProvider():
     '''Return a list with provider identifiers if their deps are ok'''
-    return [name for name, module in modules.items()
-            if name != 'local' and not isinstance(module, str) and module.checkDependencies()] + ['local']
+    return selected_provider
 
 def _execProviderFunc(func, default = {}, *args, **kwargs):
-    if not hasattr(modules[selected_provider], func):
+    if modules[selected_provider] is None or not hasattr(modules[selected_provider], func):
         return default
     try:
         return getattr(modules[selected_provider], func)(*args, **kwargs)
@@ -84,13 +115,17 @@ def getInstanceTypes():
     '''Provides map with information about the available instances'''
     return _execProviderFunc('getInstanceTypes')
 
-def uploadFileToBucket(path, bucket, dest_path = None):
+def uploadFileToStorage(path, storage_url, dest_path = None):
     '''Uploads file to the network storage'''
-    return _execProviderFunc('uploadFileToBucket', None, path, bucket, dest_path)
+    return _execProviderFunc('uploadFileToStorage', None, path, storage_url, dest_path)
 
-def uploadDataToBucket(data, bucket, dest_path):
+def uploadRecursiveToStorage(path, storage_url, dest_path = None, include = None, exclude = None):
+    '''Recursively upload files to the storage'''
+    return _execProviderFunc('uploadRecursiveToStorage', None, path, storage_url, dest_path, include, exclude)
+
+def uploadDataToStorage(data, storage_url, dest_path = None):
     '''Uploads data to the network storage'''
-    return _execProviderFunc('uploadDataToBucket', None, data, bucket, dest_path)
+    return _execProviderFunc('uploadDataToStorage', None, data, storage_url, dest_path)
 
 def getResources(session_id):
     '''Returns map of allocated resources - manager and agents'''
@@ -101,8 +136,8 @@ def getNodeLog(instance_id):
     '''Returns string with the node serial output log'''
     return _execProviderFunc('getNodeLog', 'NOT IMPLEMENTED', instance_id)
 
-def getBucketName(session_id):
-    return _execProviderFunc('getBucketName', None, session_id)
+def getStorageUrl(session_id):
+    return _execProviderFunc('getStorageUrl', None, session_id)
 
 def getManagerName(session_id):
     return _execProviderFunc('getManagerName', 'blendnet-%s-manager' % session_id, session_id)
@@ -136,39 +171,24 @@ def destroyInstance(inst_id):
 def deleteInstance(inst_id):
     return _execProviderFunc('deleteInstance', '', inst_id)
 
-def downloadDataFromBucket(bucket_name, path):
-    return _execProviderFunc('downloadDataFromBucket', None, bucket_name, path)
+def downloadDataFromStorage(storage_url, path = None):
+    return _execProviderFunc('downloadDataFromStorage', None, storage_url, path)
 
 def createFirewall(target_tag, port):
     return _execProviderFunc('createFirewall', None, target_tag, port)
 
-def setupBucket(bucket_name, cfg):
-    '''Creating the bucket and uploads the blendnet and configs into'''
-    print('INFO: Uploading BlendNet logic to the bucket %s' % bucket_name)
-
-    _execProviderFunc('createBucket', None, bucket_name)
+def setupStorage(storage_url, cfg):
+    '''Creating the storage and uploads the blendnet and configs into'''
+    print('INFO: Uploading BlendNet logic to the storage')
 
-    workers = Workers(
-        'Uploading BlendNet logic to the bucket "%s"' % bucket_name,
-        8,
-        uploadFileToBucket,
-    )
+    _execProviderFunc('createStorage', None, storage_url)
 
-    # Walk through python files and upload them
+    # Upload BlendNet logic from the addon
     dirpath = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
-    for root, _, files in os.walk(dirpath):
-        for f in files:
-            if not f.endswith('.py'):
-                continue
-            filepath = os.path.join(root, f)
-            workers.add(filepath, bucket_name, filepath.replace(dirpath, 'blendnet', 1))
-
-    workers.start()
-
+    uploadRecursiveToStorage(dirpath, storage_url, 'blendnet', '*.py')
+    
     import json
-    uploadDataToBucket(json.dumps(cfg).encode('utf-8'), bucket_name, 'work_manager/manager.json')
-
-    workers.wait()
+    uploadDataToStorage(json.dumps(cfg).encode('utf-8'), storage_url, 'work_manager/manager.json')
 
 def getCheapMultiplierList():
     '''Returns the list of available multipliers to get the right price'''
@@ -181,3 +201,20 @@ def getPrice(inst_type, cheap_multiplier):
 def getMinimalCheapPrice(inst_type):
     '''Finds the lowest available instance price and returns it'''
     return _execProviderFunc('getMinimalCheapPrice', -1.0, inst_type)
+
+def findPATHExec(executable):
+    '''Finds absolute path of the required executable'''
+    paths = os.environ['PATH'].split(os.pathsep)
+    extlist = {''}
+
+    if platform.system() == 'Windows':
+        extlist = set(os.environ['PATHEXT'].lower().split(os.pathsep))
+
+    for ext in extlist:
+        execname = executable + ext
+        for p in paths:
+            f = os.path.join(p, execname)
+            if os.path.isfile(f):
+                return f
+
+    return None
diff --git a/BlendNet/providers/aws/__init__.py b/BlendNet/providers/aws/__init__.py
index 29a31de..bbc0177 100644
--- a/BlendNet/providers/aws/__init__.py
+++ b/BlendNet/providers/aws/__init__.py
@@ -1,6 +1,6 @@
 '''Amazon Web Services
 Provide API access to allocate required resources in AWS
-Dependencies: aws cli v2
+Dependencies: aws cli v2 installed and configured auth
 Help: https://github.com/state-of-the-art/BlendNet/wiki/HOWTO:-Setup-provider:-Amazon-Web-Services-(AWS)
 '''
 
@@ -22,15 +22,15 @@ import platform
 import tempfile
 import ssl
 import site
-import urllib.request
+import urllib
 import subprocess
 import pathlib
 
 METADATA_URL = 'http://169.254.169.254/latest/'
 
 LOCATION = None # If the script is running in the cloud
-AWS_TOOL_PATH = None
-AWS_EXEC_PREFIX = ('--output', 'json')
+AWS_CONF = {}
+AWS_EXEC_PREFIX = None
 AWS_CONFIGS = None
 
 def _requestMetadata(path, verbose = False):
@@ -54,7 +54,7 @@ def _requestMetadata(path, verbose = False):
         return None
 
 def checkLocation():
-    '''Returns True if it's the GCP environment'''
+    '''Returns True if it's the AWS environment'''
     global LOCATION
 
     if LOCATION is not None:
@@ -63,9 +63,6 @@ def checkLocation():
     LOCATION = _requestMetadata('', True) is not None
     return LOCATION
 
-def checkDependencies():
-    return AWS_TOOL_PATH is not None
-
 def _executeAwsTool(*args, data=None):
     '''Runs the aws tool and returns code and data as tuple, data will be sent to stdin as bytes'''
     to_run = AWS_EXEC_PREFIX
@@ -90,29 +87,60 @@ def _executeAwsTool(*args, data=None):
 
     return data
 
-def findAWSTool():
-    '''Finds absolute path of the aws tool'''
-    paths = os.environ['PATH'].split(os.pathsep)
-    executable = 'aws'
-    extlist = {''}
-
-    if platform.system() == 'Windows':
-        extlist = set(os.environ['PATHEXT'].lower().split(os.pathsep))
-
-    for ext in extlist:
-        execname = executable + ext
-        for p in paths:
-            f = os.path.join(p, execname)
-            if os.path.isfile(f):
-                global AWS_TOOL_PATH, AWS_EXEC_PREFIX
-                AWS_TOOL_PATH = f
-                AWS_EXEC_PREFIX = (AWS_TOOL_PATH,) + AWS_EXEC_PREFIX
-                print('INFO: Found aws tool: ' + AWS_TOOL_PATH)
-                configs = _getConfigs()
-                if 'region' in configs:
-                    print('INFO: Set region for aws tool: ' + configs['region'])
-                    AWS_EXEC_PREFIX += ('--region', configs['region'])
-                return
+def initProvider(settings = dict()):
+    '''Init provider configuration'''
+    from .. import findPATHExec
+    global AWS_CONF
+    AWS_CONF = settings
+    if not AWS_CONF.get('aws_tool_path'):
+        AWS_CONF['aws_tool_path'] = findPATHExec('aws')
+
+    if not AWS_CONF['aws_tool_path']:
+        return 'Unable to find "aws" in PATH - check the provider documentation and install the requirements'
+
+    if not os.path.isfile(AWS_CONF['aws_tool_path']):
+        path = AWS_CONF['aws_tool_path']
+        AWS_CONF['aws_tool_path'] = None
+        return 'The provided "aws" exec path is invalid: %s' % (path,)
+
+    global AWS_EXEC_PREFIX, AWS_CONFIGS
+    AWS_EXEC_PREFIX = (AWS_CONF['aws_tool_path'], '--output', 'json')
+    AWS_CONFIGS = None
+    configs = _getConfigs()
+
+    if not configs:
+        AWS_CONF['aws_tool_path'] = None
+        return 'Error during execution of "aws" tool'
+
+    print('INFO: Using aws tool:', AWS_CONF['aws_tool_path'])
+
+    if 'region' in configs:
+        print('INFO: Set region for aws tool: ' + configs['region'])
+        AWS_EXEC_PREFIX += ('--region', configs['region'])
+
+    return True
+
+def checkDependencies(settings):
+    if not AWS_CONF.get('aws_tool_path'):
+        return initProvider(settings)
+    return True
+
+def getSettings():
+    '''Returns the available settings of the provider'''
+    return {
+        'aws_exec_path': {
+            'name': 'Path to aws exec',
+            'description': 'Full path to the aws or aws.exe from AWS CLI v2, by default uses PATH env to find it',
+            'type': 'path',
+            'value': AWS_CONF.get('aws_tool_path'),
+        },
+        'bucket_name': {
+            'name': 'Bucket name',
+            'description': '''What the bucket to use - in case it's empty will create the new one as "blendnet-{session_id}"''',
+            'type': 'string',
+            'value': AWS_CONF.get('bucket_name', ''),
+        },
+    }
 
 def _getConfigs():
     '''Returns dict with aws tool configs'''
@@ -120,7 +148,7 @@ def _getConfigs():
     if not AWS_CONFIGS:
         configs = dict()
         # aws configure returns non-json table, so using direct call
-        result = subprocess.run([AWS_TOOL_PATH, 'configure', 'list'], stdout=subprocess.PIPE)
+        result = subprocess.run([AWS_CONF['aws_tool_path'], 'configure', 'list'], stdout=subprocess.PIPE)
         if result.returncode != 0:
             print('ERROR: Unable to get aws config: %s %s' % (result.returncode, result.stdout))
             return configs
@@ -133,7 +161,7 @@ def _getConfigs():
             data = data.decode('iso-8859-1').strip()
         for line in data.split(os.linesep)[2:]:
             param = line.split()[0]
-            result = subprocess.run([AWS_TOOL_PATH, 'configure', 'get', param], stdout=subprocess.PIPE)
+            result = subprocess.run([AWS_CONF['aws_tool_path'], 'configure', 'get', param], stdout=subprocess.PIPE)
             if result.returncode == 0:
                 try:
                     configs[param] = result.stdout.decode('utf-8').strip()
@@ -228,9 +256,11 @@ def _createRoles():
                         '--role-name', 'blendnet-agent')
         _executeAwsTool('iam', 'wait', 'instance-profile-exists',
                         '--instance-profile-name', 'blendnet-agent')
-    except AwsToolException:
-        # The blendnet-agent role is already exists
-        pass
+    except AwsToolException as e:
+        if '(EntityAlreadyExists)' not in str(e):
+            raise
+        print('INFO: Role blendnet-agent already exists')
+
 
     # Create blendnet-manager role
     try:
@@ -276,9 +306,10 @@ def _createRoles():
         # If it's not wait - we will see the next error during manager allocation
         # Value (blendnet-manager) for parameter iamInstanceProfile.name is invalid. Invalid IAM Instance Profile name
         time.sleep(30)
-    except AwsToolException:
-        # The blendnet-manager role is already exists
-        pass
+    except AwsToolException as e:
+        if '(EntityAlreadyExists)' not in str(e):
+            raise
+        print('INFO: Role blendnet-manager already exists')
 
 def _getImageAmi(name = 'debian-10-amd64-daily-*'):
     '''Gets the latest image per name filter'''
@@ -297,7 +328,7 @@ def _getInstanceId(instance_name):
                            ]),
                            '--query', 'Reservations[].Instances[].InstanceId')
     if len(data) != 1:
-        raise AwsToolException('Error in request of unique instance id with name "%s": %s' % (instance_name, data))
+        return None
 
     return data[0]
 
@@ -306,13 +337,10 @@ def createInstanceManager(cfg):
 
     _createRoles()
 
-    try:
-        inst_id = _getInstanceId(cfg['instance_name'])
-        # If it pass here - means the instance is already existing
+    inst_id = _getInstanceId(cfg['instance_name'])
+    if inst_id:
+        # The instance is already exists
         return inst_id
-    except AwsToolException:
-        # No instance existing - than we can proceed
-        pass
 
     image = _getImageAmi()
     disk_config = [{
@@ -345,9 +373,9 @@ fi
 cat <<'EOF' > /usr/local/bin/blendnet_cloud_init.sh
 #!/bin/sh
 echo '--> Update the BlendNet manager'
-aws s3 cp --recursive 's3://blendnet-{session_id}/work_manager' "$(getent passwd blendnet-user | cut -d: -f6)"
-aws s3 rm --recursive 's3://blendnet-{session_id}/work_manager'
-aws s3 cp --recursive 's3://blendnet-{session_id}/blendnet' /srv/blendnet
+aws s3 cp --recursive '{storage_url}/work_manager' "$(getent passwd blendnet-user | cut -d: -f6)"
+aws s3 rm --recursive '{storage_url}/work_manager'
+aws s3 cp --recursive '{storage_url}/blendnet' /srv/blendnet
 EOF
 
 chmod +x /usr/local/bin/blendnet_cloud_init.sh
@@ -381,7 +409,7 @@ systemctl start blendnet-manager.service
 '''.format(
         blender_url=cfg['dist_url'],
         blender_sha256=cfg['dist_checksum'],
-        session_id=cfg['session_id'],
+        storage_url=cfg['storage_url'],
     )
 
     options = [
@@ -411,13 +439,10 @@ systemctl start blendnet-manager.service
 def createInstanceAgent(cfg):
     '''Creating a new instance for BlendNet Agent'''
 
-    try:
-        inst_id = _getInstanceId(cfg['instance_name'])
-        # If it pass here - means the instance is already existing
+    inst_id = _getInstanceId(cfg['instance_name'])
+    if inst_id:
+        # The instance is already exists
         return inst_id
-    except AwsToolException:
-        # No instance existing - than we can proceed
-        pass
 
     image = _getImageAmi()
     disk_config = [{
@@ -450,8 +475,8 @@ fi
 cat <<'EOF' > /usr/local/bin/blendnet_cloud_init.sh
 #!/bin/sh
 echo '--> Update the BlendNet agent'
-aws s3 cp --recursive 's3://blendnet-{session_id}/work_{name}' "$(getent passwd blendnet-user | cut -d: -f6)"
-aws s3 cp --recursive 's3://blendnet-{session_id}/blendnet' /srv/blendnet
+aws s3 cp --recursive '{storage_url}/work_{instance_name}' "$(getent passwd blendnet-user | cut -d: -f6)"
+aws s3 cp --recursive '{storage_url}/blendnet' /srv/blendnet
 EOF
 
 chmod +x /usr/local/bin/blendnet_cloud_init.sh
@@ -485,8 +510,8 @@ systemctl start blendnet-agent.service
     '''.format(
         blender_url=cfg['dist_url'],
         blender_sha256=cfg['dist_checksum'],
-        session_id=cfg['session_id'],
-        name=cfg['instance_name'],
+        instance_name=cfg['instance_name'],
+        storage_url=cfg['storage_url'],
     )
 
     options = [
@@ -606,56 +631,84 @@ def createFirewall(target_group, port):
         # Waiting for the operation to completed
         _executeAwsTool('ec2', 'wait', 'security-group-exists',
                         '--group-names', target_group)
-    except AwsToolException:
-        # The blendnet-manager security group already exists
-        pass
+    except AwsToolException as e:
+        if '(InvalidGroup.Duplicate)' not in str(e):
+            raise
 
-def createBucket(bucket_name):
+def createStorage(storage_url):
     '''Creates bucket if it's not exists'''
 
-    _executeAwsTool('s3', 'mb', 's3://' + bucket_name)
+    try:
+        _executeAwsTool('s3', 'mb', storage_url)
+    except AwsToolException as e:
+        if '(BucketAlreadyOwnedByYou)' not in str(e):
+            raise
 
     return True
 
-def uploadFileToBucket(path, bucket_name, dest_path = None):
+def uploadFileToStorage(path, storage_url, dest_path = None):
     '''Upload file to the bucket'''
 
-    if not dest_path:
-        dest_path = path
+    if dest_path:
+        if platform.system() == 'Windows':
+            dest_path = pathlib.PurePath(dest_path).as_posix()
+        storage_url += '/' + dest_path
 
-    # If the plugin was called from Windows, we need to convert the path separators
-    if platform.system() == 'Windows':
-        dest_path = pathlib.PurePath(dest_path).as_posix()
+    print('INFO: Uploading file to "%s" ...' % (storage_url,))
+    _executeAwsTool('s3', 'cp', path, storage_url)
 
-    dest_path = 's3://%s/%s' % (bucket_name, dest_path)
+    return True
+
+def uploadRecursiveToStorage(path, storage_url, dest_path = None, include = None, exclude = None):
+    '''Recursively upload files to the storage'''
+
+    if dest_path:
+        if platform.system() == 'Windows':
+            dest_path = pathlib.PurePath(dest_path).as_posix()
+        storage_url += '/' + dest_path
+
+    print('INFO: AWS: Uploading files from %s to "%s" ...' % (path, storage_url))
 
-    print('INFO: Uploading file to "%s" ...' % (dest_path,))
-    _executeAwsTool('s3', 'cp', path, dest_path)
+    cmd = ['s3', 'cp', path, storage_url, '--recursive']
+    if include:
+        cmd += ['--include', include]
+    if exclude:
+        cmd += ['--exclude', exclude]
+
+    _executeAwsTool(*cmd)
+
+    print('INFO: AWS: Uploaded files to "%s"' % (storage_url,))
 
     return True
 
-def uploadDataToBucket(data, bucket_name, dest_path):
+def uploadDataToStorage(data, storage_url, dest_path = None):
     '''Upload data to the bucket'''
     # WARN: tmpfile is not allowed to use by subprocesses on Win
 
-    dest_path = 's3://%s/%s' % (bucket_name, dest_path)
+    if dest_path:
+        if platform.system() == 'Windows':
+            dest_path = pathlib.PurePath(dest_path).as_posix()
+        storage_url += '/' + dest_path
 
-    print('INFO: Uploading data to "%s" ...' % (dest_path,))
-    _executeAwsTool('s3', 'cp', '-', dest_path, data=data)
+    print('INFO: Uploading data to "%s" ...' % (storage_url,))
+    _executeAwsTool('s3', 'cp', '-', storage_url, data=data)
 
     return True
 
-def downloadDataFromBucket(bucket_name, path):
+def downloadDataFromStorage(storage_url, path = None):
     tmp_file = tempfile.NamedTemporaryFile()
 
-    path = 's3://%s/%s' % (bucket_name, path)
+    if path:
+        if platform.system() == 'Windows':
+            path = pathlib.PurePath(path).as_posix()
+        storage_url += '/' + path
 
-    print('INFO: Downloading file from "%s" ...' % (path,))
+    print('INFO: Downloading file from "%s" ...' % (storage_url,))
 
     try:
-        _executeAwsTool('s3', 'cp', path, tmp_file.name)
-    except AwsToolException:
-        print('WARN: Downloading failed')
+        _executeAwsTool('s3', 'cp', storage_url, tmp_file.name)
+    except AwsToolException as e:
+        print('WARN: Downloading failed', e)
         return None
 
     # The original tmp_file is unlinked, so reread it
@@ -716,9 +769,10 @@ def getManagerSizeDefault():
 def getAgentSizeDefault():
     return 't2.micro'
 
-def getBucketName(session_id):
-    '''Returns the appropriate bucket name'''
-    return 'blendnet-%s' % (session_id.lower(),)
+def getStorageUrl(session_id):
+    '''Returns the aws bucket url'''
+    default_name = 'blendnet-{session_id}'.format(session_id=session_id.lower())
+    return 's3://' + (AWS_CONF.get('bucket_name') or default_name)
 
 def getManagerName(session_id):
     return 'blendnet-%s-manager' % session_id
@@ -783,8 +837,6 @@ def getMinimalCheapPrice(inst_type):
     prices = _getZonesMinimalSpotPrice(inst_type).values()
     return min(prices) if prices else -1.0
 
-findAWSTool()
-
 from .Processor import Processor
 from .Manager import Manager
 from .Agent import Agent
diff --git a/BlendNet/providers/azure/Agent.py b/BlendNet/providers/azure/Agent.py
new file mode 100644
index 0000000..231e22a
--- /dev/null
+++ b/BlendNet/providers/azure/Agent.py
@@ -0,0 +1,11 @@
+#!/usr/bin/python3
+# -*- coding: UTF-8 -*-
+'''Azure Agent
+
+Description: Implementation of the Azure agent
+'''
+
+from .Instance import Instance
+
+class Agent(Instance):
+    pass
diff --git a/BlendNet/providers/azure/Instance.py b/BlendNet/providers/azure/Instance.py
new file mode 100644
index 0000000..94812e2
--- /dev/null
+++ b/BlendNet/providers/azure/Instance.py
@@ -0,0 +1,20 @@
+#!/usr/bin/python3
+# -*- coding: UTF-8 -*-
+'''Azure Instance
+
+Description: Implementation of the Azure instance
+'''
+
+import time
+
+from .. import InstanceProvider
+
+class Instance(InstanceProvider):
+    def __init__(self):
+        InstanceProvider.__init__(self)
+
+    def timeToTerminating(self):
+        '''Seconds to instance terminate'''
+        if not self.isTerminating():
+            return 24*3600
+        return self.timeOfTerminating() - time.time() + 60.0
diff --git a/BlendNet/providers/azure/Manager.py b/BlendNet/providers/azure/Manager.py
new file mode 100644
index 0000000..2873bde
--- /dev/null
+++ b/BlendNet/providers/azure/Manager.py
@@ -0,0 +1,11 @@
+#!/usr/bin/python3
+# -*- coding: UTF-8 -*-
+'''Azure Manager
+
+Description: Implementation of the Azure manager
+'''
+
+from .Instance import Instance
+
+class Manager(Instance):
+    pass
diff --git a/BlendNet/providers/azure/Processor.py b/BlendNet/providers/azure/Processor.py
new file mode 100644
index 0000000..21f86e3
--- /dev/null
+++ b/BlendNet/providers/azure/Processor.py
@@ -0,0 +1,9 @@
+#!/usr/bin/python3
+# -*- coding: UTF-8 -*-
+'''Azure Processor
+
+Description: Implementation of the Azure processor
+'''
+
+class Processor:
+    pass
diff --git a/BlendNet/providers/azure/__init__.py b/BlendNet/providers/azure/__init__.py
new file mode 100644
index 0000000..2005417
--- /dev/null
+++ b/BlendNet/providers/azure/__init__.py
@@ -0,0 +1,903 @@
+'''Microsoft Azure
+Provide API access to allocate required resources in Azure
+Dependencies: azure cli installed and configured auth
+Help: https://github.com/state-of-the-art/BlendNet/wiki/HOWTO:-Setup-provider:-Azure
+'''
+
+__all__ = [
+    'Processor',
+    'Manager',
+    'Agent',
+    'Instance',
+]
+
+# Exception to notify that the command returned exitcode != 0
+class AzToolException(Exception):
+    pass
+
+import os
+import sys
+import json
+import platform
+import tempfile
+import ssl
+import site
+import urllib
+import subprocess
+import pathlib
+import time
+import datetime as dt
+
+METADATA_URL = 'http://169.254.169.254/metadata/instance/'
+
+LOCATION = None # If the script is running in the cloud
+AZ_CONF = {}
+
+AZ_EXEC_OPTIONS = None
+AZ_CACHE_LOCATIONS = []
+AZ_CACHE_SIZES = None
+
+def _requestMetadata(path, verbose = False):
+    req = urllib.request.Request(METADATA_URL+path+'?api-version=2020-10-01&format=text"')
+    req.add_header('Metadata','true')
+    try:
+        while True:
+            with urllib.request.urlopen(req, timeout=1) as res:
+                if res.getcode() == 503:
+                    print('WARN: Azure: Unable to reach metadata serivce')
+                    time.sleep(5)
+                    continue
+                data = res.read()
+                try:
+                    return data.decode('utf-8')
+                except (LookupError, UnicodeDecodeError):
+                    # UTF-8 not worked, so probably it's latin1
+                    return data.decode('iso-8859-1')
+    except Exception as e:
+        if verbose:
+            print('WARN: Azure: Metadata is not available ' + path)
+        return None
+
+def checkLocation():
+    '''Returns True if it's the Azure environment'''
+    global LOCATION
+
+    if LOCATION is not None:
+        return LOCATION
+
+    LOCATION = _requestMetadata('compute/location', True) is not None
+    return LOCATION
+
+def _executeAzTool(*args, data=None):
+    '''Runs the az tool and returns code and data as tuple, data will be sent to stdin as bytes'''
+    cmd = (AZ_CONF.get('az_exec_path'),) + args + AZ_EXEC_OPTIONS
+    result = subprocess.run(cmd, input=data, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
+    if result.returncode != 0:
+        raise AzToolException('Az tool returned %d during execution of "%s": %s' % (
+            result.returncode, cmd, result.stderr))
+
+    data = None
+    try:
+        data = json.loads(result.stdout)
+    except UnicodeDecodeError as e:
+        print('WARN: Azure: Found UnicodeDecodeError during parsing of the az output, switching to ISO-8859-1:', str(e))
+        data = json.loads(result.stdout.decode('iso-8859-1'))
+    except json.decoder.JSONDecodeError:
+        try:
+            data = {'stdout': result.stdout.decode('utf-8')}
+        except (LookupError, UnicodeDecodeError):
+            # UTF-8 not worked, so probably it's latin1
+            data = {'stdout': result.stdout.decode('iso-8859-1')}
+
+    return data
+
+def _initAzTool():
+    '''Init the az cli with the required parameters'''
+    # Login on azure VM with identity
+    if checkLocation():
+        _executeAzTool('login', '--identity')
+
+    # Get available locations
+    global AZ_CACHE_SIZES, AZ_CACHE_LOCATIONS
+    AZ_CACHE_SIZES = None
+    locations = _executeAzTool('account', 'list-locations')
+    AZ_CACHE_LOCATIONS = [('please select', 'please select', 'please select')]
+    AZ_CACHE_LOCATIONS += sorted( (l['name'], l['name'], l['regionalDisplayName']) for l in locations )
+
+    return True
+
+def initProvider(settings = dict()):
+    '''Finds absolute path to the az tool'''
+    from .. import findPATHExec
+    global AZ_CONF
+    AZ_CONF = settings
+    if not AZ_CONF.get('az_exec_path'):
+        AZ_CONF['az_exec_path'] = findPATHExec('az')
+    if not AZ_CONF.get('location'):
+        AZ_CONF['location'] = 'westus'
+        if checkLocation():
+            AZ_CONF['location'] = _requestMetadata('instance/location')
+    if not AZ_CONF.get('resource_group'):
+        AZ_CONF['resource_group'] = _requestMetadata('instance/resourceGroupName') if checkLocation() else 'blendnet'
+    if not AZ_CONF.get('storage_account'):
+        AZ_CONF['storage_account'] = 'blendnet{session_id}'
+
+    if not AZ_CONF['az_exec_path']:
+        return 'Unable to find "az" in PATH - check the provider documentation and install the requirements'
+
+    if not os.path.isfile(AZ_CONF['az_exec_path']):
+        path = AZ_CONF['az_exec_path']
+        AZ_CONF['az_exec_path'] = {}
+        return 'The provided "az" exec path is invalid: %s' % (path,)
+
+    global AZ_EXEC_OPTIONS
+    AZ_EXEC_OPTIONS = ('--output', 'json')
+
+    if not _initAzTool():
+        AZ_CONF['az_exec_path'] = None
+        return 'Error during execution of "az" tool'
+
+    print('INFO: Azure: Using az tool:', AZ_CONF['az_exec_path'])
+
+    return True
+
+def checkDependencies(settings):
+    if not AZ_CONF.get('az_exec_path'):
+        return initProvider(settings)
+    return True
+
+def _getLocationItems(scene = None, context = None):
+    '''Will return items for enum blender property'''
+    return AZ_CACHE_LOCATIONS
+
+def getSettings():
+    '''Returns the available settings of the provider'''
+    return {
+        'az_exec_path': {
+            'name': 'Path to az exec',
+            'description': 'Full path to the az or az.exe from Azure CLI, by default uses PATH env to find it',
+            'type': 'path',
+            'value': AZ_CONF.get('az_exec_path'),
+        },
+        'location': {
+            'name': 'Location of resources',
+            'description': 'Select the required location for resources provision',
+            'type': 'choice',
+            'values': _getLocationItems,
+            'value': AZ_CONF.get('location'),
+        },
+        'resource_group': {
+            'name': 'Resource group',
+            'description': 'Set the resource group name to organize your resources, will be created if not exists',
+            'type': 'string',
+            'value': AZ_CONF.get('resource_group'),
+        },
+        'storage_account': {
+            'name': 'Storage account',
+            'description': '''What kind of storage account to use - in case it's empty will create the new one as "blendnet{session_id}"''',
+            'type': 'string',
+            'value': AZ_CONF.get('storage_account'),
+        },
+        'storage_container': {
+            'name': 'Storage container',
+            'description': '''What the storage container to use - in case it's empty will create the new one as "blendnet-{session_id}"''',
+            'type': 'string',
+            'value': AZ_CONF.get('storage_container'),
+        },
+    }
+
+def _getInstanceTypeInfo(name):
+    '''Get info about the instance type'''
+    try:
+        # Update the cache
+        getInstanceTypes()
+        return { 'cpu': AZ_CACHE_SIZES[name][0], 'mem': AZ_CACHE_SIZES[name][1] }
+    except:
+        print('ERROR: Azure: Unable to get the Azure machine type info for:', name)
+
+    return None
+
+def _verifyQuotas(avail):
+    try:
+        import bpy
+    except:
+        return []
+
+    errors = []
+
+    prefs = bpy.context.preferences.addons[__package__.split('.', 1)[0]].preferences
+    manager_info = _getInstanceTypeInfo(prefs.manager_instance_type)
+    agents_info = _getInstanceTypeInfo(prefs.manager_agent_instance_type)
+    agents_num = prefs.manager_agents_max
+
+    # Manager
+    if manager_info:
+        if avail.get('Total vCPUs', 0) < manager_info['cpu']:
+            errors.append('Available "Total vCPUs" is too small to provision the Manager')
+        if avail.get('IP Addresses', 0) < 1: # External addresses
+            errors.append('Available "Public IP Addresses" is too small to provision the Manager')
+    else:
+        errors.append('Unable to get the Manager type info to validate quotas')
+
+    # Agents
+    if agents_info:
+        if avail.get('Total vCPUs', 0) < agents_info['cpu'] * agents_num:
+            errors.append('Available "Total vCPUs" is too small to provision the Agents')
+    else:
+        errors.append('Unable to get the Agents type info to validate quotas')
+
+    # Common
+    if manager_info and agents_info:
+        if avail.get('Virtual Machines', 0) < 1 + agents_num:
+            errors.append('Available "Virtual Machines" is too small to provision the Manager and Agents')
+    else:
+        errors.append('Unable to get the Manager and Agents type info to validate quotas')
+
+    if errors:
+        errors.append('You can request Azure project quotas increase to get better experience')
+
+    return errors
+
+def getProviderInfo():
+    configs = dict()
+    try:
+        useful_quotas = {
+            'cores': 'Total vCPUs',
+            'virtualMachines': 'Virtual Machines',
+            'PublicIPAddresses': 'IP Addresses',
+        }
+
+        avail = {}
+
+        # VM quotas
+        data = _executeAzTool('vm', 'list-usage', '--location', AZ_CONF['location'])
+
+        for q in data:
+            if q['name']['value'] in useful_quotas:
+                avail[useful_quotas[q['name']['value']]] = float(q['limit']) - float(q['currentValue'])
+                configs['Quota: ' + useful_quotas[q['name']['value']]] = '%s, usage: %s' % (q['limit'], q['currentValue'])
+
+        # Network quotas
+        data = _executeAzTool('network', 'list-usages', '--location', AZ_CONF['location'])
+
+        for q in data:
+            if q['name']['value'] in useful_quotas:
+                avail[useful_quotas[q['name']['value']]] = float(q['limit']) - float(q['currentValue'])
+                configs['Quota: ' + useful_quotas[q['name']['value']]] = '%s, usage: %s' % (q['limit'], q['currentValue'])
+
+        errors = _verifyQuotas(avail)
+        if errors:
+            configs['ERRORS'] = errors
+
+    except AzToolException as e:
+        configs['ERRORS'] = ['Looks like access to the API is restricted '
+                             '- please check your permissions: %s' % e]
+
+    return configs
+
+def getInstanceTypes():
+    global AZ_CACHE_SIZES
+    try:
+        if not AZ_CACHE_SIZES:
+            data = _executeAzTool('vm', 'list-sizes', '--location', AZ_CONF['location'])
+            AZ_CACHE_SIZES = dict([ (d['name'], (d['numberOfCores'], d['memoryInMb'])) for d in data ])
+        return dict([ (k, ('%s vCPUs %s GB RAM' % (v[0], v[1]/1024.0), v[1]/1024.0)) for k, v in AZ_CACHE_SIZES.items() ])
+    except AzToolException as e:
+        return {'ERROR': 'Looks like access to the API is restricted '
+                         '- please check your permissions: %s' % e}
+    return {}
+
+def _createResourceGroup():
+    '''Will check if the resource group existing and create if it's not'''
+    data = _executeAzTool('group', 'list', '--query', "[?location=='{}']".format(AZ_CONF['location']))
+    groups_list = ( res['name'] for res in data )
+    if AZ_CONF['resource_group'] not in groups_list:
+        _executeAzTool('group', 'create', '--location', AZ_CONF['location'], '--name', AZ_CONF['resource_group'])
+
+def _createIdentities():
+    '''Will ensure the required identities are here'''
+
+    print('INFO: Azure: Creating the identity blendnet-agent')
+    agent = _executeAzTool('identity', 'create',
+                           '--location', AZ_CONF['location'],
+                           '--resource-group', AZ_CONF['resource_group'],
+                           '--name', 'blendnet-agent')
+
+    print('INFO: Azure: Creating the identity blendnet-manager')
+    mngr = _executeAzTool('identity', 'create',
+                          '--location', AZ_CONF['location'],
+                          '--resource-group', AZ_CONF['resource_group'],
+                          '--name', 'blendnet-manager')
+
+    # Create assignments after idenities, because they take some time appear
+
+    # Use Reader access for Agent to download data from containers
+    _executeAzTool('role', 'assignment', 'create',
+                   '--role', 'Reader and Data Access',
+                   '--assignee-object-id', agent['principalId'],
+                   '--description', 'Allow to download from storage for BlendNet Agent',
+                   '--resource-group', AZ_CONF['resource_group'])
+
+    # Use Network access for Manager to create VM
+    _executeAzTool('role', 'assignment', 'create',
+                   '--role', 'Network Contributor',
+                   '--assignee-object-id', mngr['principalId'],
+                   '--description', 'Allow to create Agent VMs for BlendNet Manager',
+                   '--resource-group', AZ_CONF['resource_group'])
+
+    # Create VM access for Manager
+    _executeAzTool('role', 'assignment', 'create',
+                   '--role', 'Virtual Machine Contributor',
+                   '--assignee-object-id', mngr['principalId'],
+                   '--description', 'Allow to create Agent VMs for BlendNet Manager',
+                   '--resource-group', AZ_CONF['resource_group'])
+
+    # Use blendnet-agent identity access for Manager
+    _executeAzTool('role', 'assignment', 'create',
+                   '--role', 'Managed Identity Operator',
+                   '--assignee-object-id', mngr['principalId'],
+                   '--description', 'Allow to create Agent VMs for BlendNet Manager',
+                   '--scope', agent['id'])
+
+    print('INFO: Azure: Created identities')
+
+def createInstanceManager(cfg):
+    '''Creating a new instance for BlendNet Manager'''
+    _createResourceGroup()
+    _createIdentities()
+
+    image = 'Debian:debian-10:10:latest'
+
+    account = urllib.parse.urlparse(cfg['storage_url']).hostname.split('.')[0]
+    container = urllib.parse.urlparse(cfg['storage_url']).path.split('/')[-1]
+
+    # TODO: make script overridable
+    # TODO: too much hardcode here
+    startup_script = '''#!/bin/sh
+echo '--> Check for blender dependencies'
+dpkg -l libxrender1 libxi6 libgl1
+if [ $? -gt 0 ]; then
+    apt update
+    until apt install --no-install-recommends -y libxrender1 libxi6 libgl1; do
+        echo "Unable to install blender dependencies, repeating..."
+        sleep 5
+    done
+fi
+
+if [ ! -x /srv/blender/blender ]; then
+    echo '--> Download & unpack blender'
+    echo "{blender_sha256} -" > /tmp/blender.sha256
+    curl -fLs "{blender_url}" | tee /tmp/blender.tar.bz2 | sha256sum -c /tmp/blender.sha256 || (echo "ERROR: checksum of the blender binary is incorrect"; exit 1)
+    mkdir -p /srv/blender
+    tar -C /srv/blender --strip-components=1 --checkpoint=10000 --checkpoint-action=echo='Unpacked %{{r}}T' -xf /tmp/blender.tar.bz2
+fi
+
+# Azure instances has no preinstalled az cli
+if ! which az; then
+    echo '--> Install az CLI'
+    curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash
+fi
+
+cat <<'EOF' > /usr/local/bin/blendnet_cloud_init.sh
+#!/bin/sh -e
+
+# Login to identity
+az login --identity
+
+echo '--> Update the BlendNet manager'
+az storage copy --recursive --source-account-name {storage_account} --source-container {storage_name} --source-blob 'work_manager/*' -d "$(getent passwd blendnet-user | cut -d: -f6)"
+# Remove not working due to exception: Exception: MSI auth not yet supported.
+# az storage remove --recursive --account-name {storage_account} --container-name {storage_name} --name work_manager
+az storage blob delete-batch --account-name {storage_account} --source {storage_name} --pattern 'work_manager/*'
+az storage copy --recursive --source-account-name {storage_account} --source-container {storage_name} --source-blob 'blendnet' -d /srv
+
+chown -R blendnet-user .azure .azcopy
+EOF
+
+chmod +x /usr/local/bin/blendnet_cloud_init.sh
+adduser --shell /bin/false --disabled-password blendnet-user
+
+cat <<'EOF' > /etc/systemd/system/blendnet-manager.service
+[Unit]
+Description=BlendNet Manager Service
+After=network-online.target google-network-daemon.service
+
+[Service]
+User=blendnet-user
+WorkingDirectory=~
+Type=simple
+ExecStartPre=+/usr/local/bin/blendnet_cloud_init.sh
+ExecStart=/srv/blender/blender -b -noaudio -P /srv/blendnet/manager.py
+Restart=always
+TimeoutStopSec=60
+StandardOutput=syslog
+StandardError=syslog
+
+[Install]
+WantedBy=multi-user.target
+EOF
+
+echo '--> Run the BlendNet manager'
+systemctl daemon-reload
+systemctl enable blendnet-manager.service
+systemctl start blendnet-manager.service
+'''.format(
+        blender_url=cfg['dist_url'],
+        blender_sha256=cfg['dist_checksum'],
+        session_id=cfg['session_id'],
+        storage_account=account,
+        storage_name=container,
+    )
+
+    options = [
+        'vm', 'create',
+        '--name', cfg['instance_name'],
+        '--resource-group', AZ_CONF['resource_group'],
+        '--image', image,
+        '--size', cfg['instance_type'],
+        '--boot-diagnostics-storage', 'https://'+urllib.parse.urlparse(cfg['storage_url']).hostname+'/',
+        '--os-disk-size-gb', '200',
+        '--generate-ssh-keys', # For ssh access use '--admin-username', 'blendnet-admin', '--ssh-key-values', '@/home/user/.ssh/id_rsa.pub',
+        '--assign-identity', 'blendnet-manager',
+        '--nsg', 'blendnet-manager',
+        '--custom-data', startup_script,
+        # "vm" tag is used to remove the related VM resources
+        '--tags', 'app=blendnet', 'session_id='+cfg['session_id'], 'type=manager', 'vm='+cfg['instance_name'],
+    ]
+
+    # Creating an instance
+    print('INFO: Azure: Creating manager', cfg['instance_name'])
+    _executeAzTool(*options)
+
+    return cfg['instance_name']
+
+def createInstanceAgent(cfg):
+    '''Creating a new instance for BlendNet Agent'''
+
+    image = 'Debian:debian-10:10:latest'
+
+    account = urllib.parse.urlparse(cfg['storage_url']).hostname.split('.')[0]
+    container = urllib.parse.urlparse(cfg['storage_url']).path.split('/')[-1]
+    # TODO: make script overridable
+    # TODO: too much hardcode here
+    startup_script = '''#!/bin/sh
+echo '--> Check for blender dependencies'
+dpkg -l libxrender1 libxi6 libgl1
+if [ $? -gt 0 ]; then
+    apt update
+    until apt install --no-install-recommends -y libxrender1 libxi6 libgl1; do
+        echo "Unable to install blender dependencies, repeating..."
+        sleep 5
+    done
+fi
+
+if [ ! -x /srv/blender/blender ]; then
+    echo '--> Download & unpack blender'
+    echo "{blender_sha256} -" > /tmp/blender.sha256
+    curl -fLs "{blender_url}" | tee /tmp/blender.tar.bz2 | sha256sum -c /tmp/blender.sha256 || (echo "ERROR: checksum of the blender binary is incorrect"; exit 1)
+    mkdir -p /srv/blender
+    tar -C /srv/blender --strip-components=1 --checkpoint=10000 --checkpoint-action=echo='Unpacked %{{r}}T' -xf /tmp/blender.tar.bz2
+fi
+
+# Azure instances has no preinstalled az cli
+if ! which az; then
+    echo '--> Install az CLI'
+    curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash
+fi
+
+cat <<'EOF' > /usr/local/bin/blendnet_cloud_init.sh
+#!/bin/sh -e
+
+# Login to identity
+az login --identity
+
+echo '--> Update the BlendNet agent'
+az storage copy --recursive --source-account-name {storage_account} --source-container {storage_name} --source-blob 'work_{instance_name}/*' -d "$(getent passwd blendnet-user | cut -d: -f6)"
+az storage copy --recursive --source-account-name {storage_account} --source-container {storage_name} --source-blob 'blendnet' -d /srv
+
+chown -R blendnet-user .azure .azcopy
+EOF
+
+chmod +x /usr/local/bin/blendnet_cloud_init.sh
+adduser --shell /bin/false --disabled-password blendnet-user
+
+cat <<'EOF' > /etc/systemd/system/blendnet-agent.service
+[Unit]
+Description=BlendNet Agent Service
+After=network-online.target google-network-daemon.service
+
+[Service]
+User=blendnet-user
+WorkingDirectory=~
+Type=simple
+ExecStartPre=+/usr/local/bin/blendnet_cloud_init.sh
+ExecStart=/srv/blender/blender -b -noaudio -P /srv/blendnet/agent.py
+Restart=always
+TimeoutStopSec=20
+StandardOutput=syslog
+StandardError=syslog
+
+[Install]
+WantedBy=multi-user.target
+EOF
+
+echo '--> Run the BlendNet agent'
+systemctl daemon-reload
+systemctl enable blendnet-agent.service
+systemctl start blendnet-agent.service
+    '''.format(
+        blender_url=cfg['dist_url'],
+        blender_sha256=cfg['dist_checksum'],
+        storage_account=account,
+        storage_name=container,
+        instance_name=cfg['instance_name'],
+    )
+
+    options = [
+        'vm', 'create',
+        '--name', cfg['instance_name'],
+        '--resource-group', AZ_CONF['resource_group'],
+        '--image', image,
+        '--size', cfg['instance_type'],
+        '--os-disk-size-gb', '200',
+        '--boot-diagnostics-storage', 'https://'+urllib.parse.urlparse(cfg['storage_url']).hostname+'/',
+        '--generate-ssh-keys', # For ssh access use '--admin-username', 'blendnet-admin', '--ssh-key-values', '<place_pubkey_here>',
+        '--assign-identity', 'blendnet-agent',
+        '--nsg', 'blendnet-agent',
+        '--public-ip-address', '', # Disable public IP address for the agent (comment it for ssh access)
+        '--custom-data', startup_script,
+        # "vm" tag is used to remove the related VM resources
+        '--tags', 'app=blendnet', 'session_id='+cfg['session_id'], 'type=agent', 'vm='+cfg['instance_name'],
+    ]
+
+    if cfg['use_cheap_instance']:
+        # Running cheap instance
+        print('INFO: Azure: Running cheap agent instance with max price %f (min %f)' % (
+            cfg['instance_max_price'],
+            getMinimalCheapPrice(cfg['instance_type']),
+        ))
+        options.append('--priority')
+        options.append('Spot')
+        options.append('--max-price')
+        options.append(str(cfg['instance_max_price']))
+        options.append('--eviction-policy')
+        options.append('Delete')
+
+    # Creating an instance
+    print('INFO: Azure: Creating agent %s' % (cfg['instance_name'],))
+    _executeAzTool(*options)
+
+    return cfg['instance_name']
+
+def startInstance(instance_id):
+    '''Start stopped instance with specified name'''
+
+    _executeAzTool('vm', 'start',
+                   '--resource-group', AZ_CONF['resource_group'],
+                   '--name', instance_id)
+
+def stopInstance(instance_id):
+    '''Stop instance with specified name'''
+
+    _executeAzTool('vm', 'stop',
+                   '--resource-group', AZ_CONF['resource_group'],
+                   '--name', instance_id)
+
+def deleteInstance(instance_id):
+    '''Delete the instance with specified name'''
+    # WARNING: Uses "vm" tag to remove all the related resources
+
+    # Get resources with the res = instance_id
+    toremove_ids = _executeAzTool('resource', 'list',
+                                  '--tag', 'vm=' + instance_id, '--query', '[].id')
+    if len(toremove_ids) < 5:
+        print('WARN: Azure: Not enough resources for VM to remove (5 needed): %s' % (toremove_ids,))
+
+    # Clean the related resources
+    # Sometimes the resources are failed to delete, so repeat until done
+    for i in range(5):
+        try:
+            _executeAzTool('resource', 'delete',
+                           '--resource-group', AZ_CONF['resource_group'],
+                           '--ids', *toremove_ids)
+        except AzToolException as e:
+            if 'Some resources failed to be deleted' not in str(e):
+                print('ERROR: Unable to delete resources:', e)
+        print('WARN: Repeat deleting of the resources to be sure', i, toremove_ids)
+        time.sleep(1)
+
+def createFirewall(target_group, port):
+    '''Create minimal firewall to access Manager / Agent'''
+
+    # Create the network security group
+    print('INFO: Azure: Creating security group for %s' % (target_group,))
+    _executeAzTool('network', 'nsg', 'create',
+                   '--name', target_group,
+                   '--location', AZ_CONF['location'],
+                   '--resource-group', AZ_CONF['resource_group'])
+    # Disable SSH access
+    _executeAzTool('network', 'nsg', 'rule', 'create',
+                   '--name', 'inbound-ssh',
+                   '--resource-group', AZ_CONF['resource_group'],
+                   '--nsg-name', target_group,
+                   '--priority', '1000',
+                   '--access', 'Deny', # Change 'Deny' to 'Allow' in case you need SSH access
+                   '--direction', 'Inbound',
+                   '--protocol', 'Tcp',
+                   '--destination-port-ranges', '22',
+                   '--destination-address-prefixes', '0.0.0.0/0')
+    # Allow blendnet ports access
+    _executeAzTool('network', 'nsg', 'rule', 'create',
+                   '--name', 'inbound-https',
+                   '--resource-group', AZ_CONF['resource_group'],
+                   '--nsg-name', target_group,
+                   '--priority', '1001',
+                   '--access', 'Allow',
+                   '--direction', 'Inbound',
+                   '--protocol', 'Tcp',
+                   '--destination-port-ranges', str(port),
+                   '--destination-address-prefixes', '10.0.0.0/8' if target_group == 'blendnet-agent' else '0.0.0.0/0')
+
+def createStorage(storage_url):
+    '''Creates storage if it's not exists'''
+
+    _createResourceGroup()
+
+    print('INFO: Azure: Creating storage %s ...' % (storage_url,))
+
+    account = urllib.parse.urlparse(storage_url).hostname.split('.')[0]
+    container = urllib.parse.urlparse(storage_url).path.split('/')[-1]
+
+    # Using storage account / storage container for azure
+    _executeAzTool('storage', 'account', 'create',
+                   '--name', account,
+                   '--location', AZ_CONF['location'],
+                   '--resource-group', AZ_CONF['resource_group'])
+
+    # Wait for account
+    while _executeAzTool('storage', 'account', 'check-name',
+                         '--name', account).get('nameAvailable'):
+        print('DEBUG: Azure: Waiting for account creation')
+
+    _executeAzTool('storage', 'container', 'create',
+                   '--name', container,
+                   '--account-name', account)
+
+    # Wait for container
+    while not _executeAzTool('storage', 'container', 'exists',
+                             '--name', container, '--account-name', account).get('exists'):
+        print('DEBUG: Azure: Waiting for container creation')
+
+    return True
+
+def uploadFileToStorage(path, storage_url, dest_path = None):
+    '''Upload file to the storage'''
+
+    if dest_path:
+        if platform.system() == 'Windows':
+            dest_path = pathlib.PurePath(dest_path).as_posix()
+        storage_url += '/' + dest_path
+
+    # Weird bug in az copy, it don't like relative paths not started with dir
+    if not os.path.isabs(path):
+        path = os.path.join('.', path)
+
+    print('INFO: Azure: Uploading file to %s ...' % (storage_url,))
+
+    _executeAzTool('storage', 'copy',
+                   '--source-local-path', path,
+                   '--destination', storage_url)
+
+    return True
+
+def uploadRecursiveToStorage(path, storage_url, dest_path = None, include = None, exclude = None):
+    '''Recursively upload files to the storage'''
+
+    if dest_path:
+        if platform.system() == 'Windows':
+            dest_path = pathlib.PurePath(dest_path).as_posix()
+        storage_url += '/' + dest_path
+
+    print('INFO: Azure: Uploading files from %s to "%s" ...' % (path, storage_url))
+
+    cmd = ['storage', 'copy', '--recursive', '--source-local-path', os.path.join(path, '*'), '--destination', storage_url]
+    if include:
+        cmd += ['--include-pattern', include]
+    if exclude:
+        cmd += ['--exclude-pattern', exclude]
+
+    _executeAzTool(*cmd)
+
+    print('INFO: Azure: Uploaded files to "%s"' % (storage_url,))
+
+    return True
+
+def uploadDataToStorage(data, storage_url, dest_path = None):
+    '''Upload data to the storage'''
+    # WARN: tempfile.NamedTemporaryFile is not allowed to be used by a subprocesses on Win
+
+    # No way to use az cli to upload stdin data, so using temp dir & file
+    with tempfile.TemporaryDirectory(prefix='blendnet') as temp_dir_name:
+        temp_file = os.path.join(temp_dir_name, 'upload_file')
+        with open(temp_file, 'wb') as fd:
+            fd.write(data)
+            fd.flush()
+
+        if dest_path:
+            if platform.system() == 'Windows':
+                dest_path = pathlib.PurePath(dest_path).as_posix()
+            storage_url += '/' + dest_path
+
+        print('INFO: Azure: Uploading data to "%s" ...' % (storage_url,))
+        _executeAzTool('storage', 'copy',
+                       '--source-local-path', temp_file,
+                       '--destination', storage_url)
+
+    return True
+
+def downloadDataFromStorage(storage_url, path = None):
+    temp_file = tempfile.NamedTemporaryFile()
+
+    if path:
+        if platform.system() == 'Windows':
+            path = pathlib.PurePath(path).as_posix()
+        storage_url += '/' + path
+
+    print('INFO: Azure: Downloading file from "%s" ...' % (path,))
+
+    try:
+        _executeAzTool('storage', 'copy',
+                       '--source', storage_url,
+                       '--destination-local-path', temp_file.name)
+    except AzToolException:
+        print('WARN: Azure: Download operation failed')
+        return None
+
+    # The original temp_file is unlinked, so reread it
+    with open(temp_file.name, 'rb') as fh:
+        return fh.read()
+
+def getResources(session_id):
+    '''Get the allocated resources with a specific session_id'''
+    out = {'agents':{}}
+
+    def parseInstanceInfo(it):
+        try:
+            return {
+                'id': it.get('name'),
+                'name': it.get('name'),
+                'ip': it.get('publicIps'),
+                'internal_ip': it['privateIps'],
+                'type': it['hardwareProfile']['vmSize'],
+                'started': it['powerState'] == 'VM running',
+                'stopped': it['powerState'] == 'VM stopped',
+                'created': 'unknown', # TODO: actually available in resources, but not sure it's worth the delay
+            }
+        except:
+            return None
+
+    data = _executeAzTool('vm', 'list', '--show-details',
+                          '--resource-group', AZ_CONF['resource_group'],
+                          '--query', "[?tags.session_id == '%s']" % (session_id,))
+
+    # Azure left the disks sometimes, so need to clean the unattached ones
+    # and btw getting the instance creation date
+    disks = _executeAzTool('disk', 'list',
+                           '--resource-group', AZ_CONF['resource_group'],
+                           '--query', "[?tags.session_id == '%s']" % (session_id,))
+    vm_dates = dict()
+    for disk in disks:
+        vm_dates[disk.get('tags', {}).get('vm')] = disk.get('timeCreated')
+        if disk.get('diskState') != 'Unattached':
+            continue
+        if (dt.datetime.now(dt.timezone.utc) - dt.datetime.fromisoformat(disk.get('timeCreated'))).seconds < 120:
+            continue
+        print('INFO: Azure: Destroying stale disk:', disk.get('name'))
+        _executeAzTool('disk', 'delete', '--no-wait', '--yes', '--ids', disk.get('id'))
+
+    for it in data:
+        inst = parseInstanceInfo(it)
+        if not inst:
+            continue
+        inst['created'] = vm_dates.get(inst['id'], 'unknown')
+        it_type = it['tags'].get('type')
+        if it_type == 'manager':
+            out['manager'] = inst
+        elif it_type == 'agent':
+            out['agents'][inst['name']] = inst
+        else:
+            print('WARN: Azure: Unknown type resource instance', inst['name'])
+
+    return out
+
+def getNodeLog(instance_id):
+    '''Get the instance serial output log'''
+    data = _executeAzTool('vm', 'boot-diagnostics', 'get-boot-log',
+                          '--resource-group', AZ_CONF['resource_group'],
+                          '--name', instance_id)
+
+    return data.get('stdout')
+
+def getManagerSizeDefault():
+    return 'Standard_A1_v2'
+
+def getAgentSizeDefault():
+    # Standard_B and some other are not support Spot VMs
+    # https://docs.microsoft.com/en-us/azure/virtual-machines/spot-vms#limitations
+    return 'Standard_A1_v2'
+
+def getStorageUrl(session_id):
+    '''Returns the azure storage url'''
+    default_account = 'blendnet{session_id}'.format(session_id=session_id.lower())
+    default_name = 'blendnet-{session_id}'.format(session_id=session_id.lower())
+    return 'https://%s.blob.core.windows.net/%s' % (
+        (AZ_CONF.get('storage_account') or default_account).format(session_id=session_id.lower()),
+        (AZ_CONF.get('storage_container') or default_name).format(session_id=session_id.lower()),
+    )
+
+def getManagerName(session_id):
+    return 'blendnet-%s-manager' % session_id
+
+def getAgentsNamePrefix(session_id):
+    return 'blendnet-%s-agent-' % session_id
+
+def getCheapMultiplierList():
+    '''Azure supports spot instances which is market based on spot price'''
+    return [0.35] + [ i/100.0 for i in range(1, 100) ]
+
+def getPrice(inst_type, cheap_multiplier):
+    '''Returns the price of the instance type per hour for the current region'''
+    ctx = ssl.create_default_context()
+    for path in site.getsitepackages():
+        path = os.path.join(path, 'certifi', 'cacert.pem')
+        if not os.path.exists(path):
+            continue
+        ctx.load_verify_locations(cafile=path)
+        break
+
+    if len(ctx.get_ca_certs()) == 0:
+        ctx.check_hostname = False
+        ctx.verify_mode = ssl.CERT_NONE
+
+    url = 'https://prices.azure.com/api/retail/prices'
+    filt = "priceType eq 'Consumption' and serviceName eq 'Virtual Machines' and " \
+           "armRegionName eq '%s' and armSkuName eq '%s'" % (AZ_CONF['location'], inst_type)
+    params = urllib.parse.urlencode({'$filter': filt})
+    url += '?' + params
+    req = urllib.request.Request(url)
+    try:
+        while True:
+            with urllib.request.urlopen(req, timeout=5, context=ctx) as res:
+                if res.getcode() == 503:
+                    print('WARN: Azure: Unable to reach price url')
+                    time.sleep(5)
+                    continue
+                data = json.load(res)
+                for d in data['Items']:
+                    # Skip windows prices & low priority machines
+                    if d['productName'].endswith('Windows') or d['skuName'].endswith('Low Priority'):
+                        continue
+
+                    # Return spot price only if multiplier <0 is selected
+                    if cheap_multiplier < 0:
+                        if not d['skuName'].endswith('Spot'):
+                            continue
+                        return (d['unitPrice'], d['currencyCode'])
+                    elif d['skuName'].endswith('Spot'):
+                        continue
+
+                    return (d['unitPrice'] * cheap_multiplier, d['currencyCode'])
+
+                return (-1.0, 'ERR: Unable to find the price')
+    except Exception as e:
+        print('WARN: Azure: Error during getting the instance type price:', url, e)
+        return (-1.0, 'ERR: ' + str(e))
+
+def getMinimalCheapPrice(inst_type):
+    '''getPrice returns minimal Spot price'''
+    return getPrice(inst_type, -1)[0]
+
+from .Processor import Processor
+from .Manager import Manager
+from .Agent import Agent
+from .Instance import Instance
diff --git a/BlendNet/providers/gcp/__init__.py b/BlendNet/providers/gcp/__init__.py
index 2ac24b6..bb79789 100644
--- a/BlendNet/providers/gcp/__init__.py
+++ b/BlendNet/providers/gcp/__init__.py
@@ -16,13 +16,17 @@ import os.path
 import time
 import pathlib
 import platform
-import urllib.request
+import urllib
 import subprocess
 
+from ...Workers import Workers
+
 METADATA_URL = 'http://metadata.google.internal/computeMetadata/v1/'
 METADATA_HEADER = ('Metadata-Flavor', 'Google')
 
 LOCATION = None # If the script is running in the cloud
+GCP_CONF = {}
+
 GOOGLE_CLOUD_SDK_ROOT = None
 GOOGLE_CLOUD_SDK_CREDS = None
 GOOGLE_CLOUD_SDK_CONFIGS = None
@@ -60,22 +64,63 @@ def checkLocation():
 
 def setGoogleCloudSdk(path):
     global GOOGLE_CLOUD_SDK_ROOT
+    unloadGoogleCloudSdk()
     if os.path.isdir(path) and os.path.isdir('%s/platform' % path):
-        print('INFO: Found google cloud sdk: %s' % path)
+        print('INFO: Found google cloud sdk:', path)
         GOOGLE_CLOUD_SDK_ROOT = path
         return True
+    else:
+        GOOGLE_CLOUD_SDK_ROOT = None
 
     return False
 
-def findGoogleCloudSdk():
+def unloadGoogleCloudSdk():
+    print('DEBUG: Unloading gcloud paths:', GOOGLE_CLOUD_SDK_ROOT)
+    paths = (
+        '%s/lib/third_party' % GOOGLE_CLOUD_SDK_ROOT,
+        '%s/platform/bq/third_party' % GOOGLE_CLOUD_SDK_ROOT,
+        '%s/lib' % GOOGLE_CLOUD_SDK_ROOT,
+    )
+    for path in paths:
+        if path in sys.path:
+            sys.path.remove(path)
+
+def loadGoogleCloudSdk():
+    print('DEBUG: Loading gcloud paths:', GOOGLE_CLOUD_SDK_ROOT)
+    paths = (
+        '%s/lib/third_party' % GOOGLE_CLOUD_SDK_ROOT,
+        '%s/platform/bq/third_party' % GOOGLE_CLOUD_SDK_ROOT,
+        '%s/lib' % GOOGLE_CLOUD_SDK_ROOT,
+    )
+    for path in paths:
+        sys.path.append(path)
+
+    # Init credentials and properties
+    _getCreds()
+
+def initProvider(settings = dict()):
     '''Will try to find the google cloud sdk home directory'''
-    # Windows doesn't use PATH to locate binary unless shell=True
-    result = subprocess.run(['gcloud', 'info'],
-                            shell=(platform.system() == 'Windows'),
-                            stdout=subprocess.PIPE)
+    from .. import findPATHExec
+    global GCP_CONF
+    GCP_CONF = settings
+    if not GCP_CONF.get('gcloud_exec_path'):
+        GCP_CONF['gcloud_exec_path'] = findPATHExec('gcloud')
+
+    if not GCP_CONF['gcloud_exec_path']:
+        return 'Unable to find "gcloud" in PATH - check the provider documentation and install the requirements'
 
+    if not os.path.isfile(GCP_CONF['gcloud_exec_path']):
+        path = GCP_CONF['gcloud_exec_path']
+        GCP_CONF['gcloud_exec_path'] = None
+        return 'The provided "gcloud" exec path is invalid: %s' % (path,)
+
+    print('INFO: Using gcloud tool:', GCP_CONF['gcloud_exec_path'])
+
+    result = subprocess.run([GCP_CONF['gcloud_exec_path'], 'info'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
     if result.returncode != 0:
-        return
+        GCP_CONF['gcloud_exec_path'] = None
+        return 'Error during execution of "gcloud" tool: %s' % (result.stderr.decode('utf-8').strip(),)
+
     lines = result.stdout
     try:
         lines = lines.decode('utf-8').split('\n')
@@ -83,24 +128,39 @@ def findGoogleCloudSdk():
         # UTF-8 not worked, so probably it's latin1
         lines = lines.decode('iso-8859-1').split('\n')
 
+    sdk_path = None
     for line in lines:
-        if not line.startswith('Installation Root: ['):
-            continue
-        path = line.strip()[:-1].lstrip('Installation Root: [')
-        if setGoogleCloudSdk(path):
-            return path
+        if line.startswith('Installation Root: ['):
+            sdk_path = line.strip()[:-1].lstrip('Installation Root: [')
+            break
+    if sdk_path and setGoogleCloudSdk(sdk_path):
+        loadGoogleCloudSdk()
+        return True
 
-def loadGoogleCloudSdk():
-    print('DEBUG: Loading gcloud paths')
-    sys.path.append('%s/lib/third_party' % GOOGLE_CLOUD_SDK_ROOT)
-    sys.path.append('%s/platform/bq/third_party' % GOOGLE_CLOUD_SDK_ROOT)
-    sys.path.append('%s/lib' % GOOGLE_CLOUD_SDK_ROOT)
+    GCP_CONF['gcloud_exec_path'] = None
+    return 'Unable to find Google Cloud SDK Installation Root path'
 
-    # Init credentials and properties
-    _getCreds()
+def checkDependencies(settings):
+    if not GOOGLE_CLOUD_SDK_ROOT:
+        return initProvider(settings)
+    return True
 
-def checkDependencies():
-    return GOOGLE_CLOUD_SDK_ROOT is not None
+def getSettings():
+    '''Returns the available settings of the provider'''
+    return {
+        'gcloud_exec_path': {
+            'name': 'Path to gcloud exec',
+            'description': 'Full path to the gcloud or gcloud.exe from Google Cloud SDK, by default uses PATH env to find it',
+            'type': 'path',
+            'value': GCP_CONF.get('gcloud_exec_path'),
+        },
+        'bucket_name': {
+            'name': 'Bucket name',
+            'description': '''What the bucket to use - in case it's empty will create the new one as "{project}-blendnet-{session_id}"''',
+            'type': 'string',
+            'value': GCP_CONF.get('bucket_name', ''),
+        },
+    }
 
 def _getCreds():
     if not GOOGLE_CLOUD_SDK_ROOT:
@@ -136,14 +196,16 @@ def _getConfigs():
             'zone': props.compute.zone.Get(),
         }
 
-        if checkLocation():
-            # Get defaults from metadata if they are not set
+        # Get defaults from metadata if they are not set
+        try:
             if not configs['project']:
                 configs['project'] = _requestMetadata('project/project-id')
             if not configs['zone']:
                 configs['zone'] = _requestMetadata('instance/zone').rsplit('/', 1)[1]
             if not configs['region']:
                 configs['region'] = configs['zone'].rsplit('-', 1)[0]
+        except Exception as e:
+            print('DEBUG: Failed update config from metadata:', e)
 
         GOOGLE_CLOUD_SDK_CONFIGS = configs
 
@@ -326,9 +388,9 @@ fi
 
 echo '--> Download & run the BlendNet manager'
 adduser --shell /bin/false --disabled-password blendnet-user
-gsutil -m cp -r 'gs://{project}-blendnet-{session_id}/work_manager/*' "$(getent passwd blendnet-user | cut -d: -f6)"
-gsutil -m rm 'gs://{project}-blendnet-{session_id}/work_manager/**'
-gsutil -m cp -r 'gs://{project}-blendnet-{session_id}/blendnet' /srv
+gsutil -m cp -r '{storage_url}/work_manager/*' "$(getent passwd blendnet-user | cut -d: -f6)"
+gsutil -m rm '{storage_url}/work_manager/**'
+gsutil -m cp -r '{storage_url}/blendnet' /srv
 
 cat <<'EOF' > /etc/systemd/system/blendnet-manager.service
 [Unit]
@@ -354,8 +416,7 @@ systemctl start blendnet-manager.service # We don't need "enable" here
     '''.format(
         blender_url=cfg['dist_url'],
         blender_sha256=cfg['dist_checksum'],
-        project=configs['project'],
-        session_id=cfg['session_id'],
+        storage_url=cfg['storage_url'],
     )
     #su -l -s /bin/sh -c '/srv/blender/blender -b -noaudio -P /srv/blendnet/manager.py' blendnet-user
 
@@ -448,8 +509,8 @@ fi
 
 echo '--> Download & run the BlendNet agent'
 adduser --shell /bin/false --disabled-password blendnet-user
-gsutil -m cp -r 'gs://{project}-blendnet-{session_id}/work_{name}/*' "$(getent passwd blendnet-user | cut -d: -f6)"
-gsutil -m cp -r 'gs://{project}-blendnet-{session_id}/blendnet' /srv
+gsutil -m cp -r '{storage_url}/work_{instance_name}/*' "$(getent passwd blendnet-user | cut -d: -f6)"
+gsutil -m cp -r '{storage_url}/blendnet' /srv
 
 cat <<'EOF' > /etc/systemd/system/blendnet-agent.service
 [Unit]
@@ -475,9 +536,8 @@ systemctl start blendnet-agent.service # We don't need "enable" here
     '''.format(
         blender_url=cfg['dist_url'],
         blender_sha256=cfg['dist_checksum'],
-        project=configs['project'],
-        session_id=cfg['session_id'],
-        name=cfg['instance_name'],
+        instance_name=cfg['instance_name'],
+        storage_url=cfg['storage_url'],
     )
     #su -l -s /bin/sh -c '/srv/blender/blender -b -noaudio -P /srv/blendnet/agent.py' blendnet-user
 
@@ -629,10 +689,12 @@ def _getBucket(bucket_name):
     except: # TODO: be more specific here - exception could mean anything
         return None
 
-def createBucket(bucket_name):
+def createStorage(storage_url):
     '''Creates bucket if it's not exists'''
     storage, configs = _getStorage(), _getConfigs()
 
+    bucket_name = urllib.parse.urlparse(storage_url).hostname
+
     if _getBucket(bucket_name):
         return True
 
@@ -646,59 +708,105 @@ def createBucket(bucket_name):
 
     return True
 
-def uploadFileToBucket(path, bucket_name, dest_path = None):
+def uploadFileToStorage(path, storage_url, dest_path = None):
     '''Upload file to the bucket'''
     from googleapiclient.http import MediaIoBaseUpload
     storage = _getStorage()
 
+    if dest_path:
+        if platform.system() == 'Windows':
+            dest_path = pathlib.PurePath(dest_path).as_posix()
+        storage_url += '/' + dest_path
+
     body = {
-        'name': dest_path or path,
+        'name': urllib.parse.urlparse(storage_url).path.lstrip('/'),
     }
 
-    # if the plugin was called from a windows OS, we need to convert the path separators for gsutil
+    # If the provider was called from Windows, we need to convert the path separators
     if platform.system() == 'Windows':
         body['name'] = pathlib.PurePath(body['name']).as_posix()
 
-    print('INFO: Uploading file to "gs://%s/%s"...' % (bucket_name, body['name']))
+    print('INFO: Uploading file to "%s"...' % (storage_url,))
     with open(path, 'rb') as f:
         # TODO: make sure file uploaded or there is an isssue
         storage.objects().insert(
-            bucket=bucket_name, body=body,
+            bucket=urllib.parse.urlparse(storage_url).hostname, body=body,
             media_body=MediaIoBaseUpload(f, 'application/octet-stream', chunksize=8*1024*1024),
         ).execute()
 
     return True
 
-def uploadDataToBucket(data, bucket_name, dest_path):
+def uploadRecursiveToStorage(path, storage_url, dest_path = None, include = None, exclude = None):
+    '''Recursively upload files to the storage'''
+
+    if dest_path:
+        if platform.system() == 'Windows':
+            dest_path = pathlib.PurePath(dest_path).as_posix()
+
+    print('INFO: GCP: Uploading files from %s to "%s" ...' % (path, storage_url))
+
+    workers = Workers(
+        'Uploading BlendNet logic to the storage',
+        8,
+        uploadFileToStorage,
+    )
+
+    # Walk through python files and upload them
+    for root, _, files in os.walk(path):
+        for f in files:
+            if include and not pathlib.PurePath(f).match(include):
+                continue
+            if exclude and pathlib.PurePath(f).match(exclude):
+                continue
+            filepath = os.path.join(root, f)
+            workers.add(filepath, storage_url, filepath.replace(path, dest_path, 1))
+
+    workers.start()
+    workers.wait()
+
+    print('INFO: GCP: Uploaded files to "%s"' % (storage_url,))
+
+    return True
+
+def uploadDataToStorage(data, storage_url, dest_path = None):
     '''Upload file to the bucket'''
     from googleapiclient.http import MediaInMemoryUpload
     storage = _getStorage()
 
+    if dest_path:
+        if platform.system() == 'Windows':
+            dest_path = pathlib.PurePath(dest_path).as_posix()
+        storage_url += '/' + dest_path
+
     body = {
-        'name': dest_path,
+        'name': urllib.parse.urlparse(storage_url).path.lstrip('/'),
     }
 
-    # if the plugin was called from a windows OS, we need to convert the path separators for gsutil
-    if platform.system() == 'Windows':
-        body['name'] = pathlib.PurePath(body['name']).as_posix()
-
-    print('INFO: Uploading data to "gs://%s/%s"...' % (bucket_name, body['name']))
-    # TODO: make sure file uploaded or there is an isssue
+    print('INFO: Uploading data to "%s"...' % (storage_url,))
+    # TODO: make sure file uploaded or there is an issue
     storage.objects().insert(
-        bucket=bucket_name, body=body,
+        bucket=urllib.parse.urlparse(storage_url).hostname, body=body,
         media_body=MediaInMemoryUpload(data, mimetype='application/octet-stream'),
     ).execute()
 
     return True
 
-def downloadDataFromBucket(bucket_name, path):
+def downloadDataFromStorage(storage_url, path = None):
     from googleapiclient.http import MediaIoBaseDownload
     from io import BytesIO
 
     storage = _getStorage()
 
-    print('INFO: Downloading data from "gs://%s/%s"...' % (bucket_name, path))
-    req = storage.objects().get_media(bucket=bucket_name, object=path)
+    if path:
+        if platform.system() == 'Windows':
+            path = pathlib.PurePath(path).as_posix()
+        storage_url += '/' + path
+
+    print('INFO: Downloading data from "%s"...' % (storage_url,))
+    req = storage.objects().get_media(
+        bucket=urllib.parse.urlparse(storage_url).hostname,
+        object=urllib.parse.urlparse(storage_url).path.lstrip('/')
+    )
     data_fd = BytesIO()
     downloader = MediaIoBaseDownload(data_fd, req, chunksize=8*1024*1024)
 
@@ -768,10 +876,11 @@ def getManagerSizeDefault():
 def getAgentSizeDefault():
     return 'n1-highcpu-2'
 
-def getBucketName(session_id):
-    '''Returns the appropriate bucket name'''
+def getStorageUrl(session_id):
+    '''Returns the gcp bucket info'''
     configs = _getConfigs()
-    return '%s-blendnet-%s' % (configs['project'], session_id.lower())
+    default_name = '{project}-blendnet-{session_id}'.format(project=configs['project'], session_id=session_id.lower())
+    return 'gs://' + (GCP_CONF.get('bucket_name') or default_name)
 
 def getManagerName(session_id):
     return 'blendnet-%s-manager' % session_id
@@ -854,11 +963,6 @@ def getPrice(inst_type, cheap_multiplier):
 
     return (out_price, out_currency)
 
-findGoogleCloudSdk()
-
-if GOOGLE_CLOUD_SDK_ROOT:
-    loadGoogleCloudSdk()
-
 from .Processor import Processor
 from .Manager import Manager
 from .Agent import Agent
diff --git a/BlendNet/providers/local/__init__.py b/BlendNet/providers/local/__init__.py
index bde39ca..622c6fb 100644
--- a/BlendNet/providers/local/__init__.py
+++ b/BlendNet/providers/local/__init__.py
@@ -17,6 +17,14 @@ LOCAL_RESOURCES = {'agents': {}}
 def getProviderInfo():
     return {}
 
+def checkDependencies(settings):
+    '''No dependencies for the local provider'''
+    return True
+
+def getSettings():
+    '''No settings for the local provider'''
+    return {}
+
 def getResources(session_id):
     '''Get the available resources from the Manager'''
     out = {
@@ -43,8 +51,8 @@ def getResources(session_id):
 
     return out
 
-def downloadDataFromBucket(bucket_name, path):
-    if not path == 'ca.crt':
+def downloadDataFromStorage(storage_url, path):
+    if path != 'ca.crt':
         return
 
     # Check if it's Addon and try to load from manager_ca_path pref
@@ -62,6 +70,7 @@ def downloadDataFromBucket(bucket_name, path):
         with open('ca.crt', 'rb') as fh:
             return fh.read()
     except:
+        print('WARN: Unable to load the "ca.crt" certificate')
         pass
 
 def createInstanceAgent(cfg):
diff --git a/BlendNet/script-compose.py b/BlendNet/script-compose.py
index 995eda7..68d6105 100644
--- a/BlendNet/script-compose.py
+++ b/BlendNet/script-compose.py
@@ -32,7 +32,7 @@ if 'frame' in task:
     scene.frame_current = task['frame']
 
 print('INFO: Checking existance of the dependencies')
-goods, bads = blend_file.getDependencies()
+goods, bads = blend_file.getDependencies(task.get('project_path'), task.get('cwd_path'), True)
 print('DEBUG: Goods:', goods)
 print('DEBUG: Bads:', bads)
 
diff --git a/BlendNet/script-render.py b/BlendNet/script-render.py
index 15a52c4..3bf5347 100644
--- a/BlendNet/script-render.py
+++ b/BlendNet/script-render.py
@@ -49,18 +49,25 @@ scene.render.threads_mode = 'AUTO'
 
 scene.cycles.device = 'CPU' # The only one supported right now
 
-# Disabling square samples - script is getting the real number of samples to render
-scene.cycles.use_square_samples = False
+if hasattr(scene.cycles, 'use_square_samples'):
+    # For blender < 3.0.0
+    # Disabling square samples - script is getting the real number of samples to render
+    scene.cycles.use_square_samples = False
 
 # Set sampling
 eprint('INFO: Set sampling')
-if scene.cycles.progressive == 'PATH':
-    scene.cycles.samples = task['samples']
-elif scene.cycles.progressive == 'BRANCHED_PATH':
-    scene.cycles.aa_samples = task['samples']
+if hasattr(scene.cycles, 'progressive'):
+    # For blender < 3.0.0
+    if scene.cycles.progressive == 'PATH':
+        scene.cycles.samples = task['samples']
+    elif scene.cycles.progressive == 'BRANCHED_PATH':
+        scene.cycles.aa_samples = task['samples']
+    else:
+        eprint('ERROR: Unable to determine the sampling integrator')
+        sys.exit(1)
 else:
-    eprint('ERROR: Unable to determine the sampling integrator')
-    sys.exit(1)
+    scene.cycles.use_adaptive_sampling = False
+    scene.cycles.samples = task['samples']
 
 # Set task seed or use random one (because we need an unique render pattern)
 scene.cycles.seed = task.get('seed', random.randrange(0, 2147483647))
@@ -77,8 +84,10 @@ if bpy.context.view_layer.cycles.use_denoising:
     # using _cycles.denoise() or composite denoise node
     bpy.context.view_layer.cycles.denoising_store_passes = True
 
-eprint('INFO: Use progressive refine')
-scene.cycles.use_progressive_refine = True
+if hasattr(scene.cycles, 'use_progressive_refine'):
+    # For blender < 3.0.0
+    eprint('INFO: Use progressive refine')
+    scene.cycles.use_progressive_refine = True
 
 # BN-119 Disabled due to crashes during collecting the statistics
 #try:
@@ -88,7 +97,17 @@ scene.cycles.use_progressive_refine = True
 #    pass
 
 eprint('INFO: Checking existance of the dependencies')
-blend_file.getDependencies()
+goods, bads = blend_file.getDependencies(task.get('project_path'), task.get('cwd_path'), True)
+
+def checkRenderExr(path):
+    '''Checks that the EXR file is actually MultiLayer and good for render result'''
+    with open(path, 'rb') as f:
+        h = f.read(32)
+        if not h.startswith(b'\x76\x2f\x31\x01'):
+            return False
+        if not b'MultiChannel' in h:
+            return False
+    return True
 
 class Commands:
     def savePreview(cls = None):
@@ -111,7 +130,24 @@ class Commands:
         # Due to the bug it's not working properly: https://developer.blender.org/T71087
         # Basically when multilayer exr is selected - it's saved as a regular one layer
         # exr, so switched to `write_still` in executing the render command
-        os.rename('_render.exr', 'render.exr')
+        try:
+            if checkRenderExr('_render.exr'):
+                os.rename('_render.exr', 'render.exr')
+        except FileNotFoundError as e:
+            # During cancel of the task `write_still` will not save the render result
+            eprint('ERROR: Unable to find render file:', e)
+
+            # Try to recover with backup-plan
+            scene.render.image_settings.file_format = 'OPEN_EXR_MULTILAYER'
+            scene.render.image_settings.color_mode = 'RGBA'
+            scene.render.image_settings.color_depth = '32'
+            scene.render.image_settings.exr_codec = 'ZIP'
+            bpy.data.images['Render Result'].save_render('_render.exr')
+            if checkRenderExr('_render.exr'):
+                os.rename('_render.exr', 'render.exr')
+                eprint('WARN: Recovered the render file:', os.stat('render.exr').st_size)
+            else:
+                eprint('ERROR: Failed to recover render file (the type is not EXR ML)')
 
 def executeCommand(name):
     func = getattr(Commands, name, None)
@@ -128,6 +164,11 @@ def stdinProcess():
             command = line.strip()
             if command == 'end':
                 break
+            # Blender v3 contains a nasty bug with OpenEXR format which don't allow to save
+            # intermediate results of render image: https://developer.blender.org/T94314
+            if command == 'savePreview' and bpy.app.version_file[0] == 3:
+                eprint('WARNING: Saving of intermediate preview for Blender v3 is disabled')
+                continue
             executeCommand(command)
         except Exception as e:
             eprint('ERROR: Exception during processing stdin: %s' % e)
@@ -142,6 +183,7 @@ scene.render.image_settings.color_mode = 'RGBA'
 scene.render.image_settings.color_depth = '32'
 scene.render.image_settings.exr_codec = 'ZIP'
 scene.render.filepath = os.path.abspath('_render.exr')
+
 bpy.ops.render.render(write_still=True)
 
 eprint('INFO: Render process completed')
diff --git a/BlendNet/utils.py b/BlendNet/utils.py
new file mode 100644
index 0000000..bcf3621
--- /dev/null
+++ b/BlendNet/utils.py
@@ -0,0 +1,74 @@
+#!/usr/bin/python3
+# -*- coding: UTF-8 -*-
+'''BlendNet Utils
+
+Description: Common utils for BlendNet
+'''
+
+import os
+import time
+import platform
+
+# Unfortunately built-in python path functions are platform-dependent
+# WARNING: Backslash-separated paths on windows will be resolved as separators!
+def isPathStraight(path):
+    '''Checks that the path contains '..' (parent dir usage) or not'''
+    if path.startswith('..') or path.endswith('..') or '/../' in path:
+        # Cound lead to false-positives with "..file..", but at least
+        # it will check the backslash case too
+        return False
+    # Just to be sure there will be no backslash issues:
+    if '\\..\\' in path:
+        return False
+    return True
+
+def isPathAbsolute(path):
+    '''Will check the path: it's absolute or not in cross-platform way'''
+    if path.startswith('/') and not path.startswith('//'):
+        return True
+    if len(path) > 2 and path[1] == ':' and path[2] == '/':
+        # For now supports only general one-letter windows disks
+        return True
+    return isPathLinAbsolute(path) or isPathWinAbsolute(path)
+
+def isPathLinAbsolute(path):
+    '''Will check the path: it's absolute for linux path'''
+    return path.startswith('/') and not path.startswith('//')
+
+def isPathWinAbsolute(path):
+    '''Will check the path: it's absolute for windows path'''
+    # For now supports only general one-letter windows disks
+    return len(path) > 2 and path[1] == ':' and path[2] in ('/', '\\')
+
+def resolvePath(path):
+    '''Will make sure all the parent dirs are resolved'''
+    # There is no proper way to resolve win paths on linux and vice versa
+    if platform.system() == 'Windows' and not isPathWinAbsolute(path):
+        return os.path.abspath('C:/'+path)[3:].replace('\\', '/')
+    elif platform.system() != 'Windows' and not isPathLinAbsolute(path):
+        return os.path.abspath('/'+path)[1:]
+    else:
+        return os.path.abspath(path)
+
+class CopyStringIO:
+    '''Class to store the logs to get them with timestamps later'''
+    def __init__(self, orig_out, copy_out, copy_out_lock):
+        self._orig_out = orig_out
+        self._copy_out = copy_out
+        self._copy_out_lock = copy_out_lock
+    def write(self, buf):
+        self._orig_out.write(buf)
+        with self._copy_out_lock:
+            key = str(time.time())
+            while key in self._copy_out:
+                key = str(float(key)+0.00001)
+            self._copy_out[key] = buf
+            if len(self._copy_out) > 100000:
+                to_remove_keys = sorted(self._copy_out.keys())[0:10000]
+                for key in to_remove_keys:
+                    del self._copy_out[key]
+    def flush(self):
+        self._orig_out.flush()
+
+    def isatty(self):
+        return self._orig_out.isatty()
diff --git a/__init__.py b/__init__.py
index 33266c1..d09a191 100644
--- a/__init__.py
+++ b/__init__.py
@@ -1,7 +1,8 @@
 bl_info = {
     'name': 'BlendNet - distributed cloud render',
     'author': 'www.state-of-the-art.io',
-    'version': (0, 3, 9),
+    'version': (0, 4, 0),
+    'warning': 'development version',
     'blender': (2, 80, 0),
     'location': 'Properties --> Render --> BlendNet Render',
     'description': 'Allows to easy allocate resources in cloud and '
@@ -43,10 +44,16 @@ class BlendNetAddonPreferences(bpy.types.AddonPreferences):
     resource_provider: EnumProperty(
         name = 'Provider',
         description = 'Engine to provide resources for rendering',
-        items = BlendNet.addon.getProvidersEnumItems(),
+        items = BlendNet.addon.getProvidersEnumItems,
         update = lambda self, context: BlendNet.addon.selectProvider(self.resource_provider),
     )
 
+    blendnet_show_panel: BoolProperty(
+        name = 'Show BlendNet',
+        description = 'Show BlendNet render panel',
+        default = True,
+    )
+
     # Advanced
     blender_dist: EnumProperty(
         name = 'Blender dist',
@@ -205,16 +212,34 @@ class BlendNetAddonPreferences(bpy.types.AddonPreferences):
 
         # Provider
         box = layout.box()
+        row = box.row()
         split = box.split(factor=0.8)
         split.prop(self, 'resource_provider')
         info = BlendNet.addon.getProviderDocs(self.resource_provider).split('\n')
         for line in info:
             if line.startswith('Help: '):
                 split.operator('wm.url_open', text='How to setup', icon='HELP').url = line.split(': ', 1)[-1]
-        if not BlendNet.addon.checkProviderIsGood(self.resource_provider):
+
+        provider_settings = BlendNet.addon.getProviderSettings()
+        for key, data in provider_settings.items():
+            path = 'provider_' + self.resource_provider + '_' + key
+            if not path in self.__class__.__annotations__:
+                print('ERROR: Unable to find provider setting:', path)
+                continue
+            if path not in self or self[path] is None:
+                self[path] = data.get('value')
+            box.prop(self, path)
+
+        messages = BlendNet.addon.getProviderMessages(self.resource_provider)
+        for msg in messages:
+            box.label(text=msg, icon='ERROR')
+
+        if not BlendNet.addon.checkProviderIsSelected():
             err = BlendNet.addon.getProviderDocs(self.resource_provider).split('\n')
             for line in err:
                 box.label(text=line.strip(), icon='ERROR')
+            return
+
         if self.resource_provider != 'local':
             box = box.box()
             box.label(text='Collected cloud info:')
@@ -386,17 +411,14 @@ class BlendNetToggleManager(bpy.types.Operator):
     bl_label = ''
     bl_description = 'Start/Stop manager instance'
 
-    retry_counter: IntProperty(default=50)
-
     _timer = None
     _last_run = 0
 
     @classmethod
     def poll(cls, context):
-        return context.window_manager.blendnet.status == 'idle'
+        return context.window_manager.blendnet.status == 'idle' or BlendNet.addon.isManagerStarted()
 
     def invoke(self, context, event):
-        self.retry_counter = 50
         wm = context.window_manager
         BlendNet.addon.toggleManager()
 
@@ -425,13 +447,6 @@ class BlendNetToggleManager(bpy.types.Operator):
     def execute(self, context):
         wm = context.window_manager
 
-        self.retry_counter -= 1
-        if self.retry_counter < 0:
-            self.report({'ERROR'}, 'BlendNet Manager operation reached maximum retries - something bad happened '
-                                   'on "%s" stage. Please consult the documentation' % wm.blendnet.status)
-            wm.blendnet.status = 'idle'
-            return {'FINISHED'}
-
         if wm.blendnet.status == 'Manager starting...':
             if not BlendNet.addon.isManagerStarted():
                 return {'PASS_THROUGH'}
@@ -440,7 +455,7 @@ class BlendNetToggleManager(bpy.types.Operator):
             if context.area:
                 context.area.tag_redraw()
             BlendNet.addon.requestManagerInfo(context)
-        elif wm.blendnet.status == 'Manager connecting...':
+        elif wm.blendnet.status == 'Manager stopping...':
             if not BlendNet.addon.isManagerStopped():
                 return {'PASS_THROUGH'}
 
@@ -551,9 +566,9 @@ class BlendNetRunTaskOperation(bpy.types.Operator):
             return {'CANCELLED'}
 
         # Fix and verify the blendfile dependencies
-        bads = blend_file.getDependencies()[1]
+        bads = blend_file.getDependencies(bpy.path.abspath('//'), os.path.abspath(''))[1]
         if bads:
-            self.report({'ERROR'}, 'Found some bad dependencies - please fix them before run: %s' % bads)
+            self.report({'ERROR'}, 'Found some bad dependencies - please fix them before run: %s' % (bads,))
             return {'CANCELLED'}
 
         # Saving project to the same directory
@@ -566,7 +581,7 @@ class BlendNetRunTaskOperation(bpy.types.Operator):
                 copy = True,
             )
         except Exception as e:
-            self.report({'ERROR'}, 'Unable to save the "_blendnet.blend" project file: %s' % e)
+            self.report({'ERROR'}, 'Unable to save the "_blendnet.blend" project file: %s' % (e,))
             return {'CANCELLED'}
 
         if self.is_animation:
@@ -620,14 +635,13 @@ class BlendNetRunTaskOperation(bpy.types.Operator):
             print('DEBUG: Uploading task "%s" to the manager' % self._task_name)
 
             # Prepare list of files need to be uploaded
-            base_dir = os.path.dirname(bpy.path.abspath(bpy.data.filepath))
-            deps, bads = blend_file.getDependencies()
+            deps, bads = blend_file.getDependencies(bpy.path.abspath('//'), os.path.abspath(''))
             if bads:
-                self.report({'ERROR'}, 'Found some bad dependencies - please fix them before run: %s' % bads)
+                self.report({'ERROR'}, 'Found some bad dependencies - please fix them before run: %s' % (bads,))
                 return {'CANCELLED'}
 
-            deps_map = dict([ (rel, os.path.join(base_dir, rel)) for rel in deps ])
-            deps_map[fname] = self._project_file
+            deps_map = dict([ (rel, bpy.path.abspath(rel)) for rel in deps ])
+            deps_map['//'+fname] = self._project_file
 
             # Run the dependencies upload background process
             BlendNet.addon.managerTaskUploadFiles(self._task_name, deps_map)
@@ -650,16 +664,22 @@ class BlendNetRunTaskOperation(bpy.types.Operator):
 
         # Configuring the task
         print('INFO: Configuring task "%s"' % self._task_name)
-        self.report({'INFO'}, 'Configuring task "%s"' % self._task_name)
+        self.report({'INFO'}, 'Configuring task "%s"' % (self._task_name,))
         samples = None
-        if scene.cycles.progressive == 'PATH':
+        if hasattr(scene.cycles, 'progressive'):
+            # For blender < 3.0.0
+            if scene.cycles.progressive == 'PATH':
+                samples = scene.cycles.samples
+            elif scene.cycles.progressive == 'BRANCHED_PATH':
+                samples = scene.cycles.aa_samples
+        else:
             samples = scene.cycles.samples
-        elif scene.cycles.progressive == 'BRANCHED_PATH':
-            samples = scene.cycles.aa_samples
 
-        # Addon need to pass the actual samples number to the manager
-        if scene.cycles.use_square_samples:
-            samples *= samples
+        if hasattr(scene.cycles, 'use_square_samples'):
+            # For blender < 3.0.0
+            # Addon need to pass the actual samples number to the manager
+            if scene.cycles.use_square_samples:
+                samples *= samples
 
         # Where the compose result will be stored on the Addon side
         compose_filepath = scene.render.frame_path()
@@ -673,19 +693,21 @@ class BlendNetRunTaskOperation(bpy.types.Operator):
             'project': fname,
             'use_compositing_nodes': scene.render.use_compositing,
             'compose_filepath': compose_filepath,
+            'project_path': bpy.path.abspath('//'), # To resolve the project parent paths like `//../..`
+            'cwd_path': os.path.abspath(''), # Current working directory to resolve relative paths like `../dir/file.txt`
         }
 
         if not BlendNet.addon.managerTaskConfig(self._task_name, cfg):
-            self.report({'WARNING'}, 'Unable to config the task "%s", let\'s retry...' % self._task_name)
+            self.report({'WARNING'}, 'Unable to config the task "%s", let\'s retry...' % (self._task_name,))
             return {'PASS_THROUGH'}
 
         # Running the task
         self.report({'INFO'}, 'Running task "%s"' % self._task_name)
         if not BlendNet.addon.managerTaskRun(self._task_name):
-            self.report({'WARNING'}, 'Unable to start the task "%s", let\'s retry...' % self._task_name)
+            self.report({'WARNING'}, 'Unable to start the task "%s", let\'s retry...' % (self._task_name,))
             return {'PASS_THROUGH'}
 
-        self.report({'INFO'}, 'Task "%s" marked as ready to start' % self._task_name)
+        self.report({'INFO'}, 'Task "%s" marked as ready to start' % (self._task_name,))
 
         # Ok, task is started - we can clean the name
         self._task_name = None
@@ -699,8 +721,7 @@ class BlendNetRunTaskOperation(bpy.types.Operator):
             scene.frame_current = self._frame_orig
 
         # Removing no more required temp blend file
-        if self._project_file and os.path.exists(self._project_file):
-            os.remove(self._project_file)
+        os.remove(self._project_file)
 
         if self._timer is not None:
             context.window_manager.event_timer_remove(self._timer)
@@ -753,7 +774,52 @@ class BlendNetGetNodeLogOperation(bpy.types.Operator):
             else:
                 layout.label(text='Unable to show the log window', icon='ERROR')
 
-        wm.popup_menu(drawPopup, title='Log for manager', icon='INFO')
+        wm.popup_menu(drawPopup, title='Log for'+prefix, icon='INFO')
+
+        return {'FINISHED'}
+
+class BlendNetGetAddonLogOperation(bpy.types.Operator):
+    bl_idname = 'blendnet.getaddonlog'
+    bl_label = 'Get BlendNet Addon Log'
+    bl_description = 'Show the running BlendNet addon log information'
+
+    @classmethod
+    def poll(cls, context):
+        return True
+
+    def invoke(self, context, event):
+        wm = context.window_manager
+
+        out = BlendNet.addon.getAddonLog()
+        prefix = 'addon'
+
+        if not out:
+            self.report({'ERROR'}, 'No log data found for ' + prefix)
+            return {'CANCELLED'}
+
+        data = []
+        line = ''
+        for t, l in out.items():
+            if not l.endswith('\n'):
+                line += l
+                continue
+            time_str = datetime.fromtimestamp(round(float(t), 3)).strftime('%y.%m.%d %H:%M:%S.%f')
+            data.append(time_str + '\t' + line + l)
+            line = ''
+        if line:
+            data.append('{not completed line}\t' + line)
+
+        data = ''.join(data)
+
+        def drawPopup(self, context):
+            layout = self.layout
+
+            if BlendNet.addon.showLogWindow(prefix, data):
+                layout.label(text='Don\'t forget to unlink the file if you don\'t want it to stay in blend file.')
+            else:
+                layout.label(text='Unable to show the log window', icon='ERROR')
+
+        wm.popup_menu(drawPopup, title='Log for ' + prefix, icon='INFO')
 
         return {'FINISHED'}
 
@@ -764,7 +830,7 @@ class BlendNetGetServiceLogOperation(bpy.types.Operator):
 
     agent_name: StringProperty(
         name = 'Name of Agent',
-        description = 'Name of Agent to get log from or Manager will be used',
+        description = 'Name of Agent (or Manager by default) to get the log from',
         default = ''
     )
 
@@ -809,7 +875,7 @@ class BlendNetGetServiceLogOperation(bpy.types.Operator):
             else:
                 layout.label(text='Unable to show the log window', icon='ERROR')
 
-        wm.popup_menu(drawPopup, title='Log for manager', icon='INFO')
+        wm.popup_menu(drawPopup, title='Log for' + prefix, icon='INFO')
 
         return {'FINISHED'}
 
@@ -1273,20 +1339,27 @@ class BlendNetRenderPanel(bpy.types.Panel):
         prefs = context.preferences.addons[__package__].preferences
 
         box = layout.box()
-        row = box.row()
-        row.label(text='BlendNet Render (%s)' % (prefs.resource_provider,))
-        row.label(text=context.window_manager.blendnet.status)
+        row = box.split(factor=0.5)
+        split = row.split(factor=0.1)
+        split.prop(prefs, 'blendnet_show_panel', icon_only=True)
+        split.label(text='BlendNet Render (%s)' % (prefs.resource_provider,))
+        split = row.split(factor=0.9)
+        split.label(text=context.window_manager.blendnet.status)
+        split.operator('blendnet.getaddonlog', text='', icon='TEXT')
+        if not prefs.blendnet_show_panel:
+            return
         row = box.row()
         row.use_property_split = True
         row.use_property_decorate = False # No prop animation
         row.prop(bn, 'scene_memory_req', text='Render RAM (GB)')
 
+        if not BlendNet.addon.checkProviderIsSelected():
+            box.label(text='ERROR: Provider init failed, check addon settings', icon='ERROR')
+            return
         if not BlendNet.addon.checkAgentMemIsEnough():
             box.label(text='WARN: Agent does not have enough memory to render the scene', icon='ERROR')
         if not prefs.agent_use_cheap_instance:
             box.label(text='WARN: No cheap VMs available, check addon settings', icon='ERROR')
-        if not BlendNet.addon.checkProviderIsGood(prefs.resource_provider):
-            box.label(text='ERROR: Provider init failed, check addon settings', icon='ERROR')
         if context.scene.render.engine != __package__:
             row = box.row(align=True)
             if BlendNet.addon.isManagerStarted():
@@ -1313,6 +1386,10 @@ class BlendNetManagerPanel(bpy.types.Panel):
     bl_context = 'render'
     bl_options = {'DEFAULT_CLOSED'}
 
+    @classmethod
+    def poll(cls, context):
+        return context.preferences.addons[__package__].preferences.blendnet_show_panel and BlendNet.addon.checkProviderIsSelected()
+
     def draw_header(self, context):
         layout = self.layout
 
@@ -1391,6 +1468,10 @@ class BlendNetAgentsPanel(bpy.types.Panel):
     bl_context = 'render'
     bl_options = {'DEFAULT_CLOSED'}
 
+    @classmethod
+    def poll(cls, context):
+        return context.preferences.addons[__package__].preferences.blendnet_show_panel and BlendNet.addon.checkProviderIsSelected()
+
     def draw_header(self, context):
         layout = self.layout
 
@@ -1589,6 +1670,36 @@ class BlendNetRenderEngine(bpy.types.RenderEngine):
         self.end_result(result)
 
 
+def loadProvidersSettings():
+    '''Get the available providers settings to set and load them during registration of the class'''
+    all_settings = BlendNet.addon.getProvidersSettings()
+    for provider, provider_settings in all_settings.items():
+        for key, data in provider_settings.items():
+            path = 'provider_' + provider + '_' + key
+            print('DEBUG: registering provider config:', path)
+            if data.get('type') in ('string', 'path'):
+                BlendNetAddonPreferences.__annotations__[path] = StringProperty(
+                    name = data.get('name'),
+                    description = data.get('description'),
+                    subtype = 'FILE_PATH' if data['type'] == 'path' else 'NONE',
+                    update = BlendNet.addon.updateProviderSettings,
+                )
+            elif data.get('type') == 'choice':
+                BlendNetAddonPreferences.__annotations__[path] = EnumProperty(
+                    name = data.get('name'),
+                    description = data.get('description'),
+                    items = data.get('values'),
+                    update = BlendNet.addon.updateProviderSettings,
+                )
+                # Additional field to store string value (otherwise it's hard on init when
+                # value of enum is integer and has no items to choose from)
+                BlendNetAddonPreferences.__annotations__[path+'_value'] = StringProperty(
+                    name = data.get('name'),
+                    description = data.get('description'),
+                )
+            else:
+                print('ERROR: Unknown provider "%s" setting "%s" type: %s' % (provider, key, data.get('type')))
+
 def initPreferences():
     '''Will init the preferences with defaults'''
     prefs = bpy.context.preferences.addons[__package__].preferences
@@ -1613,6 +1724,9 @@ def initPreferences():
     BlendNet.addon.getProviderInfo()
 
 def register():
+    BlendNet.addon.initAddonLog()
+    BlendNet.providers.loadProviders()
+    loadProvidersSettings()
     bpy.utils.register_class(BlendNetAddonPreferences)
     initPreferences()
 
@@ -1636,6 +1750,7 @@ def register():
     bpy.utils.register_class(BlendNetAgentCreateOperation)
     bpy.utils.register_class(BlendNetTaskMenu)
     bpy.utils.register_class(BlendNetGetServiceLogOperation)
+    bpy.utils.register_class(BlendNetGetAddonLogOperation)
     bpy.utils.register_class(BlendNetGetNodeLogOperation)
     bpy.utils.register_class(BlendNetRenderPanel)
     bpy.utils.register_class(BlendNetToggleManager)
@@ -1650,6 +1765,7 @@ def unregister():
     bpy.utils.unregister_class(BlendNetDestroyManager)
     bpy.utils.unregister_class(BlendNetRenderPanel)
     bpy.utils.unregister_class(BlendNetGetNodeLogOperation)
+    bpy.utils.unregister_class(BlendNetGetAddonLogOperation)
     bpy.utils.unregister_class(BlendNetGetServiceLogOperation)
     bpy.utils.unregister_class(BlendNetTaskMenu)
     bpy.utils.unregister_class(BlendNetTaskInfoOperation)
diff --git a/agent.py b/agent.py
index 3f6a8fd..49c2514 100644
--- a/agent.py
+++ b/agent.py
@@ -9,28 +9,37 @@ Run: /srv/blender/blender -b -noaudio -P /srv/blendnet/agent.py
 import os, sys
 sys.path.append(os.path.dirname(__file__))
 
+from BlendNet import providers
+
+# TODO: allow even basic config change - restart the http server if its configs changed
+conf = {}
+if os.path.exists('agent.json'):
+    with open('agent.json', 'r') as f:
+        import json
+        conf = json.load(f)
+
+providers.loadProviders()
+# Select the required provider, local by default
+providers.selectProvider(conf.get('provider', 'local'))
+
+
 from BlendNet import (
     disable_buffering,
-    Agent,
+    getVersion,
     SimpleREST,
     Server,
+    Agent,
 )
 
 class Processor(Server.Processor):
     def __init__(self, conf, prefix = 'api/v1'):
-        super().__init__(Agent(conf), prefix)
-
+        super().__init__(Agent.Agent(conf), prefix)
 
-# TODO: allow even basic config change - restart the http server if its configs changed
-conf = {}
-if os.path.exists('agent.json'):
-    with open('agent.json', 'r') as f:
-        import json
-        conf = json.load(f)
 
 SimpleREST.generateCert(conf.get('instance_name', 'blendnet-agent'), 'server')
 httpd = SimpleREST.HTTPServer((conf.get('listen_host', ''), conf.get('listen_port', 9443)), __doc__.split('\n')[0], [Processor(conf)])
 httpd.setTLS(conf.get('server_tls_key', None), conf.get('server_tls_cert', None))
 httpd.setBasicAuth('%s:%s' % (conf.get('auth_user', None), conf.get('auth_password', None)))
 
+print('BlendNet Agent v' + getVersion())
 httpd.serve_forever()
diff --git a/manager.py b/manager.py
index 6a4f0ee..b93f488 100644
--- a/manager.py
+++ b/manager.py
@@ -9,17 +9,31 @@ Run: /srv/blender/blender -b -noaudio -P /srv/blendnet/manager.py
 import os, sys
 sys.path.append(os.path.dirname(__file__))
 
+from BlendNet import providers
+
+# TODO: allow even basic config change - restart the http server if its configs changed
+conf = {}
+if os.path.exists('manager.json'):
+    with open('manager.json', 'r') as f:
+        import json
+        conf = json.load(f)
+
+providers.loadProviders()
+# Select the required provider, local by default
+providers.selectProvider(conf.get('provider', 'local'))
+
+
 from BlendNet import (
     disable_buffering,
-    Manager,
+    getVersion,
     SimpleREST,
     Server,
-    providers,
+    Manager,
 )
 
 class Processor(Server.Processor):
     def __init__(self, conf, prefix = 'api/v1'):
-        super().__init__(Manager(conf), prefix)
+        super().__init__(Manager.Manager(conf), prefix)
 
     @SimpleREST.get('resources')
     def resources(self, req = None):
@@ -45,20 +59,14 @@ class Processor(Server.Processor):
         return { 'success': True, 'message': 'Got agent log', 'data': data }
 
 
-# TODO: allow even basic config change - restart the http server if its configs changed
-conf = {}
-if os.path.exists('manager.json'):
-    with open('manager.json', 'r') as f:
-        import json
-        conf = json.load(f)
-
 SimpleREST.generateCert(conf.get('instance_name', 'blendnet-manager'), 'server')
 httpd = SimpleREST.HTTPServer((conf.get('listen_host', ''), conf.get('listen_port', 8443)), __doc__.split('\n')[0], [Processor(conf)])
 httpd.setTLS(conf.get('server_tls_key', None), conf.get('server_tls_cert', None))
 httpd.setBasicAuth('%s:%s' % (conf.get('auth_user', None), conf.get('auth_password', None)))
 
-# Upload CA back to the blendnet bucket
-if os.path.exists('ca.crt') and conf.get('bucket'):
-    providers.uploadFileToBucket('ca.crt', conf.get('bucket'))
+# Upload CA back to the blendnet storage
+if os.path.exists('ca.crt') and conf.get('storage_url'):
+    providers.uploadFileToStorage('ca.crt', conf['storage_url'], 'ca.crt')
 
+print('BlendNet Manager v' + getVersion())
 httpd.serve_forever()
