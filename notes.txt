Merging two builds?
    Since 1.9.0, "GPU package can be used on both CPU-only and GPU machines" [1]
    Package size considerations: make libonnxruntime_providers_cuda.so a separate package
    There will be warnings from the CUDA build on non-CUDA machines
    /usr/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:352: UserWarning: Deprecation warning. This ORT build has ['CUDAExecutionProvider', 'CPUExecutionProvider'] enabled. The next release (ORT 1.10) will require explicitly setting the providers parameter (as opposed to the current behavior of providers getting set/registered by default based on the build flags) when instantiating InferenceSession.For example, onnxruntime.InferenceSession(..., providers=["CUDAExecutionProvider"], ...)
      warnings.warn("Deprecation warning. This ORT build has {} enabled. ".format(available_providers) +
    2021-09-23 23:47:08.573828136 [E:onnxruntime:Default, provider_bridge_ort.cc:944 Get] Failed to load library libonnxruntime_providers_cuda.so with error: libcublas.so.11: cannot open shared object file: No such file or directory
    2021-09-23 23:47:08.574000870 [E:onnxruntime:Default, provider_bridge_ort.cc:944 Get] Failed to load library libonnxruntime_providers_cuda.so with error: libcublas.so.11: cannot open shared object file: No such file or directory

    [1] https://github.com/microsoft/onnxruntime/releases/tag/v1.9.0
